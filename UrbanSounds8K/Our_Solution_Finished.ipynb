{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLlOLCPYgIUT"
      },
      "source": [
        "# Getting the audio files\n",
        "* We send request with urllib.request to download a.tar.gz file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wQiba-fcRlce"
      },
      "outputs": [],
      "source": [
        "# import urllib.request\n",
        "# urllib.request.urlretrieve (\"https://goo.gl/8hY5ER\",\"a.tar.gz\")\n",
        "# import tarfile\n",
        "# tar = tarfile.open(\"a.tar.gz\")\n",
        "# tar.extractall()\n",
        "# tar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N4GRPmWeXPDE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# os.remove(\"a.tar.gz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZXBQCe9gSN6"
      },
      "source": [
        "# Metadata DataFrame View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0ygZWwjNSLay",
        "outputId": "3e161f3f-483e-4fe6-d0fd-b2753b5343e1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice_file_name</th>\n",
              "      <th>fsID</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>salience</th>\n",
              "      <th>fold</th>\n",
              "      <th>classID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100032-3-0-0.wav</td>\n",
              "      <td>100032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317551</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100263-2-0-117.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>58.5</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100263-2-0-121.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>60.5</td>\n",
              "      <td>64.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100263-2-0-126.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>63.0</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100263-2-0-137.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>68.5</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
              "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
              "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
              "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
              "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
              "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
              "\n",
              "              class  \n",
              "0          dog_bark  \n",
              "1  children_playing  \n",
              "2  children_playing  \n",
              "3  children_playing  \n",
              "4  children_playing  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data=pd.read_csv(\"UrbanSound8K/metadata/UrbanSound8K.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62KuqEjySSUU"
      },
      "source": [
        "# Sample Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tvKZw1vLSN5w"
      },
      "outputs": [],
      "source": [
        "### Let's read a sample audio using librosa\n",
        "import librosa\n",
        "audio_file_path=r'C:\\Users\\Emincan\\Desktop\\Projects\\Global-AI-Hub-Team-Project\\UrbanSounds8K\\UrbanSound8K\\audio\\fold1\\101415-3-0-2.wav'\n",
        "# audio_file_path='/content/UrbanSound8K/audio/fold1/101415-3-0-2.wav'\n",
        "librosa_audio_data,librosa_sample_rate=librosa.load(audio_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l7YHy9nY0qa",
        "outputId": "80d72ada-21f3-4305-87bf-62ccd35802a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.00011662 -0.00017163 -0.00017833 ... -0.04541198 -0.04675572\n",
            " -0.05040179]\n"
          ]
        }
      ],
      "source": [
        "print(librosa_audio_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lxXcoQI7WZ__",
        "outputId": "d558d410-b318-4b8c-d633-c68fdc04618d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ndef create_spectrogram(y):\\n  spec = librosa.feature.melspectrogram(y=y)\\n  spec_conv = librosa.amplitude_to_db(spec, ref=np.max)\\n  return spec_conv\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "def create_spectrogram(y):\n",
        "  spec = librosa.feature.melspectrogram(y=y)\n",
        "  spec_conv = librosa.amplitude_to_db(spec, ref=np.max)\n",
        "  return spec_conv\n",
        "\"\"\"\n",
        "# We get spectrograms with different ways"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "TIGKBhWtXCv3",
        "outputId": "9e540997-7e0d-465c-e2c9-75dd5df6d5ca"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "###  plot the librosa audio data\n",
        "import matplotlib.pyplot as plt\n",
        "# Original audio with 1 channel \n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(librosa_audio_data);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZIHijMwghf6"
      },
      "source": [
        "## Read with Scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "G1fdBtgGY40Z"
      },
      "outputs": [],
      "source": [
        "from scipy.io import wavfile as wav\n",
        "wave_sample_rate, wave_audio = wav.read(audio_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF8tZ2lRY9_M",
        "outputId": "ac6a042a-3a50-4fab-e64c-71bb7269566b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   -5,    -5,    -6, ..., -1576, -1566, -1557], dtype=int16)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wave_audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esZ-2h_8gqSU"
      },
      "source": [
        "## Original audio with 2 channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "l73xz23PY_OE",
        "outputId": "94cbb4a8-629b-4f8d-c90d-4a7fdcf25a0f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABAoAAAFfCAYAAADH3y7PAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnVklEQVR4nO3dd3wUdf7H8Xc2PUASQkiDAKF3EJAQBASJBOVOUc5Tj1NRFPXAhoKiiPUOf9gLineeoCeIemcHkQ4qMWikl0jvCTUJBEid3x/IypK2Ibs7s8nr+XjkAZn57sxnd7K7M5/5fj9fH8MwDAEAAAAAAEiymR0AAAAAAACwDhIFAAAAAADAjkQBAAAAAACwI1EAAAAAAADsSBQAAAAAAAA7EgUAAAAAAMCORAEAAAAAALDzMzsAb1FSUqL9+/erXr168vHxMTscAAAAAEANZxiGjh8/rri4ONlsnrvPT6LASfv371d8fLzZYQAAAAAAapk9e/aocePGHtsfiQIn1atXT9KZAxQaGmpyNAAAAACAmi43N1fx8fH261FPIVHgpLPDDUJDQ0kUAAAAAAA8xtPD3ylmCAAAAAAA7EgUAAAAAAAAOxIFAAAAAADAjkQBAAAAAACwI1EAAAAAAADsSBQAAAAAAAA7EgUAAAAAAMCORAEAAAAAALAjUQAAAAAAAOxIFAAAAAAAADsSBQBgEev25mjTgVyzwwAAS8kvKtbYj1fryzX7zQ4FAGoNEgUAYAHHTxfqj298ryte/U7FJYbZ4QCAZcz8cbc+/WWf7v1wldmhAECtQaIAACzgaF6B/f9FJSUmRgIA1nIkL9/sEACg1iFRAAAAAAAA7EgUAAAAAAAAOz+zAwCA2qywuER3vP+zousFmR0KAAAAIIlEAQCYau66A1qaccjsMAAAAAA7hh4AgIlOFxabHQIAAADggEQBAAAAAACwI1EAAAAAr3D8dKHZIQBArUCiAAAAAF7hX8u3mx0CANQKJAoAAADgFU7kU9cFADyBRAEAAAAsy0c+ZocAALUOiQIAAAAAAGBHogAAAACWZcgwOwQAqHVIFACABZ0sKFJxCSfHAAAA8DwSBQBgMdknC9V+0rf6w+vfmx0KAAAAaiESBQBgMct+PSRJ2nQg1+RIAMB85xYzXLAp08RIAKD2IFEAACYqs5o3Iw4AoEx7jp4yOwQAqBVIFACAiSjSBQAAAKshUQAAFvPm0q1mhwAAlkFCFQA8j0QBAFjMziMn7f/PPV1oYiQAAGfNXrlbk+dukmGQ2ADg/UgUAICFvbpwi9khAICpzq/l8vPOoyZFUrFHPl2nt5dv18y03WaHAgDVRqIAAEx0+ERBheszc097KBIAsJY5aw/o9UVbSg09+NO0VJMics7Ez9frdGGx2WEAQLX4mR0Aare07Uf05Fcb9ezQDureNMLscACPe/7bDLNDAABLGj3rF7NDcNrZaW3PyssvUpC/r0nRAED10aMAprr+nz9q04Fcy98dAEzDUFcAsLwX55P0BVCz0KMAlkDdH9Q2h47n6+BxhhUAQFkWbMwyO4Rq4bQGgLcjUQAAJrj47wvNDgEALOu5bzaZHQIA1GoMPQAAD5uz9oDzjX0qbwIAMBcf1QBqGhIFAOBh7/6ww/nG9F8FAK/zw9bDZocAANVCogAALOwUU2wBgNe5b/Zqs0MAgGpxa6Jg8uTJuvjii1WvXj1FRUVp6NChyshwrAp7+vRpjR49Wg0aNFDdunU1bNgwZWU5FrDZvXu3hgwZopCQEEVFRWncuHEqKipyaLN06VJ169ZNgYGBatmypWbMmFEqnqlTp6pZs2YKCgpSYmKiVq5c6fLnDACutHjzQb3z3XazwwAAAEAt4tZEwbJlyzR69Gj9+OOPWrBggQoLCzVo0CDl5eXZ2zzwwAP66quv9Mknn2jZsmXav3+/rr32Wvv64uJiDRkyRAUFBVqxYoXee+89zZgxQ5MmTbK32bFjh4YMGaIBAwZo9erVuv/++3X77bfr22+/tbf56KOPNHbsWD3xxBP65Zdf1KVLF6WkpOjgwYPufAkAoNqenUNRLwC1S2WjrnYczqukhYf5UKUAQM3iYxiem5ju0KFDioqK0rJly9SvXz/l5OSoYcOGmjVrlv70pz9JkjZv3qx27dopNTVVvXr10jfffKM//OEP2r9/v6KjoyVJ06ZN08MPP6xDhw4pICBADz/8sObMmaP169fb93XDDTcoOztb8+bNkyQlJibq4osv1htvvCFJKikpUXx8vO655x498sgjpWLNz89Xfn6+/ffc3FzFx8crJydHoaGhbnuNaptmj8yx/3/nc0NMjATwnGFvrVD6rmNVegzvDwC1yWUvLtX2Q+UnAxITIvTRnUkejKhiV0/9QWv2ZDss43MbgCvk5uYqLCzM49ehHq1RkJOTI0mKiIiQJKWnp6uwsFDJycn2Nm3btlWTJk2UmpoqSUpNTVWnTp3sSQJJSklJUW5urjZs2GBvc+42zrY5u42CggKlp6c7tLHZbEpOTra3Od/kyZMVFhZm/4mPj6/u0wcAAIATKrs/f5r6LQDgVh5LFJSUlOj+++/XJZdcoo4dO0qSMjMzFRAQoPDwcIe20dHRyszMtLc5N0lwdv3ZdRW1yc3N1alTp3T48GEVFxeX2ebsNs43YcIE5eTk2H/27NlzYU8cAAAANVZ+UXGp3gQA4O38PLWj0aNHa/369fr+++89tctqCQwMVGBgoNlh1Cr5RcUK9PM1OwzA7Uo8N+ILAGokK32Kvrdip9khAIDLeaRHwZgxY/T1119ryZIlaty4sX15TEyMCgoKlJ2d7dA+KytLMTEx9jbnz4Jw9vfK2oSGhio4OFiRkZHy9fUts83ZbcB8XDuhtli1O9vsEADA0rzplGDfsVNmhwAALufWRIFhGBozZow+++wzLV68WAkJCQ7ru3fvLn9/fy1atMi+LCMjQ7t371ZS0pkCNUlJSVq3bp3D7AQLFixQaGio2rdvb29z7jbOtjm7jYCAAHXv3t2hTUlJiRYtWmRvAwAAAAAA3Dz0YPTo0Zo1a5a++OIL1atXz14PICwsTMHBwQoLC9PIkSM1duxYRUREKDQ0VPfcc4+SkpLUq1cvSdKgQYPUvn173XTTTZoyZYoyMzM1ceJEjR492j404K677tIbb7yh8ePH67bbbtPixYv18ccfa86c3yvqjx07Vrfccot69Oihnj176pVXXlFeXp5uvfVWd74EAAAAqMF8mBoRQA3k1kTBW2+9JUnq37+/w/Lp06drxIgRkqSXX35ZNptNw4YNU35+vlJSUvTmm2/a2/r6+urrr7/W3XffraSkJNWpU0e33HKLnn76aXubhIQEzZkzRw888IBeffVVNW7cWO+8845SUlLsba6//nodOnRIkyZNUmZmprp27ap58+aVKnAIAAAAa2O4IgC4l1sTBYYTn+JBQUGaOnWqpk6dWm6bpk2bau7cuRVup3///lq1alWFbcaMGaMxY8ZUGhMAAAAAALWVx6ZHBAAAAGCuH7Ye1q3TV2pfNkUYAZSPRAEAAABQSwx/J01LMg7pkucWmx3KBTlVUKzvtxxWQVGJ2aEANZpbhx4AAAAArmZ41QSK1mUYhtcVY2w3aZ4kKbldlN655WKTowFqLnoUwDIoTASUr6SENwgAlKWo2Lw7y4Zh6P3UnWWuO5pX4NlgLsBXaw+YHUKV5JwstP9/4aaDFbQEUF0kCgDAC5wsLDY7BACwnMnfbFL7J77Vr1nHTdn/D1uPqLw87nPfbPJsMBfg3g9XOVV83Cqe/GqD2SEAtQaJApjm9HkXPl7W8w3wqJxThZU3AoBa5L/pe/X2su0qKCrR/32z2ZQYdh3NK3fdoeP5Hozkwi3e7D135tfsyXb4/fxzSQCuQ6IApjlVwIc7ap/th05c0OMmfLrOxZEAgPcyDOmhT9b8/vtv/6bvOqoPftxlieFa5kfgnPMvvr3J8dNFZocA1FgUMwQAD5r4+foLetyP2464OBIA8F5l5QEOHj+tYW+lSpIC/Gz6c494D0dlfd40zMAZFLUE3IceBbCMGvbdBZSp8AKLbnEyBADlS912RCu2/p5Q/dfy7brrP+k6kHPKxKis57EyktXLfj1kQiQArI5EAQAAALzK+XfGT503Vn3LwROatyFT4/+71pNhObDiDZBZabtLLVuzN0fr9+WYEA0AKyNRAMugmCFQPiuecAKAWTZnlp7lYH8ZvQf2HXNvjwIf1YyTl00Hcs0OoVKHT+Rr++Hzikfy3Qi4DYkCAPACnAsBqFUu4ENvyrwMV2wGFvXUVxtLLbt66g8mRALUDiQKAAAAAFja/uzSvUMO5Jw2IRKgdiBRANOcP9SArtVA+WpapWoA8AQzBwZ406e2N8UKwDNIFAAAAMBaXHSFzwWwk3ihAJyHRAFMc/4NUooZAuXjHA4Aqs7dvbGYutZ8h0/kmx0CUCORKAAAD7rQCtmMPABQq7joM6/EzZ+dj322vtx1DBlzrfK+PR/9dJ1H4wBqCxIFMA09CFAbcfcJAGqH77YcdqpdYXGJmyOpnDd/N205eMLsEIAaiUQBTFNY7PilROIdAAB4i1MFxdXexvj/rlGHJ77VgZzSFf3hHHpuAO5BogCmufjvC80OAfAqpwuLtZU7JwBgCUszDlZ7Gx//vFcFRSV6P3WXCyKqWH5R9RMbAGoPEgUA4EEXWqNAkq55c4WSX1rmkpNTAKgNvLlLvavtPVZ+r4XqfDcBqJlIFACAl9h0IFeS9L9f9pkcCQC4WQ25bs3MOe1UO7N7z3tzQsV7IwesjUQBTHHoOFPZAACActSQq7856w6YHQIAXBASBTDF/R+tKrXMm7PZgLNW7jxqdggAYHnbD+e5ZDvuvFPvzOxN3lJoz1Wvtxl2HTmpfdkUgwRcjUQBTPHzzmNmhwB4LW858QQAeIe3l203O4RKVfTNN3nuJo/FAdQWJAoAAAAAN6gor2u1pG9efpHZIVywwuISs0MAahwSBQAAAKiR3Hkt7kyhwoqGVVqtfsFB6kcBOAeJAljGmj05ZocAAABqkH3Zp/TSgl/dsu0nv9pYaZv92eUnE7YePOHKcKqtsh4Ou47k6a7/pGvt3mzPBFQFdCgAXI9EASzjlndXmh0C4FZH8wrMDgEAap3XFm0xbd8zVuwsd52Ph+eArO7e7nj/Z83bkKmr3vjBJfFU1f4KChYu3JTlwUiA2oFEASyjgHQwarinv9pgdggAAA87dDxf/1q+vVSy2JlZE1zpx+0Vz7qz91jFMwfsPHzSleFU2QEnhnoAcB0SBTBFfhFJAdQ+eyo5CQMA1Dy3v/eT/j53k7o9s8Bh+bl5AndPEZ1zslCPfrauwjYj3/upwvXc0AFqFxIFAAAAgJus2Wt+DabsU5UPfSssttYsDADMRaIAAAAAADyMaR1hZSQKAMDLcM8HAGCmAg8PIa2JF9Qf/7RHrR77Rgs2UogR1kSiAAA8JH3XMbNDAIBa6ZLnFuuHrYfNDsNr5ZwsdPi9ohkI3OGfy7d7dH/uNnXJVo3/31pJZ2aTKCnhFgCsh0QBPC775IVPEXe6sFhfr92vY0wzh1rM0ydoAODt9mWf0vB30swOw8G5l4Y7DuWZFoczKiuE6G5z1x2otI23XGwXFJXo+W8zHJa9+8MOk6IBykeiAB73wEerL/ixL3yboTGzVunGf/3ouoAAL7Nqd7bZIQAALpBhGNqXfUo5p36/Sz9/Y5alb4Kk7Thi6v59bZXPJTnHiWSCFZQYpRMa76Xu9HwgQCX8zA4Atc+SjEMX/Niv1u6XJG3OPO6qcAAAADyi2SNzyl03+6c9urt/Cw9GUxWOF+qevndv86k8UbDXS6YgXvZr6fPgMnIHgOnoUQAAAABUwenCYrND8CgnrtPdavWe7ErbGF5S6vfO/6SXWubp4pCAM0gUAAAAwDI+XLnb7BAqNe6/a80OwaMOHc93+N2w4C1wC4bktIPH8yl4DMtxa6Jg+fLl+uMf/6i4uDj5+Pjo888/d1hvGIYmTZqk2NhYBQcHKzk5WVu2bHFoc/ToUQ0fPlyhoaEKDw/XyJEjdeLECYc2a9euVd++fRUUFKT4+HhNmTKlVCyffPKJ2rZtq6CgIHXq1Elz5851+fMFgPI89Mkas0MAAK8w4VNzC+c546s1+80OwVTeck3+3ZZDGj3zFx0+kV95Y5Pd+K8f9dFPuy2ZhEHt5NZEQV5enrp06aKpU6eWuX7KlCl67bXXNG3aNKWlpalOnTpKSUnR6dOn7W2GDx+uDRs2aMGCBfr666+1fPlyjRo1yr4+NzdXgwYNUtOmTZWenq7nn39eTz75pP75z3/a26xYsUI33nijRo4cqVWrVmno0KEaOnSo1q9f774nD7fzluq2gCT9N32v2SEAAFCr3PTvlZqz7oCe/mqj2aFUqqCoRA//b50e/4LrE1iDWxMFV1xxhZ599lldc801pdYZhqFXXnlFEydO1NVXX63OnTvr/fff1/79++09DzZt2qR58+bpnXfeUWJiovr06aPXX39ds2fP1v79ZzK5M2fOVEFBgd5991116NBBN9xwg+6991699NJL9n29+uqrGjx4sMaNG6d27drpmWeeUbdu3fTGG2+48+nDzVK3m1uBFwAAoDZK32m9bvK/ZjkWus49/fusElaZVtiZ3gIf/Lhba/dmuz8YoBKm1SjYsWOHMjMzlZycbF8WFhamxMREpaamSpJSU1MVHh6uHj162NskJyfLZrMpLS3N3qZfv34KCAiwt0lJSVFGRoaOHTtmb3Pufs62ObufsuTn5ys3N9fhB9ZSUEzhFwAAAE8b/z/r1Wj4YrXjcJBl58yydbLAu4pPZjC7FyzAtERBZmamJCk6OtpheXR0tH1dZmamoqKiHNb7+fkpIiLCoU1Z2zh3H+W1Obu+LJMnT1ZYWJj9Jz4+vqpPERdgX1Uyvow8AAAAcIsN+3O0fl+O2WG4xMYD1rjh52z5AU5xYQXMelCOCRMmKCcnx/6zZ88es0OqESrrcjV57iYPRQIAAGAd/zdvs/KLzL3zfbZI4/HThRry2vf6w+vf6/g5Xfi9SdoO6w1RdToBQKYAFmBaoiAmJkaSlJWV5bA8KyvLvi4mJkYHDx50WF9UVKSjR486tClrG+fuo7w2Z9eXJTAwUKGhoQ4/qL68Srp+FTKcADVQba+ODQDO+mL1PrNDMNWMH3aauv97PlwlSer05Hz7sinzMswKp1o++NH602yWxyBTAAswLVGQkJCgmJgYLVq0yL4sNzdXaWlpSkpKkiQlJSUpOztb6enp9jaLFy9WSUmJEhMT7W2WL1+uwsLfs50LFixQmzZtVL9+fXubc/dzts3Z/cBz8vKLXLYtPkThLd5YvNXsEADAK9w3e7XZIZhq7zHzi+6d3/vzPz/uMimSqjti8WkQnZ36kBkSYQVuTRScOHFCq1ev1urVqyWdKWC4evVq7d69Wz4+Prr//vv17LPP6ssvv9S6det08803Ky4uTkOHDpUktWvXToMHD9Ydd9yhlStX6ocfftCYMWN0ww03KC4uTpL0l7/8RQEBARo5cqQ2bNigjz76SK+++qrGjh1rj+O+++7TvHnz9OKLL2rz5s168skn9fPPP2vMmDHufPooQ2VzyRcV88mImoekFgDAGT4+7tnu8HfSnG6bMGGue4LwgG2H8swOoUK7jp50qt3kbza7ORKgcn7u3PjPP/+sAQMG2H8/e/F+yy23aMaMGRo/frzy8vI0atQoZWdnq0+fPpo3b56CgoLsj5k5c6bGjBmjgQMHymazadiwYXrttdfs68PCwjR//nyNHj1a3bt3V2RkpCZNmqRRo0bZ2/Tu3VuzZs3SxIkT9eijj6pVq1b6/PPP1bFjR3c+fZThuy2HK1y/aPPBCtefi2wrAADwNG8r8Hf4RL4leip4grN37M3ywEernWqXc8o760KgZnFroqB///4VvmF9fHz09NNP6+mnny63TUREhGbNmlXhfjp37qzvvvuuwjbXXXedrrvuuooDBgA38JGbbhEBADzuSF6B2SFUycodR80OoVp+2ul8/AdyTkuSth484a5wquVgrrWHRgDnYtYDeIzVs7wAAACVcWfq9/3UXXrnu+0u3ebfZv7i0u15UnGJob9WYdhEVL1ASdLSjNI9VK1QMNtdQ0sAdyBRAI+5kG5vX67Zr6ve+F57fhvTdfjE71l88g4AAMDT3H2x9+ycTSou4SRHkmb/tFv5RVW4wP/t2Dw7p/R029N/2OGiqC6cjUwBvAiJAljavR+u0tq9OZr4+XpJ4osT+E1+UbE9gQYAQE20/NdDLtvW91uPuGxbnlBkgR4QqN1IFMBjqtMD4IQLp1UEPC0j67jLt3ntmyvUd8oS/bjdu058AKA8mb+NL7c66s54TlVf6wc+Wq03Fm8pc93BXHP/vtbtzdG+bOd71y7clOXGaIDKkSgAAC+0YX+uJOl/6XtNjgQAXGPwq8vNDsEyqOt0hq2KVypZufl6Yf6vZa7bnOn6pH1V3PVBepXanyosdlMk1nCqoGY/v5qARAEsa82ebLNDACzvk/S9lijQBADVlX3SO6aE88Qw8+qmCQqKSjT9hx2Wrf7vLG/vvXH4RL6O/TZLxukqXvjX5FxR6rYjajdpnp77ZrPZoaACJApgWVdP/cHsEACv8M535hdoAoDawhsuXf/13XY99dVGJb+0zOxQqscbXuxynC4sVo9nF+qiZxZoxbbDzHhwjr/P3ShJmrZsm8mRoCIkCgDAy1GnAAA8yBM9Cqp5N/mXXcdcE0gFTha4v37U/A2Zbt+Hu2SdUxPhL/9Kc5i5q7bz9p4itQWJAniF9F3H9O15XxZkZgEAQE1kVHPwgSfOkY64+cL3RH6RCou9t/+9qy+Gf9l9TC/Oz1B+EWP74Rl+ZgcAOOvO/1StCAwAAPAOTAXnWp4Y3+7ufTz91Qa3bn/V7mM6WVCsS1pGunU/F+r81/faN1dIkoL8fTV6QEsTInIdbvZ5B3oUwHL2ZZ/SJz/vMTsMwGvwhQvA2y3afNDsEJz26S/73L4PbypkdyK/SK8s/FW/ungq4O+3HHbp9s53zZsrNPydNB087p5pE9313bzFDVMuexqnLd6BHgWwnMtfWqaTTkyZwsURvEFVqxwDQG3kTZ+V//WCaWk9cY70y+5jKiwp0Xsrdur91F16ZeEWTb/1YvVv3VA+Lgggv8gzvUwO5uYrql6QR/blCl6UQyofJ/FegR4F8JjCEuc+8J1JEgDe4v/mMfUPAKDmuf+j1Rr44jKtPmc661un/6TFLuodciTP9TUQBr64VLPSdjssO37a/UUZL0R5CYEDOe7pAVGRHYfzlLqt8sLJJ/KL9M532/XklxtUXFIjUhq1GokCeMz4/641OwTA4+asPWB2CABgadsOndB9s1d7bH+nC4uVe7qwyo97e9k2tX38GzdEVFr1hx547o7t+b0H0nYc9di+q2rboTw9+tk6h2U3/utHvTg/w+X7qu5N8yMn8stcvnLHUZ3I92xyY8ALS3Xjv35URuZx5eUXKX3XUZWckwg4frpQd3+Qro5PfKtn52zSjBU7NWdd+ec/9CfwDiQK4DHpHpiqB7CSbzdk6uDxsr/oXYkvXADe7N4PV3l0f12emq/OT85XXhUvtiZ/s1mnC72l6KLn7uae/x1kuKDAwhIP16x4ffFWl2wn52Shsk8W6PCJfP1r+fZqbWvyN+X3SFyWcaha275QGw/k6M9vp2rYW6n66Oc9mvzNJjV7ZI7ueP9nfbPecXayQxWc/zDywDtQowAesXF/rtkhAB7n6ZNfAPBG2Serfne/Os6Ofd9y8IS6xod7dN/Oqu70iGZyRSHGW2f8VP2NVMAVyYzzFRWXqMvT8yVJraLqasvBEy7fx1mjZ/2iIZ2HuG375Vm48aA2/HZO/7/0vfr5t5uAP263bi8SXDgSBfCILDdUlHX1/LQAAKBm85aiid419MB123pt0RYtzXB/bwJ3zCpx8py/LXcmCTzt1Dm1wyoaTnC+ipIxnMF7B4YewCP4QADcxxXVpQGgNmj7+Dz7/79as9/ESCr27JyNyjlVqOW/HlJRsbWHO7jyG+ilBb/ql93ZLtxi2dzRX2P+hiw3bNV8Y2b9UuZyTj1qPhIFAOAmnpraCQBQdf/+fofZIZTrw5V71OWp+br53ZXq+OS3+npt1ZIaP2w97KbISjs/Wf3Zqn0e27dVHD6Rr4c+WWN2GG6xqJx6ETsO513wNrnB4R1IFACAGxRa/A4QAFiFmdcMOacqr49gGIbu+k+6B6Ip2+nCEo2Z5XzNm+ISQ6c8OMRi15GTDr8fySvQ/uxTHtv/hXB1jYIJn66rvJEXWlLBMJDDJyqevrKiYQoHLP73gTNIFMAjyByitjmZ7x3jYAHAbO4YL+6sLk/Nr/SicXPmcc3bkFlhGysp8fALeriMafyOnaz4ItJsrn6FzCjavfxX98988Hk1eoesKmcISWbOae3PcX3tMrgeiQJ4xJtLXDPtDOA1yI0BQKW+WXdA+0y+u1jZdXVxiffOQGAWM5M/znB1fGbcDyvvQtyV3PG00nYcccNW4Q4kCuARaTtcP23KtxsytffYycobAgAAS7p7ZtmF0jzJ4te0VWb1i/SynC4s1uRvNnlsf2VNP/nKwl91Ir/IYzFU18sLf1XqNvdddBuGoc9Xu77g532zV7t8m3APEgXwWrN/2qM+/7fE7DCAMjHaBgC8Q2VDD7zt87ysi2Cre+e77Xp72XaP7W/BxtIzFLyycIv+MbfqyYqSEkN7j5nTK+bGf/3otm1vO1T9KR7PHZby+ap9Gv/fmlnwsaYiUQAAXs7LzmEBwFK877K6YsfyKi/QaDXbq1FB/0KUVxzyQrrzz9/oPfUrqqKgqPrvjB7PLtT6fTnKPV2o+z9arY9/3uuCyOApJAoAwMuVN3URAKBylRX/8/GydOzI934yOwQVlxj6YvU+7T7i3BBRm0W6bRSXlOjg8aoV2tuX7b7CfOP/u0a3v/eTfs067rZ9lMdVh+QPr3+vzk/OL3f91CVb9dd30pRf5Nki0KcLizVl3mat2n3Mo/v1JiQKAMANrHHKAwDWtcQiSc7KxvRb5BrWqQupeesztcGECvzn+/SXvbpv9mr1e36JZqbt0p6jFScMfC3yIv+adUI9/75I6/flOP2YF77NcFs8H/+8Vws3HdSgl5e7bR/l8dQhef7bDH2/9bC+WOX6eggVeXPJVr25dJuueXOFR/frTUgUwO1cPVctAADwfrfOMP/Od2Xyi4r1807XF2S+EG0mztO89eXPTS9Jd32Q7qFoKnZuEevHPluv/i8srbC9RfIEdv/7xbku8ifyi3SqsGZOh/z45+s9uj9Pv46/ZlW/BkNNR6IAbjeUTB0AALCoiu5njP/vWj3+xQbPBVOJsmaJOHIiXze/u1If/7THhIjK5mtzvPKvbIrJT1ftc2c4VebsPa7Khq14QuI/Fqrn3xdqi4uHJ/y007Nd8j19Y9HGVXCleIngdmv2ZJsdAuBx5p86AACcUWIY5V6kfOGG6eGqo6wwn/82Q8t/PaTx/1vr+YDKkX3S+YKK6/flqKCoxI3RVN2MFTt1LK+g0nZW6AiRlZuvg8fzNXqW66Yanb/B8wUaPX3eZJW6GFZGogBuU1xi6No3f3D7fnYdyWN4AyDp16zjOpjrvqJKAFATLfv1kHr+Y5G+XGOtpICzjjhxQetp+7Kdny6wsvoFZpm+YqfZIVTJsSokZyoz6j+eH8LiyVP5khJDX6+teBgPSBTAjTbuz9UvFzDNTFVd+vxSTV2y1e37AarC07mrvcdOatDLy9XzH4s8u2MA8HJ/m/mLDh3P170frtLmzFzL33z4YrVjN32bl94Y3X3kpB74aHWZwymsoKSS4RKS5EQTj3HVn4FZswBMX7HDY/tavuWQx/blzUgUwG08OW7rhfm/6u1l2yyblQbcbf2+36tcW/0kFwCsavAr3+nf33vuguVC3Dd7tV6an6FvN2Rqx+E85eV7RzG986f46/f8En1msdoEVVYDv27NmgVgz9FT+sUDSYqSEkMjplu/kKoVkChAjTH5m83qO2WJ/pO60+xQUMut3HFUby3d5tF9PvP1Rvv/30/d5dF9A0BVHM0r0EVPlz+vutne9PDn94V4bfFW3fmfdA14Yam+33rY7HCcYsYUf+40Zd5m/fntVLPDsKsJQ+4zc07rZEGRW/ex8YD504d6CxIFqHGsVJ0YtdOf307VtGWePdE8dzzoa4u2eHTfAFAVby3d6tLx1K5mhUr2sL43l25ThotnGqiOrNx8s0Ootr/N/EXtJ32rUwXu6yXD+9t5JArgNh/9bN40PXn57s1GAuUpKja/cjNfggCszGoV7s+XfbJQ6buOUhzWjbxhiNwbFdS/GvfJGg9GUvucP0zFlZjtwHl+ZgeAmmtW2m7T9n3bjJ/ka/PRKzd0VVS9INPiQO0zdYn5XVatVFwJALzRsLes06W8JvKW76k1e7JVL8hP2acK1TQiRA3qBkqSPknfa3JkZSssLpG/r/ffBy52YyKJPIHzvP8vCShD2o6jWrHtiG78549mh4Ja5HRhsV5e+KvZYcgwDN3+3s/q//wS7TicZ3Y4AABIOlNP56edR1XsJZmCq6f+oMteXKZr31yhPv+3RAs3Zil911GzwypXq8e+0RuLL3z44XcWmQ3giS82eEWvk5qORAFqtG2HuEiC57y8wPwkgSTlni7Swk1Z2nnkpAa8sFQZmdYZQwmgdkvfdUzvUXC11vr39zt03bRUzUrzvr+BU4XFuv39ny3f2+SF+b9q/b4c7T5S9ZnAbvr3SjdEVHXr9uXoyzX7zQ6j1iNRAJczDENfr7XOm/vjn/Zo7Eer3V5FFbXboeP5env5drPDKNMd7/9sidoJAEBPP0jSk19trLwRLtgfXv9e/Z5fopISQ+98t12DX1muAzm/Fz0uKTG0dm+2peuF3Dd7tcbM+kWtHpur9F3HLriHwamCYqXvOqaSEkMFRSV60wJDRL2Fj0G/Dqfk5uYqLCxMOTk5Cg0NNTscy8o9Xajr3kq1VBXYs0b0bqYnr+pgdhiooZo9MsfsECoU5G/TPZe10her9+mey1qpS+Nw1a/jr3pB/maHBqCWWLnjqKWmkwNqk5jQIH37QD+FBfvrzaVbNWVehq65qJEOn8hXw7qBuqZbI8v0KChL31aReu/Wnpq/MVPfbz2sA9mn9dZfu2tzZq6iQ4MUHRqk4hJDK3cc1ZG8fA3pFKs7/5Ou+RuzKt32zueGeOAZXDizrkNrXaJg6tSpev7555WZmakuXbro9ddfV8+ePSt9HIkC5zz22TrNNLGIYWWWPtRf8REhStt+RG1i6qlB3UAdOZGv/dmn1SamngL86GSDqpv8zSa9vcyavQkqs+aJQQoL/j1ZYBiGXlm4RS2i6uqqLnEmRgagpsgvKta89Zm6b/Zqs0MBarUAP5v6t27o1MWzFb14XRc9WM6MEwPbRum7LYdVcAE9KEkUlK1WJQo++ugj3XzzzZo2bZoSExP1yiuv6JNPPlFGRoaioqIqfCyJgt9lnyzQnHUHNKxbYy379ZCO5hVowqfrzA7LJfq2itR3Ww7rqi5x2n30pMaltFHPhAjN/HGXfH1tiggJUPu4UDVrEKKiEkM2Hx/52nzOdGcqLlGQv68k6ciJfM3fmKWIOgEa1D5ahiHlFRSpToCfbLbfy60WlxhK235E3ZrWtz+2IsUlhnxtPioqLlHW8Xw1Cg+u0vMrLC6Rn81HPpR8rVBefpHqBJaeFMYwDPn4+MgwDB3PL1Kwv68mfrbe1KlA3Sk8xF/Z58x1nj4xWW8t3aYbesbL39emAD+bPl+1X31bRaqwuETfbTmsm3o1VXCAr4L8fXW6sFi+Nh/5+9pUUFSi4hJDwQG+Kikx5OOjGv13uPNwnuqHBCgspPo9NlbtPqZ2saHal31KsWFBCgkwZ8IiwzCUX1Ti1GdVdfdjhb+NgqISHcg5paYN6kg601W3xDDk52tTzslC1Qty/DyvKO78omIF+vlq7d5s5ReV6OJmEfbH/LL7mLo0DpefGyqVe/q1PLu/7JMFqhPop9OFxXrqq43y97Xpw5XWvYkAoHYjUVC2WpUoSExM1MUXX6w33nhDklRSUqL4+Hjdc889euSRRxza5ufnKz8/3/57bm6u4uPjLZ8omL1yt77dkKm8/GJtO3RCR/IKJEmNwoMV6GfT9nIqoIf8dmJfP8SfAoC1jJ/NR4F+NuUVFNuX1Qv00/H8MzUdWkXV1cmCYu3LPlXeJioUHxGsPUcrfmxYsL9yThVW2MbVOjYKVaCfr9J3HfPofuFaFzerr592Vu8Yhgb5Kfd06Rom9YL8dLyM5WU59z1jdX42HxV5ScXx80XWDdDhE2e+16LqBerg8d+/p20+padcC/SzKd/CY3ABAOYjUVA2c25LmKCgoEDp6emaMGGCfZnNZlNycrJSU0uPl5s8ebKeeuopT4boEtsP52lJRumpTSq7yDtZUKyTBcU6+ltiAbVHUYmhonOSBJIcLni2HDxRre1XliSQ5PEkgSSt35fr8X3C9aqbJJBUZpJAktNJAklekySQ5LVJAkn2JIEkhySBVPa87CQJAAC4MLUmUXD48GEVFxcrOjraYXl0dLQ2b95cqv2ECRM0duxY++9nexRY3RUdY9SyYV3VDfLT0oyDyszN14HsU0psHqHmkXU1b32mVu78ff7XHk3rq2VUXbWNqafth/MUHRqkiDoBmjJvs5o2qKMAX5tW7jyq0CA/+dp81KRBHa3Zk23eE6zhejaLcDg+57q+R7z2ZZ/S91sP6/L20aoX6KdPV+1TvUA/DekcKx8f6cOVZ7rA1w3004n8IiUmROj46SIlRNbRnHUHdH9yK72ycIvDHcX7BrbSnHUH1LtFAy3adFApHWIUFRqotO1H1KBuoFpH11VefrEWbsrSqYJibT+cp25NwrX32CkdPJ6vq7vGqX5IgLYfztPyX39PUvnafHR7nwTFhgXps1X7FB8RolW7s9W4frDW7M1Wj6YROnwiX/uyT6ldbKgSGtTRhgM5Wr8vV5e1jdKvWce199gptY8NVfem9bV6T7b2Hjupjo3CVGIYyj1VpHX7ctSzWYR2HslTRJ0zMZyt4PuXxCZatzdH6/blaFS/5mpQJ0CnCouVlZuvzJxT6tEsQk0bhOj91F1aueOoHry8tT5btU/bD+fpqi5xOpFfpMWbDyqlQ7R2HTmp7YfyHMa9XdkpRnPXZbrrTwHnCfC1aXivJvpqzQEdPnHmAvHGnk2U1KKB9hw9qee/zVB0aKCiQ4N07GSB9hw9pX6tG+qi+HBt2J+jhZsO2rd1bi+Xy9tH62hegdJ3HdOg9tGavzFLvVs0UNMGddS0QYga1w/WE19sUKCfTQ3qBioj67gC/Wy6rnu8lmYc1PbDeerVPEJ9WzXUzsN5+iR9r30/owe00Ber98vm46Nh3Rpr3b5sLdx0UH/u0Vhr9uQo6/hpxYUFa+OBXA1sG6XTRcU6mleoS1o00Dvf7yj1GrRoWKfCHl9JzRso51ShNh7IVduYetpcxrSYAb42XdutkWb/tEe+Nh8VlxiqE+CrwuIzw6cubx+trNzT2pJ1Qld1idOCTVkOCeT6If46drLsxF7zyDrl9lq7qVdTbTt0QruOnFSDugE6VVCs3UdPKjjA12F4S0VG9G6mzJzT+n7rYd3dv4XyC4s1+6c9Cg/x169ZZxKafVpGqnnDOnr/t+n3ru3WSK2i6umtpVtLJYSiQwOVlZuv/m0aqlVUXf3rux0Oy6vKmd5TzrqoSbhW7c52ybbOCvC1lRq7e/5zPft3M6pfc/3zAmdxuaxtlLo3ra/nv82oVrwAAHPVmqEH+/fvV6NGjbRixQolJSXZl48fP17Lli1TWlpahY+nRkHlrF71XZL9xLhpgxC9ObybGoUH689vp9pPMtMeHaioeoH6ZXe2WkfXVZC/r70Owdl6AonNG8jX5tyYz5xThQ6F4lDzFBaX6Pq3U/WLi0/qPWlknwQV/1ZzY866/crKzderN3RVzqlCBfn56uWFv+qdW3qobUyow9++YRgyDDmM0waAcxmGoX99t12/Zp3Qf89JpAGAVTD0oGy1JlFQUFCgkJAQ/fe//9XQoUPty2+55RZlZ2friy++qPDxJAoqtzkzV5k5pzVi+k9mh1KmekF+Sp94OTMbwC28IVF2eftoLTin0rHVvxgB1Bw5pwqV/NIyHTpe9d4aAFzjzn7Nldg8Qos2HVRSiwbys/kopUOM8gqKVSfAVwkT5podYoWWjeuv+PohKjYM7TpyUnd/kK5dR04q7dGBql8nQCcLijQrbbdeW7Sl3F5kZbH6+RCJAg9ITExUz5499frrr0s6U8ywSZMmGjNmTKlihucjUeA8q10wTfpDe7WKrquLm0W4vVo3aq/DJ/LV49mFZodRrhG9m+nxP7TXU19t0Pupu/Td+AGKjwgxOywAtcjZmXesfjECVOTey1rqtcVbzQ7DKXf0TdCjV7bTjsN5io8IkX8ls6tY7Rz+XLNH9VKv5g0clhUWl6igqKTMmaqkM7PVbM48rtbRdeXna5NhGLptxk+l6rmRKChbralRIEljx47VLbfcoh49eqhnz5565ZVXlJeXp1tvvdXs0OBGt/VJMDsE1ALBFk5CpT06UNGhQZKkp6/uqKev7mhyRABqo7MXKR3iQrVhPwVl4X1mj+ql3UdOmh2G0+7u31I+Pj5q3rCuU+1fvaGr7pu92r1BOelsvS3pzOxt5ycJpDOfKRUlP2w2H7WP+/3C2sfHRw3rBbo+2BqqVvXBvv766/XCCy9o0qRJ6tq1q1avXq158+aVKnCI6pk9qpcublbf7DAAj7Jyb5WzSQIAsIK3b+pudggw0aWtG+qvvZqYHYZTPv1bb/v/v394gHo1b6A/dIlVu9hQDevWWCN6NzMvuDK8Obyb+raKlCQN7RqniDoBVXr81V0buSOsKhvQpqFWTbpcl7ZuKMm1N/2u6mKN5+gNalWiQJLGjBmjXbt2KT8/X2lpaUpMTDQ7pBqnV/MG+uSu3pU3BGoQX5uP/pLoHSc+AGCmxvVDFFnXunf1JlzRVn/u0VhtY+qZHUqN0ig8WBOuaKvXbrhIbWK8YxjvRfHh+nLMJUqfmKzG9c8M1wsJ8NM39/XVi3/uopAAa90kCPSz6Y2/dNOrN3TV36/pdEHbePKP7V0cVdV1a1Jf/r42vX1Td/3v7t661YUJmT6tIvXVmD4Oy04WeM8Ux55U6xIFqB1uSWoqSWof6x1fRKgZ/j7UOl36X76+i7rEh+v1Gy8yOxQAKGX2KOveqAny99WUP3XRzNutG6M3eu+2nrrz0hYKC/FXo3Dv6Onm4+Ojzo3D1aCcxJaPBSf9CQv219VdG5U7br8yIy4xd8juLUlNdUe/5pLOvBe7N63v8tmVOjUOc/g9yM9aCR+rqFU1CuBZ5c3j7W4PXt5ad/Rrru7NItS3ZaTH94/ay8ciZwzrnhykekH+uuaixmaHAgBlahll3bv1Z+t8l3dxiAvTMur3cfID2kTpoUGtNXddpjYe8N56FT6yxvf+Wa46DXnsynb6+9xNrtlYFSRE1tFTJtRRYprnstGjAG4z7a+eHYP4f8M6aedzQ3TPwFYK8vfVVV3iVL+KY7OAmqBekL/ZIQCA1yrxovnAdky+0uwQLoiPj4/GXNZKX465xOxQqsUi9wdcrt9vtQFQu5EogNs0i6zj0elGrJbVRe1ktfGKAICqOffi79ZLmpkWR3naxTpWcfcG5YXp52tTp0ZhZa9ElfnZXHNpZ9afVXK7KHN2jDKRKECN0Y56BLCAd0dcbHYIAIBq6Nw43P7/+5NbmxdIOYb/Vji3R9OaMcMU3b5d5xIvHnL73LWd9OCgNmaHgXNQowA1xvmFSQAzJCZE6IaL47X9UJ5W7jxqdjgAACfEhQXp/ZE9tevISXU/5wLcijfsL23dUCseucyr5oP3qyAZ8Ny1nXTFq995MBrneGMxS18XJV3M+LO/oSczR1kNPQrgdld0jDE7BMBjfHx89Nywznrgcs/fhYqsG6CHBlnv7hcAlGXRg5eaHYKDllH1NLBdtNlhVCo+IkRx4cHy9z1zGv/XXta7wAry//0So0GdAL1/W/kX3VbsEbpm0iCn7s5b4e/lo1G9lJgQoX/d3MNl2wzyd90wygec6JUz6rdZDjzp7LCiszOloTR6FMDtXriui9bsydb+nNNmhwJ4TLPIEI/u78sxl6hTozCvGa8KAC0a1q28kcn8XTTm21Xu6Ft66ron/9hBf+4Rr6ve+MGEiMr24R299PgX6/X4kPbqmRDhNd9NX43pIx8fKSzEuaLAXePD3RtQJR7/Q3slNm+gj+5Mcul24yNcdw7ztwEt1LxhHd3z4apy25iRKJg4pL2uuagRU6lXwFqffqiR6gT66Z8uzHKe7+qucfpu/AC3bR+4ELFhwbrzUs998XVuHO41J2IA4C2CvaBArZ+vTZ0bhyss2Doz3lzUpL6+vqevEps38JrvptEDWqhT4zB1rGJxxYTIOm6KqHIjejdz27Y3Pp3iku34SOpyTt2P8tp4mq/NR50bh8vPl8vh8vDKwCOq+qFbFddfHO/SzCfgKhfF14xCUwBQ0w3uGFvuuht7xnswkgv32JXtzA7hglVUwwDlc1VNgrKEBLim47mvzafSHhrekkyqbUgUwOsxLSKsiu89ALC+l6/vovGDK6q2bp0P85p6QeXqrvMX4kLPJx//g/sSNB/e0UsTh3hvAkg68zcbFuyvF6/roiGdyk7I1cy/au9HogAeMy7FPVOetIyy/hhH1E588QGA9V1zUeNKircZHoulMo3rB5e7zptmQThf96b1TR9Galzgcb6sbbQub++eooZJLRro9r7Nte7JQW7ZvicN695YU4d3K3NdDc1/eT0SBfB63vzFiJqtR7MIs0MAANQQd/ZrrhsrmEKuf5uGGj2ghQcjqlls1bhaffuv3R1+/0Pn8oeyXIh6QdapP1EVdzpRpPCiJtaqr4HfkSgAADeJqBNgdggAYGnv39bT7BCcYI3bnROubGefErEsPj4+GpfS1oMR1SzVOco2m4+SLTBVotU8OKjy3sSf3t27xg6p8XYkCuAxw7o1dvk2/3uX+WPaAADAhenXuqE++1tvs8OwnI/vTKpwmIGVzbo9sdrbiAsLckEk5evXumGpZdW9WH1zeDdd3TVOz/+pc7W2YyUzq3ksA/wqv9QkSWBdJArgMTEu/tC/tHVDunYDAODlWli81lDdQM9PkdgzIUJLHuqvnhdwnjOyT4IbInLehR7PQP/fL0u+GNPHVeGU6cqOMaWW1QuqXpX/AD+bXr3hIl3XI16xbk50eMolLSMdfp/6l266qVdTSdJ13Su+AVhesueytlGuCQ5uR6IAXosEJAAA3i+kwkKC7uXMXfsxA1rZL9i7xoerfWyou8OSJPn72nTHb2O8L2oS7vTjHv9DezdF5F5R9YL00KDWeuzKdm6vP1XWOeRff7sAdoV7BrZy2bbMNuPWi+3/H9I5VpP+2F4f35mkv1/TqcLH3Xkp9TK8nWsmyAQAAAAugJ+vTX/sEqev1uz36H6v6hKnKU50Ew8L8dfHvw11NAxDo/6Tro0Hct0dniTp8vbRWjj2UsVHeOcwhKoac5l7L7DrBPjaky/nigkNqmTmi6oJdUHxwUbhFR/zJhEh1d6HM87fj7+vTT0TKu/pcnNS2YkXw7DOLCKoGD0K4LXoUABv0Dra2l1qAcAK/n5NR4/vs1mDkCpfHJoxnrplVF0F+pnX66ImeX9kou5Pbm12GC7xwcjq14JwRvOGdXXbJQl6aFDp1+2ZqzuU+7jy3ivuTgbBdUgUwGtR/ATeYPYoCm4CQGVccQe2yjiPqLYrO5Ue62/lV/XsIW8b4/7hI9XtBWKr4CptSOdYNWngmR4FkjTpj+3LvMBv0qBOme2jQ8sfOtK9aX2XxQX3IlEAAG4UUSdAKx65zOwwAADnsfIFrTe4sWe83hzeXS0annexaOEX9mxoXeLDHZe7IeZ+rUrPrFAVPhW8kC/8qUu1tu1uFcUO70GiAB516yXNXLYtPoLgLZyZHqg6Zt3hme6HAOBOE4e08+j+rNqhYFxK5XPPW8HZXiAfjuqlBy/3vu7839zX1/7/vw1o6fLthwZXr5eMrZy/z5m3Jyo4wBpDUcqrN2DV9xaqhkQBPOpCpvkBULHeLSIrbwQAFtfSw9MkXuhdT3deAzUKD9ZoN1y0usPZi+uoekEunTHAU9rFhmrbP67U4gcv1V8Tm7h8+3f3r17Vf1t5mQIvcH8ydQhqAhIF8ChXZhjJVsJb+PLHCgCVurR19bpqV1WbmHoe3Z8zXPV10TzyzHCAyirnV0fYOXfM/Xx/DzzA17qXF+fXt/K1+ah5w7puqXtV3bob3nDmEFn391oE747oIenM38X1F7s+8QLPY3pEeDFv+AgFpPp1AswOAQAsz8fHR+1jQ90+9eA/b+qurNzTSukQ7db9XIiLmrim0Nt7t/XUP5dv1+19E3Tp80tdss2K1Avy1wPJrVVsGAoPse53njedOZaXvIhzY/Knqjo2CtOjV7ZV4/ohuqxttDY/M1j+TiSKbr2kmab/sFMP1JAZKGoqEgUA4AHjUtro+W8zzA4DACzt6as76E/TUt26j0EdSlfqrwp3dhKb9If2LtlOfESInhnq2Skn7/OC7ube1MHv/JEH/7u7tw6fyFdCZNkzDZhlVL/fh1g4O93o40Pa66+9mtp7vsCarNs3CJDUp2WkNjyVUuY6b/qwBwAAlavt3+2hwdzDwxlP/rGDw+/dm9ZXSjWTXFZhs/mohZuGfMB1SBTAwyr+QLi8vWM3wA9uT1SdQL404f3KqwwMAABKe3N4N7NDMFXvlhQqhrlIFMBSbu3dTHPv7asrO8Vo4dhL7cvHljHtDjlIeJMSN+UJxg/2jmm0AACVY/75313ZKdbl2/T0zBqAN+NWLSynfVyo3hze3WEZxeDg7To1CnPLdns1b+CW7QIAPM+LZ8TzCiEBXPoAzqJHAbxCWd+bDGuCN+nfxrPTfgEAvI8vmYIapUNcqP3/13ZrZGIkQNWRKIBHVXpxX4XvR7rnwZu4q2APpQ8AwLPcef5Bcbea5Z7Lfp8JopuLpr4EPIVEAQAAAAC4UVXy+kH+XKLBfPwVwqNcmScn6Q4AAABv0D42tPJGv7FxkgsLIFEAj7q4WUSF6xlOgJpseGITs0MAAItz73lAo/Bgt24f1nXNRebWCOjetL76ODnlIYkCWAGJAniUK2cv4DMU3qZJRIjZIQBArTWkc6yWjutvdhgwSUqHaLND0LDuziUrOMeFFZAogFco6wOT3gcAAMBZV3aMlb9v9U99uYiDu9GjAFZAogCWUt7nor+NP1V4v6YN6rhhq0x7AADOuLJTjNkhmKJVVF2zQ8BvnL3Jdeelzd0cCVA5rr7gFa7qGldqWdf4cM8HAlSDFbo9AkBtVVunHpx7X1+XbzM+whtrPZh//J39E7yrXwv3BgI4wc/sAIBzlff5GeTvW2rZiEuauTUWwNXccZJq0KEAADzK2/INrhhucb7OjcJdvk13M+O49WkVqWB/X3WIc37GA0my2bzsjww1ktt6FPz9739X7969FRISovDw8DLb7N69W0OGDFFISIiioqI0btw4FRUVObRZunSpunXrpsDAQLVs2VIzZswotZ2pU6eqWbNmCgoKUmJiolauXOmw/vTp0xo9erQaNGigunXratiwYcrKynLVU4VJ3PHFBwAAYAZmZHCvhvUCPb7PuoF+WvPEIH1yV5LH9w1Ul9uutAoKCnTdddfp7rvvLnN9cXGxhgwZooKCAq1YsULvvfeeZsyYoUmTJtnb7NixQ0OGDNGAAQO0evVq3X///br99tv17bff2tt89NFHGjt2rJ544gn98ssv6tKli1JSUnTw4EF7mwceeEBfffWVPvnkEy1btkz79+/Xtdde666nDjdhqAEAADWbu+76dmxUtTu6FRncMdZl2zrXO7f0cMt23cHwUH2c/m0aumxb3ZrUd9m2qiLAz1Zrh73Au7ktUfDUU0/pgQceUKdOncpcP3/+fG3cuFEffPCBunbtqiuuuELPPPOMpk6dqoKCAknStGnTlJCQoBdffFHt2rXTmDFj9Kc//Ukvv/yyfTsvvfSS7rjjDt16661q3769pk2bppCQEL377ruSpJycHP373//WSy+9pMsuu0zdu3fX9OnTtWLFCv3444/uevq4QBV9kF7bzdz5bwEAgHu5YzhVw3qBevsm112E/7FzrEKDXD96t2kDptA93xt/6aZpf+1mdhhArWRa3+3U1FR16tRJ0dG/F/dKSUlRbm6uNmzYYG+TnJzs8LiUlBSlpqZKOtNrIT093aGNzWZTcnKyvU16eroKCwsd2rRt21ZNmjSxtylLfn6+cnNzHX4AAADgXZ4d2tGl3fp9fHzUMyHCZduzb9cCxfaspm6gn9t6cJjBmZ4FzUgYwSJMSxRkZmY6JAkk2X/PzMyssE1ubq5OnTqlw4cPq7i4uMw2524jICCgVJ2Ec9uUZfLkyQoLC7P/xMfHX9DzBAB3opYhAFSMy2/Xo5Cu+7hjlgrgQlQpUfDII4/Ix8enwp/Nmze7K1aPmjBhgnJycuw/e/bsMTukWqGiRGv9kADPBQIAADyuNg/l9qbn7k2xepOJQ9opJIBJ6WANVfpLfPDBBzVixIgK2zRv3typbcXExJSaneDsTAQxMTH2f8+fnSArK0uhoaEKDg6Wr6+vfH19y2xz7jYKCgqUnZ3t0Kvg3DZlCQwMVGCg56uj1gYRdQJ0NK+gyo+7slOsFm8+qM9W7dOd/Zz7OwNqOu7qAEDFWkbVNTuEGodhEu5xe1/Ob2EdVepR0LBhQ7Vt27bCn4AA5+76JiUlad26dQ6zEyxYsEChoaFq3769vc2iRYscHrdgwQIlJZ2ZYiQgIEDdu3d3aFNSUqJFixbZ23Tv3l3+/v4ObTIyMrR79257G3jW6zdedEGP87X56OXru2rnc0M04cp2Lo4K8IyrusRVexvtY3+v3h1lwnRPAOBNmjckUXDvZS1du0HyBBeElw3exG19W3bv3q2jR49q9+7dKi4u1urVqyVJLVu2VN26dTVo0CC1b99eN910k6ZMmaLMzExNnDhRo0ePtt/Jv+uuu/TGG29o/Pjxuu2227R48WJ9/PHHmjNnjn0/Y8eO1S233KIePXqoZ8+eeuWVV5SXl6dbb71VkhQWFqaRI0dq7NixioiIUGhoqO655x4lJSWpV69e7nr6qICvrfyPST5AUdN1jQ/Xl2v2X/DjR/ZJ0Mg+Cdp5OE+H8wrULLKOC6MDANREYwe10WuLt7pse952vnZ11+on6YHaxm2JgkmTJum9996z/37RRWfuIi9ZskT9+/eXr6+vvv76a919991KSkpSnTp1dMstt+jpp5+2PyYhIUFz5szRAw88oFdffVWNGzfWO++8o5SUFHub66+/XocOHdKkSZOUmZmprl27at68eQ4FDl9++WXZbDYNGzZM+fn5SklJ0Ztvvumup45q6NgozOwQALeq7rjOx/9wpsdVnAsreAMAUBV9W0WaHUKVXNY2yuwQAK/jtkTBjBkzNGPGjArbNG3aVHPnzq2wTf/+/bVq1aoK24wZM0Zjxowpd31QUJCmTp2qqVOnVrgdmC/I39fsEAC3oqYAAHg/d3yWe1OBwOu6W382sF7NIxQbFqyfdx3VoPbl1yXzpH6tGpa7rnlDegjCWiirCQAAAMBptgqGkVpFnQA/vXx9V5WUGJaJNyzEXysfG6ief19Uat1Ho6idBmupUjFDwBUa16fLNAAAKM0al3PmYCYB13ryqg6SrJfUiKoXVGpZvSA/NaQ4MSyGRAE8rnH9EM28PVG390kwOxQAAGAhjM6yjrGXtzY7hGqJjwgxOwSnpT060OwQgFIYegBTXNIyUoeO55sdBgAAAMrQKoppJT3htksSFBLAJRmshx4FMI3BfQMAAHAOV3cSH9I51sVbPKNFNS6i+7Qse8YAqxUzHNguWjf2tH7RwvPdekkzbX5msNlhVKhnQoTZIQCVIlEAAACAGqlX8wZu2e59A1td8GM/uD1RXePDXReMmwT42TR6QEuzw6iSNZMG6Yk/drD8LFozb080OwSgUiQKYBqK9gBVM+VPnc0OAQAgqU6gn3o1v/C7wkH+pU/B3X1WZLUeC1XRuXFYpW0uaxulsBB/D0RTff6+XILB+vgrhWnqBjIeC6iKQD8+sgHUbE0b1I655H1NqMS/6emqd8f3sUh2YfqIiytt864TbayoecPa8TcP78NZJ0xzWdsos0MAPI6/ewAoX0SdAC0ce6nZYbjd01d39Pg+L6Q7flxY6an8zNCgbs2bOvB/dydp7OWtdcPF3lcHArUDiQKYxmbz0Ts39zA7DMCjmkVy5wAAKtKyFlTbb9Gw9HO0yt37c1kxppqie9MI3TuwlfwYhgCL4i8TpkpuH212CAAAAACAc5AoAAAAAExmpXv3D17e2v7/12+8yMRIAJiFanIAAACAB7x6Q1ezQ6jQ8nEDtG5fjq7sFGNf9scucWpYL1A3/PNHEyMD4GkkCgAAAAAPiKgTYHYI5erYKFRNGoSoSYOQUut6NW9gQkQAzMTQAwDwEhSVAoCa49+3OBZ0NvsjvldCxcmA9rGhHooEgBWQKAAAAICl3NizidkhuF3X+HCH3w3DnDjOqixRMeO2ixXoZ9PQrnGeCQiAqRh6AMu4Oamp2SEAAAALcNnddbOvvivga/v9SV7brZFsNmv3GouqF6T1T6XIn+n8gFqBRAEso3vT+maHAAAA4DaxYcH2/4eHBOj6HvEyZGjKn7qYGJXzSBIAtQeJAgAAANRMZg/8P0/LqLoOv//fnzqbFAkAVIy0ICyjbiB5K6Ai1jrdBQD3cdnnnYWHHlgNBXMBnIsrM5hu0h/aa/3+HA1oE2V2KIClNW9Yx+wQAAA1VOP6wZU3sqiFYy81OwSgxiFRANPd1ifB7BAAr9AhLszsEADAI1zWD4C75E7z5pkmzh/SAaD6GHoAAAAA1HIUKgRwLj4RAMDDxqW0MTsEAICHXdaWIZYAvAeJAgDwsEA/PnoBwNv1TGjgdNsfJwzUv27u4cZoar4RvZuZHQJQq3C2CgAAAFTR6AEtnG4bExYkX5t16yVEhwaaHUKlBrajRwbgSSQKAAAAUCNd2THGbdsO9PNV88iaMRtNZF3rJwrKQ08DwD1IFAAAAKBGauDFF8BwToe4ULNDAGokEgUAAACAm4zq19zsEACgykgUAAAAAG4SVc/6vRp8rFs+AYBJ/MwOAAAAAHClyLqB+ktiE7PDkCTdlNTU7BAqZRhmR1C5Zg1qRj0IwFuQKAAAAECN8tNjA+VjgdvkfVtFKtDP1+wwaoT4iBCzQwBqFYYeAAAAoEaxQpJAkp4b1tnsEJxikZfrgljlWAM1DYkCAPCw9rFUaAaA2qBReLDZITjo1iS8zOWtoup5NhAXGuzGKTCB2oxEAQB4WO+WkWaHAACohT65q3eZy5/4Y3sPR+IaL1zXRXUDGUkNuAOJAgAwwdf39NG9A1tV2OZmLyiABQAo2zNXdzA7hFJ8bWV30w8PCfBwJK5x7UWNzA4BqLFIFACACTo2CtPYy1s73X5wB7pWAoA3aenF3fmt6vzki62cxAeA6iNRAABeIDrU+vNwA4CreMN0fZL0lAV7DdRkgf7MIAF4CokCADBRoF/5H8PcJwEAa+vbqmG56yjGD8CbkSgAABMtHHupU+1iLVY5GwCsyirF7ep76bh/AJDcmCjYuXOnRo4cqYSEBAUHB6tFixZ64oknVFBQ4NBu7dq16tu3r4KCghQfH68pU6aU2tYnn3yitm3bKigoSJ06ddLcuXMd1huGoUmTJik2NlbBwcFKTk7Wli1bHNocPXpUw4cPV2hoqMLDwzVy5EidOHHC9U8cAKqgohPasJAATb/1Yt3Uq6lG9G7muaAAwGTVuRt/R9/mrgukGtrEUKPA1Wx00wA8xm2Jgs2bN6ukpERvv/22NmzYoJdfflnTpk3To48+am+Tm5urQYMGqWnTpkpPT9fzzz+vJ598Uv/85z/tbVasWKEbb7xRI0eO1KpVqzR06FANHTpU69evt7eZMmWKXnvtNU2bNk1paWmqU6eOUlJSdPr0aXub4cOHa8OGDVqwYIG+/vprLV++XKNGjXLX0weAC/bK9V11efto3dmvuQa0idIzQzsqiHGZAOA17rzUGskKZ/ytfwuzQ3DakE6xZocA1BpuSxQMHjxY06dP16BBg9S8eXNdddVVeuihh/Tpp5/a28ycOVMFBQV699131aFDB91www2699579dJLL9nbvPrqqxo8eLDGjRundu3a6ZlnnlG3bt30xhtvSDrTm+CVV17RxIkTdfXVV6tz5856//33tX//fn3++eeSpE2bNmnevHl65513lJiYqD59+uj111/X7NmztX//fne9BABwQYZe1Ej/urmH6lik+ywAoOaIj3AcyuZNPdaCA3wrnVoYgGt4tEZBTk6OIiIi7L+npqaqX79+Cgj4fQxXSkqKMjIydOzYMXub5ORkh+2kpKQoNTVVkrRjxw5lZmY6tAkLC1NiYqK9TWpqqsLDw9WjRw97m+TkZNlsNqWlpZUZa35+vnJzcx1+AAAA4H7nznpQUdHXstA7vWK+vEAAnOCxRMHWrVv1+uuv684777Qvy8zMVHR0tEO7s79nZmZW2Obc9ec+rrw2UVFRDuv9/PwUERFhb3O+yZMnKywszP4THx9fpecLAM4IDfY3OwQAsLSMZ68wOwRYSM9mEZU3AlBtVU4UPPLII/Lx8anwZ/PmzQ6P2bdvnwYPHqzrrrtOd9xxh8uCd6cJEyYoJyfH/rNnzx6zQwJQA/nauLMDAK7Ur3X5UxbC+/VpFan3buup7x8eYHYoQI1W5QGwDz74oEaMGFFhm+bNfy/gsn//fg0YMEC9e/d2KFIoSTExMcrKynJYdvb3mJiYCtucu/7sstjYWIc2Xbt2tbc5ePCgwzaKiop09OhR++PPFxgYqMDAwAqfJwAAAKyla3y42SF4FaPyJpZzKckgwO2q3KOgYcOGatu2bYU/Z2sO7Nu3T/3791f37t01ffp02WyOu0tKStLy5ctVWFhoX7ZgwQK1adNG9evXt7dZtGiRw+MWLFigpKQkSVJCQoJiYmIc2uTm5iotLc3eJikpSdnZ2UpPT7e3Wbx4sUpKSpSYmFjVlwAAAAAAgBrLbTUKziYJmjRpohdeeEGHDh1SZmamQ02Av/zlLwoICNDIkSO1YcMGffTRR3r11Vc1duxYe5v77rtP8+bN04svvqjNmzfrySef1M8//6wxY8ZIknx8fHT//ffr2Wef1Zdffql169bp5ptvVlxcnIYOHSpJateunQYPHqw77rhDK1eu1A8//KAxY8bohhtuUFxcnLteAgAAANRCPrLusLLuTR3H+Fs3UgBmctvcWwsWLNDWrVu1detWNW7c2GGd8Vsp27CwMM2fP1+jR49W9+7dFRkZqUmTJmnUqFH2tr1799asWbM0ceJEPfroo2rVqpU+//xzdezY0d5m/PjxysvL06hRo5Sdna0+ffpo3rx5CgoKsreZOXOmxowZo4EDB8pms2nYsGF67bXX3PX0AQAAAMt54qr2Cgv217s/7DA7FAAW5rZEwYgRIyqtZSBJnTt31nfffVdhm+uuu07XXXdduet9fHz09NNP6+mnny63TUREhGbNmlVpPAAAAEBNFRrkr/GD29gTBXUC3XY5AMCL8ckAAAAA1CJB/r76711JKjFIFAAoG58MAAAAwAUKCfDVyYJis8Oosh7NIipvBKDWclsxQwAAAKCmmz7i4lLLfKgQCMDLkSgAAACApXRqFGZ2CE5r3rCu2SEAgMsx9AAAAACWcv3F8SoqKdHFFXSP75kQoZU7jnowKue1IHkAwMvRowAAAACW4mvz0c1JzdQuNrTcNu3PWTd6QAtPhOW0ay9qZHYIAFAt9CgAAACA13ng8tY6fCJf11zUSJszj5sdjl3LqLqy2ShSAMC7kSgAAACA1wkL9tcbf+kmSZZKFIQGcXoNwPsx9AAAAABeLaVDtCSpUXiwyZFIPkx5AKAGIOUJAAAAr9Yyqp5SJ1ym+iEBHt+3vy+JAQA1D4kCAAAAeL3YMHN6E4Sfl5zo3Nh7pnYEgPIw9AAAAABwkYcGtTE7BACoNhIFAAAAgIvUCaTDLgDvR6IAACxk/GDuRAEAAMBcJAoAwEL+1r+l2SEAAACgliNRAAAAAAAA7EgUAAAAAC4Q4MupNYCagU8zADDZP67pZHYIAAAXqF/H3+wQAMAlSBQAgMk6NWLObQDwZrNuT9RFTcI1fURPs0MBAJdg/hYAMFmnxmEaPaCFGoWHmB0KAOAC9G4Zqc9aRpodBgC4DIkCALCAcSltzQ4BAAAAkMTQAwAAAAAAcA4SBQAAAAAAwI5EAQAAALxGswYhmj7iYrPDAIAajRoFAAAA8AoBvjYtHTfA7DAAoMajRwEAAAAAALAjUQAAAAAAAOxIFAAAAAAAADsSBQAAAAAAwI5EAQAAAAAAsCNRAAAAAAAA7EgUAAAAAAAAOxIFAAAAAADAjkQBAAAAAACwI1EAAAAASxvSOVaSNKpfc5MjAYDawc/sAAAAAICKvPznrrq9T4I6Nw43OxQAqBVIFAAAAMDSAvxsuqhJfbPDAIBag6EHAAAAAADAjkQBAAAAAACwI1EAAAAAAADsSBQAAAAAAAA7tyYKrrrqKjVp0kRBQUGKjY3VTTfdpP379zu0Wbt2rfr27augoCDFx8drypQppbbzySefqG3btgoKClKnTp00d+5ch/WGYWjSpEmKjY1VcHCwkpOTtWXLFoc2R48e1fDhwxUaGqrw8HCNHDlSJ06ccP2TBgAAAADAi7k1UTBgwAB9/PHHysjI0P/+9z9t27ZNf/rTn+zrc3NzNWjQIDVt2lTp6el6/vnn9eSTT+qf//ynvc2KFSt04403auTIkVq1apWGDh2qoUOHav369fY2U6ZM0WuvvaZp06YpLS1NderUUUpKik6fPm1vM3z4cG3YsEELFizQ119/reXLl2vUqFHufPoAAAAAAHgdH8MwDE/t7Msvv9TQoUOVn58vf39/vfXWW3rssceUmZmpgIAASdIjjzyizz//XJs3b5YkXX/99crLy9PXX39t306vXr3UtWtXTZs2TYZhKC4uTg8++KAeeughSVJOTo6io6M1Y8YM3XDDDdq0aZPat2+vn376ST169JAkzZs3T1deeaX27t2ruLi4SmPPzc1VWFiYcnJyFBoa6uqXBgAAAAAAB2Zdh3qsRsHRo0c1c+ZM9e7dW/7+/pKk1NRU9evXz54kkKSUlBRlZGTo2LFj9jbJyckO20pJSVFqaqokaceOHcrMzHRoExYWpsTERHub1NRUhYeH25MEkpScnCybzaa0tLQy483Pz1dubq7DDwAAAAAANZ3bEwUPP/yw6tSpowYNGmj37t364osv7OsyMzMVHR3t0P7s75mZmRW2OXf9uY8rr01UVJTDej8/P0VERNjbnG/y5MkKCwuz/8THx1fpeQMAAAAA4I2qnCh45JFH5OPjU+HP2WEDkjRu3DitWrVK8+fPl6+vr26++WZ5cLTDBZswYYJycnLsP3v27DE7JAAAAAAA3M6vqg948MEHNWLEiArbNG/e3P7/yMhIRUZGqnXr1mrXrp3i4+P1448/KikpSTExMcrKynJ47NnfY2Ji7P+W1ebc9WeXxcbGOrTp2rWrvc3BgwcdtlFUVKSjR4/aH3++wMBABQYG2n8/m9xgCAIAAAAAwBPOXn96+mZ7lRMFDRs2VMOGDS9oZyUlJZLOjP+XpKSkJD322GMqLCy01y1YsGCB2rRpo/r169vbLFq0SPfff799OwsWLFBSUpIkKSEhQTExMVq0aJE9MZCbm6u0tDTdfffd9m1kZ2crPT1d3bt3lyQtXrxYJSUlSkxMdCr248ePSxJDEAAAAAAAHnX8+HGFhYV5bH9um/UgLS1NP/30k/r06aP69etr27Ztevzxx5WVlaUNGzYoMDBQOTk5atOmjQYNGqSHH35Y69ev12233aaXX37ZPnXhihUrdOmll+q5557TkCFDNHv2bP3jH//QL7/8oo4dO0qS/u///k/PPfec3nvvPSUkJOjxxx/X2rVrtXHjRgUFBUmSrrjiCmVlZWnatGkqLCzUrbfeqh49emjWrFlOPZ+SkhLt379f9erVk4+PjzteMpfIzc1VfHy89uzZw+wMXoZj5504bt6J4+adOG7eiePmnThu3onj5p0qOm6GYej48eOKi4uTzeaxuQiq3qPAWSEhIfr000/1xBNPKC8vT7GxsRo8eLAmTpxo79IfFham+fPna/To0erevbsiIyM1adIke5JAknr37q1Zs2Zp4sSJevTRR9WqVSt9/vnn9iSBJI0fP155eXkaNWqUsrOz1adPH82bN8+eJJCkmTNnasyYMRo4cKBsNpuGDRum1157zennY7PZ1LhxYxe8Mp4RGhrKh4OX4th5J46bd+K4eSeOm3fiuHknjpt34rh5p/KOmyd7Epzlth4FMIdZ82yi+jh23onj5p04bt6J4+adOG7eiePmnThu3smKx81zfRcAAAAAAIDlkSioYQIDA/XEE084zNgA78Cx804cN+/EcfNOHDfvxHHzThw378Rx805WPG4MPQAAAAAAAHb0KAAAAAAAAHYkCgAAAAAAgB2JAgAAAAAAYEeiAAAAAAAA2JEoAAAAAAAAdiQKapipU6eqWbNmCgoKUmJiolauXGl2SDXW5MmTdfHFF6tevXqKiorS0KFDlZGR4dCmf//+8vHxcfi56667HNrs3r1bQ4YMUUhIiKKiojRu3DgVFRU5tFm6dKm6deumwMBAtWzZUjNmzCgVD8feOU8++WSpY9K2bVv7+tOnT2v06NFq0KCB6tatq2HDhikrK8thGxwzz2vWrFmp4+bj46PRo0dL4r1mFcuXL9cf//hHxcXFycfHR59//rnDesMwNGnSJMXGxio4OFjJycnasmWLQ5ujR49q+PDhCg0NVXh4uEaOHKkTJ044tFm7dq369u2roKAgxcfHa8qUKaVi+eSTT9S2bVsFBQWpU6dOmjt3bpVjqS0qOm6FhYV6+OGH1alTJ9WpU0dxcXG6+eabtX//fodtlPUefe655xzacNxcq7L324gRI0odk8GDBzu04f3meZUdt7K+63x8fPT888/b2/B+8zxnzvutdA7pTCyVMlBjzJ492wgICDDeffddY8OGDcYdd9xhhIeHG1lZWWaHViOlpKQY06dPN9avX2+sXr3auPLKK40mTZoYJ06csLe59NJLjTvuuMM4cOCA/ScnJ8e+vqioyOjYsaORnJxsrFq1ypg7d64RGRlpTJgwwd5m+/btRkhIiDF27Fhj48aNxuuvv274+voa8+bNs7fh2DvviSeeMDp06OBwTA4dOmRff9dddxnx8fHGokWLjJ9//tno1auX0bt3b/t6jpk5Dh486HDMFixYYEgylixZYhgG7zWrmDt3rvHYY48Zn376qSHJ+OyzzxzWP/fcc0ZYWJjx+eefG2vWrDGuuuoqIyEhwTh16pS9zeDBg40uXboYP/74o/Hdd98ZLVu2NG688Ub7+pycHCM6OtoYPny4sX79euPDDz80goODjbffftve5ocffjB8fX2NKVOmGBs3bjQmTpxo+Pv7G+vWratSLLVFRcctOzvbSE5ONj766CNj8+bNRmpqqtGzZ0+je/fuDtto2rSp8fTTTzu8B8/9PuS4uV5l77dbbrnFGDx4sMMxOXr0qEMb3m+eV9lxO/d4HThwwHj33XcNHx8fY9u2bfY2vN88z5nzfiudQ1YWizNIFNQgPXv2NEaPHm3/vbi42IiLizMmT55sYlS1x8GDBw1JxrJly+zLLr30UuO+++4r9zFz5841bDabkZmZaV/21ltvGaGhoUZ+fr5hGIYxfvx4o0OHDg6Pu/76642UlBT77xx75z3xxBNGly5dylyXnZ1t+Pv7G5988ol92aZNmwxJRmpqqmEYHDOruO+++4wWLVoYJSUlhmHwXrOi80+AS0pKjJiYGOP555+3L8vOzjYCAwONDz/80DAMw9i4caMhyfjpp5/sbb755hvDx8fH2Ldvn2EYhvHmm28a9evXtx83wzCMhx9+2GjTpo399z//+c/GkCFDHOJJTEw07rzzTqdjqa3KunA538qVKw1Jxq5du+zLmjZtarz88svlPobj5l7lJQquvvrqch/D+818zrzfrr76auOyyy5zWMb7zXznn/db6RzSmVicwdCDGqKgoEDp6elKTk62L7PZbEpOTlZqaqqJkdUeOTk5kqSIiAiH5TNnzlRkZKQ6duyoCRMm6OTJk/Z1qamp6tSpk6Kjo+3LUlJSlJubqw0bNtjbnHtcz7Y5e1w59lW3ZcsWxcXFqXnz5ho+fLh2794tSUpPT1dhYaHDa9m2bVs1adLE/lpyzMxXUFCgDz74QLfddpt8fHzsy3mvWduOHTuUmZnp8PqFhYUpMTHR4f0VHh6uHj162NskJyfLZrMpLS3N3qZfv34KCAiwt0lJSVFGRoaOHTtmb1PRsXQmFpQvJydHPj4+Cg8Pd1j+3HPPqUGDBrrooov0/PPPO3Sn5biZY+nSpYqKilKbNm10991368iRI/Z1vN+sLysrS3PmzNHIkSNLreP9Zq7zz/utdA7pTCzO8HO6JSzt8OHDKi4udvjDk6To6Ght3rzZpKhqj5KSEt1///265JJL1LFjR/vyv/zlL2ratKni4uK0du1aPfzww8rIyNCnn34qScrMzCzzmJ1dV1Gb3NxcnTp1SseOHePYV0FiYqJmzJihNm3a6MCBA3rqqafUt29frV+/XpmZmQoICCh18hsdHV3p8Ti7rqI2HDPX+Pzzz5Wdna0RI0bYl/Fes76zr3NZr9+5xyAqKsphvZ+fnyIiIhzaJCQklNrG2XX169cv91ieu43KYkHZTp8+rYcfflg33nijQkND7cvvvfdedevWTREREVqxYoUmTJigAwcO6KWXXpLEcTPD4MGDde211yohIUHbtm3To48+qiuuuEKpqany9fXl/eYF3nvvPdWrV0/XXnutw3Leb+Yq67zfSueQzsTiDBIFgAuMHj1a69ev1/fff++wfNSoUfb/d+rUSbGxsRo4cKC2bdumFi1aeDpMSLriiivs/+/cubMSExPVtGlTffzxxwoODjYxMjjr3//+t6644grFxcXZl/FeA9yvsLBQf/7zn2UYht566y2HdWPHjrX/v3PnzgoICNCdd96pyZMnKzAw0NOhQtINN9xg/3+nTp3UuXNntWjRQkuXLtXAgQNNjAzOevfddzV8+HAFBQU5LOf9Zq7yzvtrGoYe1BCRkZHy9fUtVc0yKytLMTExJkVVO4wZM0Zff/21lixZosaNG1fYNjExUZK0detWSVJMTEyZx+zsuorahIaGKjg4mGNfTeHh4WrdurW2bt2qmJgYFRQUKDs726HNua8lx8xcu3bt0sKFC3X77bdX2I73mvWcfY0qev1iYmJ08OBBh/VFRUU6evSoS96D566vLBY4Opsk2LVrlxYsWODQm6AsiYmJKioq0s6dOyVx3KygefPmioyMdPhc5P1mXd99950yMjIq/b6TeL95Unnn/VY6h3QmFmeQKKghAgIC1L17dy1atMi+rKSkRIsWLVJSUpKJkdVchmFozJgx+uyzz7R48eJSXbzKsnr1aklSbGysJCkpKUnr1q1z+KI+ewLWvn17e5tzj+vZNmePK8e+ek6cOKFt27YpNjZW3bt3l7+/v8NrmZGRod27d9tfS46ZuaZPn66oqCgNGTKkwna816wnISFBMTExDq9fbm6u0tLSHN5f2dnZSk9Pt7dZvHixSkpK7MmfpKQkLV++XIWFhfY2CxYsUJs2bVS/fn17m4qOpTOx4HdnkwRbtmzRwoUL1aBBg0ofs3r1atlsNnvXdo6b+fbu3asjR444fC7yfrOuf//73+revbu6dOlSaVveb+5X2Xm/lc4hnYnF2SeNGmL27NlGYGCgMWPGDGPjxo3GqFGjjPDwcIfKmnCdu+++2wgLCzOWLl3qMD3NyZMnDcMwjK1btxpPP/208fPPPxs7duwwvvjiC6N58+ZGv3797Ns4O03KoEGDjNWrVxvz5s0zGjZsWOY0KePGjTM2bdpkTJ06tcxpUjj2znnwwQeNpUuXGjt27DB++OEHIzk52YiMjDQOHjxoGMaZ6WSaNGliLF682Pj555+NpKQkIykpyf54jpl5iouLjSZNmhgPP/yww3Lea9Zx/PhxY9WqVcaqVasMScZLL71krFq1yl4d/7nnnjPCw8ONL774wli7dq1x9dVXlzk94kUXXWSkpaUZ33//vdGqVSuH6dqys7ON6Oho46abbjLWr19vzJ492wgJCSk17Zefn5/xwgsvGJs2bTKeeOKJMqf9qiyW2qKi41ZQUGBcddVVRuPGjY3Vq1c7fN+drdK9YsUK4+WXXzZWr15tbNu2zfjggw+Mhg0bGjfffLN9Hxw316vouB0/ftx46KGHjNTUVGPHjh3GwoULjW7duhmtWrUyTp8+bd8G7zfPq+xz0jDOTG8YEhJivPXWW6Uez/vNHJWd9xuGtc4hK4vFGSQKapjXX3/daNKkiREQEGD07NnT+PHHH80OqcaSVObP9OnTDcMwjN27dxv9+vUzIiIijMDAQKNly5bGuHHjHOZ2NwzD2Llzp3HFFVcYwcHBRmRkpPHggw8ahYWFDm2WLFlidO3a1QgICDCaN29u38e5OPbOuf76643Y2FgjICDAaNSokXH99dcbW7duta8/deqU8be//c2oX7++ERISYlxzzTXGgQMHHLbBMTPHt99+a0gyMjIyHJbzXrOOJUuWlPm5eMsttxiGcWa6rccff9yIjo42AgMDjYEDB5Y6nkeOHDFuvPFGo27dukZoaKhx6623GsePH3dos2bNGqNPnz5GYGCg0ahRI+O5554rFcvHH39stG7d2ggICDA6dOhgzJkzx2G9M7HUFhUdtx07dpT7fbdkyRLDMAwjPT3dSExMNMLCwoygoCCjXbt2xj/+8Q+HC1LD4Li5WkXH7eTJk8agQYOMhg0bGv7+/kbTpk2NO+64o1RSk/eb51X2OWkYhvH2228bwcHBRnZ2dqnH834zR2Xn/YZhrXNIZ2KpjM9vTxwAAAAAAIAaBQAAAAAA4HckCgAAAAAAgB2JAgAAAAAAYEeiAAAAAAAA2JEoAAAAAAAAdiQKAAAAAACAHYkCAAAAAABgR6IAAAAAAADYkSgAAAAAAAB2JAoAAAAAAIAdiQIAAAAAAGD3/9WvouvgpzQlAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(wave_audio);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDT-6R3aZA7E",
        "outputId": "bc4fc5f8-d1a7-4ead-d7da-b4d273cfcd81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(40, 173)\n"
          ]
        }
      ],
      "source": [
        "mfccs = librosa.feature.mfcc(y=librosa_audio_data, sr=librosa_sample_rate, n_mfcc=40)\n",
        "print(mfccs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHVSGncwZKWo",
        "outputId": "9b7bffc4-179b-42af-ce8c-eca4c859f574"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-5.2506287e+02, -5.1955383e+02, -5.1863977e+02, ...,\n",
              "        -4.3568246e+02, -3.8561288e+02, -3.0827991e+02],\n",
              "       [ 9.1997910e+00,  1.6759438e+01,  1.8103901e+01, ...,\n",
              "         1.1375922e+02,  1.4781424e+02,  1.3629199e+02],\n",
              "       [ 8.8354816e+00,  1.5750098e+01,  1.7259289e+01, ...,\n",
              "         6.4274628e+01,  4.9134655e+01,  3.2146011e+01],\n",
              "       ...,\n",
              "       [ 4.3310225e-01, -3.5408967e+00, -4.8356514e+00, ...,\n",
              "        -5.2699137e+00, -1.6015506e-01,  5.9511268e-01],\n",
              "       [ 4.4527557e-01, -3.2774944e+00, -4.6472969e+00, ...,\n",
              "        -3.4224114e+00,  3.9338789e+00,  7.3076093e-01],\n",
              "       [ 3.5710910e-01, -2.9899125e+00, -4.4125967e+00, ...,\n",
              "        -2.6713367e+00,  2.7566633e+00, -5.4228485e-02]], dtype=float32)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mfccs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BzoshlTZZlSB",
        "outputId": "5b1e544e-d841-4d1b-eabc-4cc1d3d93374"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice_file_name</th>\n",
              "      <th>fsID</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>salience</th>\n",
              "      <th>fold</th>\n",
              "      <th>classID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100032-3-0-0.wav</td>\n",
              "      <td>100032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317551</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100263-2-0-117.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>58.5</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100263-2-0-121.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>60.5</td>\n",
              "      <td>64.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100263-2-0-126.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>63.0</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100263-2-0-137.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>68.5</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
              "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
              "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
              "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
              "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
              "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
              "\n",
              "              class  \n",
              "0          dog_bark  \n",
              "1  children_playing  \n",
              "2  children_playing  \n",
              "3  children_playing  \n",
              "4  children_playing  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "audio_dataset_path ='UrbanSound8K/audio/'\n",
        "metadata=pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
        "metadata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "71xIIr8TZLXl"
      },
      "outputs": [],
      "source": [
        "def features_extractor(file):\n",
        "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "    \n",
        "    return mfccs_scaled_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_2KftPg0vU"
      },
      "source": [
        "## Feature Extraction\n",
        "\n",
        "* We divides the data by extracting the characteristics of the frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBsvsPqWZOXd",
        "outputId": "371cb718-da95-49ba-932b-69561efa81f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3555it [01:55, 30.96it/s]c:\\Users\\Emincan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
            "  return f(*args, **kwargs)\n",
            "8321it [04:24, 40.01it/s]c:\\Users\\Emincan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
            "  return f(*args, **kwargs)\n",
            "8327it [04:24, 44.80it/s]c:\\Users\\Emincan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
            "  return f(*args, **kwargs)\n",
            "8732it [04:36, 31.60it/s]\n"
          ]
        }
      ],
      "source": [
        "### Now we iterate through every audio file and extract features \n",
        "### using Mel-Frequency Cepstral Coefficients\n",
        "extracted_features=[]\n",
        "for index_num,row in tqdm(metadata.iterrows()):\n",
        "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
        "    final_class_labels=row[\"class\"]\n",
        "    data=features_extractor(file_name)\n",
        "    extracted_features.append([data,final_class_labels])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RhK3iqAhIMU"
      },
      "source": [
        "## Our Final DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l_E0l6AxZQiR",
        "outputId": "a3aaef46-628e-451a-b9e1-5b3b5a828021"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-217.35526, 70.22338, -130.38527, -53.282898,...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-424.09818, 109.34077, -52.919525, 60.86475, ...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-458.79114, 121.38419, -46.520657, 52.00812, ...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-413.89984, 101.66371, -35.42945, 53.036358, ...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-446.60352, 113.68541, -52.402218, 60.302044,...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             feature             class\n",
              "0  [-217.35526, 70.22338, -130.38527, -53.282898,...          dog_bark\n",
              "1  [-424.09818, 109.34077, -52.919525, 60.86475, ...  children_playing\n",
              "2  [-458.79114, 121.38419, -46.520657, 52.00812, ...  children_playing\n",
              "3  [-413.89984, 101.66371, -35.42945, 53.036358, ...  children_playing\n",
              "4  [-446.60352, 113.68541, -52.402218, 60.302044,...  children_playing"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
        "extracted_features_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lRfU34pzZzO4"
      },
      "outputs": [],
      "source": [
        "# Our features and label.\n",
        "X=np.array(extracted_features_df['feature'].tolist())\n",
        "y=np.array(extracted_features_df['class'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZP5kXMkZ0YJ",
        "outputId": "c87e0c6a-fb3b-4716-a85d-6475e3c70e1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8732, 40)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AqpC9deYZ2GF"
      },
      "outputs": [],
      "source": [
        "# Label Encoding\n",
        "y=np.array(pd.get_dummies(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNvw1sNXZ3kB",
        "outputId": "2fa76a00-f837-46fe-c6a7-3237f2a66c19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8732, 10)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FXEUujKyZ5Z3"
      },
      "outputs": [],
      "source": [
        "### Train/Test/Val Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=53)\n",
        "X_test , X_val , y_test , y_val = train_test_split(X_test,y_test , test_size = 0.4 , random_state =53)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCE-4IzAZ5t_",
        "outputId": "9d4dcc34-61b2-484c-ffd1-c3b48a8c31a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train---------: [[-4.4660352e+02  1.1368541e+02 -5.2402218e+01 ...  2.0793355e+00\n",
            "   1.1161355e+00  4.3718461e-02]\n",
            " [-3.4466641e+02  8.1548080e+01  1.0016554e+01 ...  2.2427995e+00\n",
            "  -1.3785095e+00  2.3533483e-01]\n",
            " [-3.0478070e+02  1.6254568e+01 -2.3844900e+01 ...  5.0087671e+00\n",
            "  -1.5540754e+00  5.5810905e+00]\n",
            " ...\n",
            " [-3.5567734e+02  1.5805850e+02 -9.9176035e+00 ... -2.0883915e+00\n",
            "  -2.9937372e+00 -3.6237228e+00]\n",
            " [-7.5334724e+01  7.3310951e+01 -2.7474356e+01 ... -1.7935060e+00\n",
            "  -3.3400061e+00  2.8595352e+00]\n",
            " [-4.3270258e+02  1.4079111e+02 -5.3869976e+01 ... -2.6685240e-02\n",
            "  -5.1870644e-01 -4.2102008e+00]]\n",
            "y---------------: [[0 0 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " ...\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]]\n",
            "X_train.shape: (6985, 40)\n",
            "X_test.shape: (1048, 40)\n",
            "X_val.shape: (699, 40)\n",
            "y_test.shape: (1048, 10)\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_train---------: {X_train}\")\n",
        "print(f\"y---------------: {y}\")\n",
        "print(f\"X_train.shape: {X_train.shape}\")\n",
        "print(f\"X_test.shape: {X_test.shape}\")\n",
        "print(f\"X_val.shape: {X_val.shape}\")\n",
        "print(f\"y_test.shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRQX9hsSaUVK"
      },
      "source": [
        "# Modelling Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "izW2uklNaVAT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UtJ0i_mcaWoL"
      },
      "outputs": [],
      "source": [
        "# This will be our output layer dense\n",
        "num_labels=y.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XBjD9FACaZHY"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "# First layer\n",
        "model.add(Dense(1024,input_shape=(40,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# Second layer\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# Third layer\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# Fourth layer\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# Last layer\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cATdT-pJaaej",
        "outputId": "30673176-3728-4d7d-828c-bd6431381646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1024)              41984     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,097,226\n",
            "Trainable params: 1,097,226\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Qe3rwY-sabRy"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtmmwck7ahWh",
        "outputId": "5197395f-e96e-47da-8a1d-4beb8ea23817"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 4.7557 - accuracy: 0.1551\n",
            "Epoch 1: val_loss improved from inf to 2.14247, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 2s 10ms/step - loss: 4.7430 - accuracy: 0.1548 - val_loss: 2.1425 - val_accuracy: 0.1989\n",
            "Epoch 2/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 2.1481 - accuracy: 0.2246\n",
            "Epoch 2: val_loss improved from 2.14247 to 2.00219, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 2.1481 - accuracy: 0.2252 - val_loss: 2.0022 - val_accuracy: 0.3548\n",
            "Epoch 3/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 2.0388 - accuracy: 0.2629\n",
            "Epoch 3: val_loss improved from 2.00219 to 1.87390, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 2.0392 - accuracy: 0.2628 - val_loss: 1.8739 - val_accuracy: 0.3662\n",
            "Epoch 4/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 1.9186 - accuracy: 0.3107\n",
            "Epoch 4: val_loss improved from 1.87390 to 1.76304, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 1.9157 - accuracy: 0.3102 - val_loss: 1.7630 - val_accuracy: 0.4664\n",
            "Epoch 5/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 1.8392 - accuracy: 0.3471\n",
            "Epoch 5: val_loss improved from 1.76304 to 1.65814, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 1.8384 - accuracy: 0.3477 - val_loss: 1.6581 - val_accuracy: 0.4864\n",
            "Epoch 6/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 1.7152 - accuracy: 0.4029\n",
            "Epoch 6: val_loss improved from 1.65814 to 1.53487, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 1.7155 - accuracy: 0.4026 - val_loss: 1.5349 - val_accuracy: 0.5279\n",
            "Epoch 7/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 1.6369 - accuracy: 0.4354\n",
            "Epoch 7: val_loss improved from 1.53487 to 1.36436, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 1.6359 - accuracy: 0.4359 - val_loss: 1.3644 - val_accuracy: 0.5751\n",
            "Epoch 8/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 1.5103 - accuracy: 0.4768\n",
            "Epoch 8: val_loss improved from 1.36436 to 1.30156, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 1.5093 - accuracy: 0.4772 - val_loss: 1.3016 - val_accuracy: 0.6152\n",
            "Epoch 9/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 1.4564 - accuracy: 0.5038\n",
            "Epoch 9: val_loss improved from 1.30156 to 1.20541, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 1.4569 - accuracy: 0.5041 - val_loss: 1.2054 - val_accuracy: 0.6023\n",
            "Epoch 10/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 1.3989 - accuracy: 0.5230\n",
            "Epoch 10: val_loss improved from 1.20541 to 1.19850, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 1.4013 - accuracy: 0.5224 - val_loss: 1.1985 - val_accuracy: 0.6180\n",
            "Epoch 11/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 1.3392 - accuracy: 0.5472\n",
            "Epoch 11: val_loss improved from 1.19850 to 1.13414, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 1.3389 - accuracy: 0.5470 - val_loss: 1.1341 - val_accuracy: 0.6567\n",
            "Epoch 12/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 1.2708 - accuracy: 0.5671\n",
            "Epoch 12: val_loss improved from 1.13414 to 1.02055, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 1.2664 - accuracy: 0.5685 - val_loss: 1.0205 - val_accuracy: 0.6767\n",
            "Epoch 13/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 1.2436 - accuracy: 0.5831\n",
            "Epoch 13: val_loss did not improve from 1.02055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 1.2433 - accuracy: 0.5834 - val_loss: 1.0246 - val_accuracy: 0.6724\n",
            "Epoch 14/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 1.1691 - accuracy: 0.6110\n",
            "Epoch 14: val_loss improved from 1.02055 to 0.92069, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 1.1682 - accuracy: 0.6110 - val_loss: 0.9207 - val_accuracy: 0.7010\n",
            "Epoch 15/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 1.1148 - accuracy: 0.6313\n",
            "Epoch 15: val_loss did not improve from 0.92069\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 1.1182 - accuracy: 0.6301 - val_loss: 0.9627 - val_accuracy: 0.7268\n",
            "Epoch 16/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 1.0801 - accuracy: 0.6334\n",
            "Epoch 16: val_loss improved from 0.92069 to 0.90800, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 1.0838 - accuracy: 0.6322 - val_loss: 0.9080 - val_accuracy: 0.7110\n",
            "Epoch 17/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 1.0665 - accuracy: 0.6453\n",
            "Epoch 17: val_loss improved from 0.90800 to 0.84635, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 1.0688 - accuracy: 0.6450 - val_loss: 0.8463 - val_accuracy: 0.7525\n",
            "Epoch 18/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 1.0392 - accuracy: 0.6460\n",
            "Epoch 18: val_loss improved from 0.84635 to 0.83343, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 1.0417 - accuracy: 0.6450 - val_loss: 0.8334 - val_accuracy: 0.7439\n",
            "Epoch 19/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 1.0046 - accuracy: 0.6641\n",
            "Epoch 19: val_loss improved from 0.83343 to 0.77112, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 1.0034 - accuracy: 0.6650 - val_loss: 0.7711 - val_accuracy: 0.7439\n",
            "Epoch 20/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.9980 - accuracy: 0.6702\n",
            "Epoch 20: val_loss did not improve from 0.77112\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.9968 - accuracy: 0.6710 - val_loss: 0.7737 - val_accuracy: 0.7611\n",
            "Epoch 21/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.9397 - accuracy: 0.6838\n",
            "Epoch 21: val_loss improved from 0.77112 to 0.72377, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.9397 - accuracy: 0.6838 - val_loss: 0.7238 - val_accuracy: 0.7711\n",
            "Epoch 22/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.9247 - accuracy: 0.6886\n",
            "Epoch 22: val_loss improved from 0.72377 to 0.69743, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.9231 - accuracy: 0.6893 - val_loss: 0.6974 - val_accuracy: 0.7783\n",
            "Epoch 23/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.9007 - accuracy: 0.7069\n",
            "Epoch 23: val_loss improved from 0.69743 to 0.67257, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.9013 - accuracy: 0.7072 - val_loss: 0.6726 - val_accuracy: 0.7840\n",
            "Epoch 24/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.8722 - accuracy: 0.7109\n",
            "Epoch 24: val_loss improved from 0.67257 to 0.62481, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.8732 - accuracy: 0.7110 - val_loss: 0.6248 - val_accuracy: 0.8026\n",
            "Epoch 25/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.8681 - accuracy: 0.7187\n",
            "Epoch 25: val_loss did not improve from 0.62481\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.8675 - accuracy: 0.7188 - val_loss: 0.6503 - val_accuracy: 0.8069\n",
            "Epoch 26/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.8455 - accuracy: 0.7303\n",
            "Epoch 26: val_loss did not improve from 0.62481\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.8414 - accuracy: 0.7307 - val_loss: 0.6252 - val_accuracy: 0.8097\n",
            "Epoch 27/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.8450 - accuracy: 0.7242\n",
            "Epoch 27: val_loss improved from 0.62481 to 0.62095, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.8444 - accuracy: 0.7241 - val_loss: 0.6209 - val_accuracy: 0.7954\n",
            "Epoch 28/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.8018 - accuracy: 0.7354\n",
            "Epoch 28: val_loss did not improve from 0.62095\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.8007 - accuracy: 0.7356 - val_loss: 0.6526 - val_accuracy: 0.7983\n",
            "Epoch 29/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.7879 - accuracy: 0.7368\n",
            "Epoch 29: val_loss improved from 0.62095 to 0.60360, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.7872 - accuracy: 0.7370 - val_loss: 0.6036 - val_accuracy: 0.8240\n",
            "Epoch 30/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.7937 - accuracy: 0.7449\n",
            "Epoch 30: val_loss improved from 0.60360 to 0.58901, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.7937 - accuracy: 0.7446 - val_loss: 0.5890 - val_accuracy: 0.8140\n",
            "Epoch 31/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.7556 - accuracy: 0.7560\n",
            "Epoch 31: val_loss improved from 0.58901 to 0.56279, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.7550 - accuracy: 0.7562 - val_loss: 0.5628 - val_accuracy: 0.8298\n",
            "Epoch 32/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.7472 - accuracy: 0.7570\n",
            "Epoch 32: val_loss improved from 0.56279 to 0.53450, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.7469 - accuracy: 0.7571 - val_loss: 0.5345 - val_accuracy: 0.8212\n",
            "Epoch 33/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.7361 - accuracy: 0.7565\n",
            "Epoch 33: val_loss did not improve from 0.53450\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.7361 - accuracy: 0.7565 - val_loss: 0.5548 - val_accuracy: 0.8255\n",
            "Epoch 34/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.7194 - accuracy: 0.7656\n",
            "Epoch 34: val_loss did not improve from 0.53450\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.7186 - accuracy: 0.7658 - val_loss: 0.5484 - val_accuracy: 0.8283\n",
            "Epoch 35/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.7132 - accuracy: 0.7610\n",
            "Epoch 35: val_loss improved from 0.53450 to 0.51836, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.7137 - accuracy: 0.7612 - val_loss: 0.5184 - val_accuracy: 0.8412\n",
            "Epoch 36/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.7065 - accuracy: 0.7681\n",
            "Epoch 36: val_loss did not improve from 0.51836\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.7080 - accuracy: 0.7678 - val_loss: 0.5422 - val_accuracy: 0.8155\n",
            "Epoch 37/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.6962 - accuracy: 0.7791\n",
            "Epoch 37: val_loss improved from 0.51836 to 0.50749, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6955 - accuracy: 0.7788 - val_loss: 0.5075 - val_accuracy: 0.8369\n",
            "Epoch 38/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.6950 - accuracy: 0.7732\n",
            "Epoch 38: val_loss did not improve from 0.50749\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6939 - accuracy: 0.7737 - val_loss: 0.5100 - val_accuracy: 0.8255\n",
            "Epoch 39/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.6542 - accuracy: 0.7846\n",
            "Epoch 39: val_loss did not improve from 0.50749\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6550 - accuracy: 0.7843 - val_loss: 0.5168 - val_accuracy: 0.8412\n",
            "Epoch 40/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.6499 - accuracy: 0.7914\n",
            "Epoch 40: val_loss did not improve from 0.50749\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6503 - accuracy: 0.7911 - val_loss: 0.5391 - val_accuracy: 0.8283\n",
            "Epoch 41/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.6610 - accuracy: 0.7866\n",
            "Epoch 41: val_loss did not improve from 0.50749\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6601 - accuracy: 0.7868 - val_loss: 0.5236 - val_accuracy: 0.8541\n",
            "Epoch 42/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.6654 - accuracy: 0.7803\n",
            "Epoch 42: val_loss improved from 0.50749 to 0.48414, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6664 - accuracy: 0.7802 - val_loss: 0.4841 - val_accuracy: 0.8398\n",
            "Epoch 43/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.7894\n",
            "Epoch 43: val_loss did not improve from 0.48414\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6564 - accuracy: 0.7894 - val_loss: 0.5019 - val_accuracy: 0.8312\n",
            "Epoch 44/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.6327 - accuracy: 0.7980\n",
            "Epoch 44: val_loss improved from 0.48414 to 0.47493, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6323 - accuracy: 0.7981 - val_loss: 0.4749 - val_accuracy: 0.8569\n",
            "Epoch 45/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.6219 - accuracy: 0.7978\n",
            "Epoch 45: val_loss improved from 0.47493 to 0.46453, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6251 - accuracy: 0.7980 - val_loss: 0.4645 - val_accuracy: 0.8670\n",
            "Epoch 46/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.8100\n",
            "Epoch 46: val_loss improved from 0.46453 to 0.45382, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6028 - accuracy: 0.8100 - val_loss: 0.4538 - val_accuracy: 0.8498\n",
            "Epoch 47/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.6109 - accuracy: 0.7990\n",
            "Epoch 47: val_loss improved from 0.45382 to 0.44589, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6109 - accuracy: 0.7990 - val_loss: 0.4459 - val_accuracy: 0.8541\n",
            "Epoch 48/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5980 - accuracy: 0.8094\n",
            "Epoch 48: val_loss did not improve from 0.44589\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5993 - accuracy: 0.8092 - val_loss: 0.4693 - val_accuracy: 0.8584\n",
            "Epoch 49/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.6312 - accuracy: 0.7988\n",
            "Epoch 49: val_loss did not improve from 0.44589\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6307 - accuracy: 0.7991 - val_loss: 0.4752 - val_accuracy: 0.8398\n",
            "Epoch 50/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5821 - accuracy: 0.8107\n",
            "Epoch 50: val_loss did not improve from 0.44589\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5822 - accuracy: 0.8106 - val_loss: 0.4691 - val_accuracy: 0.8555\n",
            "Epoch 51/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5807 - accuracy: 0.8084\n",
            "Epoch 51: val_loss did not improve from 0.44589\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5804 - accuracy: 0.8067 - val_loss: 0.4806 - val_accuracy: 0.8512\n",
            "Epoch 52/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.6038 - accuracy: 0.8092\n",
            "Epoch 52: val_loss did not improve from 0.44589\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6042 - accuracy: 0.8090 - val_loss: 0.4558 - val_accuracy: 0.8598\n",
            "Epoch 53/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5655 - accuracy: 0.8165\n",
            "Epoch 53: val_loss improved from 0.44589 to 0.44518, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5650 - accuracy: 0.8170 - val_loss: 0.4452 - val_accuracy: 0.8627\n",
            "Epoch 54/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5798 - accuracy: 0.8146\n",
            "Epoch 54: val_loss did not improve from 0.44518\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5798 - accuracy: 0.8146 - val_loss: 0.4797 - val_accuracy: 0.8255\n",
            "Epoch 55/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5776 - accuracy: 0.8185\n",
            "Epoch 55: val_loss did not improve from 0.44518\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5797 - accuracy: 0.8170 - val_loss: 0.4768 - val_accuracy: 0.8484\n",
            "Epoch 56/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5696 - accuracy: 0.8198\n",
            "Epoch 56: val_loss did not improve from 0.44518\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5696 - accuracy: 0.8198 - val_loss: 0.4528 - val_accuracy: 0.8541\n",
            "Epoch 57/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.8203\n",
            "Epoch 57: val_loss improved from 0.44518 to 0.43971, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5586 - accuracy: 0.8198 - val_loss: 0.4397 - val_accuracy: 0.8512\n",
            "Epoch 58/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5627 - accuracy: 0.8220\n",
            "Epoch 58: val_loss did not improve from 0.43971\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5625 - accuracy: 0.8222 - val_loss: 0.4450 - val_accuracy: 0.8741\n",
            "Epoch 59/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5611 - accuracy: 0.8212\n",
            "Epoch 59: val_loss did not improve from 0.43971\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5615 - accuracy: 0.8209 - val_loss: 0.4601 - val_accuracy: 0.8498\n",
            "Epoch 60/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5541 - accuracy: 0.8165\n",
            "Epoch 60: val_loss improved from 0.43971 to 0.43236, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5541 - accuracy: 0.8165 - val_loss: 0.4324 - val_accuracy: 0.8741\n",
            "Epoch 61/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5575 - accuracy: 0.8210\n",
            "Epoch 61: val_loss improved from 0.43236 to 0.42707, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5613 - accuracy: 0.8205 - val_loss: 0.4271 - val_accuracy: 0.8727\n",
            "Epoch 62/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5440 - accuracy: 0.8226\n",
            "Epoch 62: val_loss did not improve from 0.42707\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5446 - accuracy: 0.8226 - val_loss: 0.4416 - val_accuracy: 0.8612\n",
            "Epoch 63/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5842 - accuracy: 0.8178\n",
            "Epoch 63: val_loss did not improve from 0.42707\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5820 - accuracy: 0.8182 - val_loss: 0.4384 - val_accuracy: 0.8526\n",
            "Epoch 64/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5666 - accuracy: 0.8204\n",
            "Epoch 64: val_loss did not improve from 0.42707\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5677 - accuracy: 0.8202 - val_loss: 0.4289 - val_accuracy: 0.8684\n",
            "Epoch 65/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5353 - accuracy: 0.8345\n",
            "Epoch 65: val_loss did not improve from 0.42707\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5352 - accuracy: 0.8346 - val_loss: 0.4872 - val_accuracy: 0.8412\n",
            "Epoch 66/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5451 - accuracy: 0.8255\n",
            "Epoch 66: val_loss did not improve from 0.42707\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5457 - accuracy: 0.8255 - val_loss: 0.4429 - val_accuracy: 0.8755\n",
            "Epoch 67/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5380 - accuracy: 0.8302\n",
            "Epoch 67: val_loss improved from 0.42707 to 0.42399, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5380 - accuracy: 0.8302 - val_loss: 0.4240 - val_accuracy: 0.8641\n",
            "Epoch 68/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5323 - accuracy: 0.8353\n",
            "Epoch 68: val_loss did not improve from 0.42399\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5325 - accuracy: 0.8348 - val_loss: 0.4325 - val_accuracy: 0.8655\n",
            "Epoch 69/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5360 - accuracy: 0.8294\n",
            "Epoch 69: val_loss did not improve from 0.42399\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5351 - accuracy: 0.8293 - val_loss: 0.4492 - val_accuracy: 0.8598\n",
            "Epoch 70/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5282 - accuracy: 0.8315\n",
            "Epoch 70: val_loss did not improve from 0.42399\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5276 - accuracy: 0.8316 - val_loss: 0.4267 - val_accuracy: 0.8684\n",
            "Epoch 71/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5348 - accuracy: 0.8384\n",
            "Epoch 71: val_loss did not improve from 0.42399\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5334 - accuracy: 0.8388 - val_loss: 0.4253 - val_accuracy: 0.8727\n",
            "Epoch 72/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5059 - accuracy: 0.8394\n",
            "Epoch 72: val_loss did not improve from 0.42399\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5051 - accuracy: 0.8395 - val_loss: 0.4396 - val_accuracy: 0.8598\n",
            "Epoch 73/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5199 - accuracy: 0.8378\n",
            "Epoch 73: val_loss improved from 0.42399 to 0.42162, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5202 - accuracy: 0.8381 - val_loss: 0.4216 - val_accuracy: 0.8712\n",
            "Epoch 74/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5331 - accuracy: 0.8307\n",
            "Epoch 74: val_loss did not improve from 0.42162\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5307 - accuracy: 0.8306 - val_loss: 0.4355 - val_accuracy: 0.8598\n",
            "Epoch 75/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4948 - accuracy: 0.8434\n",
            "Epoch 75: val_loss did not improve from 0.42162\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4984 - accuracy: 0.8421 - val_loss: 0.4422 - val_accuracy: 0.8584\n",
            "Epoch 76/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4747 - accuracy: 0.8428\n",
            "Epoch 76: val_loss improved from 0.42162 to 0.37819, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4779 - accuracy: 0.8429 - val_loss: 0.3782 - val_accuracy: 0.8827\n",
            "Epoch 77/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5253 - accuracy: 0.8360\n",
            "Epoch 77: val_loss did not improve from 0.37819\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5252 - accuracy: 0.8359 - val_loss: 0.4071 - val_accuracy: 0.8684\n",
            "Epoch 78/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5118 - accuracy: 0.8400\n",
            "Epoch 78: val_loss did not improve from 0.37819\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5116 - accuracy: 0.8401 - val_loss: 0.4044 - val_accuracy: 0.8813\n",
            "Epoch 79/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.8485\n",
            "Epoch 79: val_loss did not improve from 0.37819\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4716 - accuracy: 0.8485 - val_loss: 0.4276 - val_accuracy: 0.8512\n",
            "Epoch 80/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.8361\n",
            "Epoch 80: val_loss did not improve from 0.37819\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5249 - accuracy: 0.8361 - val_loss: 0.4119 - val_accuracy: 0.8798\n",
            "Epoch 81/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4906 - accuracy: 0.8430\n",
            "Epoch 81: val_loss did not improve from 0.37819\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4866 - accuracy: 0.8442 - val_loss: 0.4299 - val_accuracy: 0.8655\n",
            "Epoch 82/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4832 - accuracy: 0.8468\n",
            "Epoch 82: val_loss did not improve from 0.37819\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4869 - accuracy: 0.8464 - val_loss: 0.3939 - val_accuracy: 0.8798\n",
            "Epoch 83/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.8402\n",
            "Epoch 83: val_loss did not improve from 0.37819\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5046 - accuracy: 0.8402 - val_loss: 0.4115 - val_accuracy: 0.8584\n",
            "Epoch 84/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4794 - accuracy: 0.8447\n",
            "Epoch 84: val_loss improved from 0.37819 to 0.37568, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4822 - accuracy: 0.8438 - val_loss: 0.3757 - val_accuracy: 0.8741\n",
            "Epoch 85/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4764 - accuracy: 0.8523\n",
            "Epoch 85: val_loss did not improve from 0.37568\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4764 - accuracy: 0.8523 - val_loss: 0.3814 - val_accuracy: 0.8798\n",
            "Epoch 86/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4788 - accuracy: 0.8525\n",
            "Epoch 86: val_loss did not improve from 0.37568\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4797 - accuracy: 0.8523 - val_loss: 0.3828 - val_accuracy: 0.8741\n",
            "Epoch 87/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4620 - accuracy: 0.8518\n",
            "Epoch 87: val_loss did not improve from 0.37568\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4662 - accuracy: 0.8513 - val_loss: 0.4051 - val_accuracy: 0.8870\n",
            "Epoch 88/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4862 - accuracy: 0.8519\n",
            "Epoch 88: val_loss improved from 0.37568 to 0.37100, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4867 - accuracy: 0.8515 - val_loss: 0.3710 - val_accuracy: 0.8827\n",
            "Epoch 89/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4577 - accuracy: 0.8528\n",
            "Epoch 89: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4585 - accuracy: 0.8525 - val_loss: 0.3930 - val_accuracy: 0.8798\n",
            "Epoch 90/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5081 - accuracy: 0.8479\n",
            "Epoch 90: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5093 - accuracy: 0.8478 - val_loss: 0.4041 - val_accuracy: 0.8784\n",
            "Epoch 91/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4917 - accuracy: 0.8516\n",
            "Epoch 91: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4872 - accuracy: 0.8524 - val_loss: 0.4042 - val_accuracy: 0.8698\n",
            "Epoch 92/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4618 - accuracy: 0.8541\n",
            "Epoch 92: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4645 - accuracy: 0.8533 - val_loss: 0.4219 - val_accuracy: 0.8755\n",
            "Epoch 93/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4796 - accuracy: 0.8557\n",
            "Epoch 93: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4796 - accuracy: 0.8557 - val_loss: 0.4280 - val_accuracy: 0.8627\n",
            "Epoch 94/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4985 - accuracy: 0.8436\n",
            "Epoch 94: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4983 - accuracy: 0.8435 - val_loss: 0.3980 - val_accuracy: 0.8784\n",
            "Epoch 95/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4688 - accuracy: 0.8538\n",
            "Epoch 95: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4688 - accuracy: 0.8540 - val_loss: 0.4183 - val_accuracy: 0.8770\n",
            "Epoch 96/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4693 - accuracy: 0.8544\n",
            "Epoch 96: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4690 - accuracy: 0.8543 - val_loss: 0.4120 - val_accuracy: 0.8755\n",
            "Epoch 97/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.8550\n",
            "Epoch 97: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4635 - accuracy: 0.8550 - val_loss: 0.4195 - val_accuracy: 0.8813\n",
            "Epoch 98/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4559 - accuracy: 0.8573\n",
            "Epoch 98: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4554 - accuracy: 0.8574 - val_loss: 0.3942 - val_accuracy: 0.8798\n",
            "Epoch 99/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4597 - accuracy: 0.8528\n",
            "Epoch 99: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4590 - accuracy: 0.8535 - val_loss: 0.3799 - val_accuracy: 0.8827\n",
            "Epoch 100/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4317 - accuracy: 0.8640\n",
            "Epoch 100: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4316 - accuracy: 0.8639 - val_loss: 0.3953 - val_accuracy: 0.8670\n",
            "Epoch 101/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4734 - accuracy: 0.8511\n",
            "Epoch 101: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4734 - accuracy: 0.8511 - val_loss: 0.4015 - val_accuracy: 0.8741\n",
            "Epoch 102/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4627 - accuracy: 0.8633\n",
            "Epoch 102: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4619 - accuracy: 0.8633 - val_loss: 0.4048 - val_accuracy: 0.8813\n",
            "Epoch 103/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4696 - accuracy: 0.8534\n",
            "Epoch 103: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4696 - accuracy: 0.8537 - val_loss: 0.4171 - val_accuracy: 0.8813\n",
            "Epoch 104/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4487 - accuracy: 0.8596\n",
            "Epoch 104: val_loss did not improve from 0.37100\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4494 - accuracy: 0.8594 - val_loss: 0.4134 - val_accuracy: 0.8798\n",
            "Epoch 105/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4439 - accuracy: 0.8617\n",
            "Epoch 105: val_loss improved from 0.37100 to 0.36285, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4445 - accuracy: 0.8617 - val_loss: 0.3628 - val_accuracy: 0.8898\n",
            "Epoch 106/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.8613\n",
            "Epoch 106: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4711 - accuracy: 0.8613 - val_loss: 0.4106 - val_accuracy: 0.8655\n",
            "Epoch 107/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4817 - accuracy: 0.8499\n",
            "Epoch 107: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4807 - accuracy: 0.8504 - val_loss: 0.4196 - val_accuracy: 0.8555\n",
            "Epoch 108/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4453 - accuracy: 0.8651\n",
            "Epoch 108: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4453 - accuracy: 0.8651 - val_loss: 0.3757 - val_accuracy: 0.8941\n",
            "Epoch 109/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4503 - accuracy: 0.8617\n",
            "Epoch 109: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4508 - accuracy: 0.8617 - val_loss: 0.4088 - val_accuracy: 0.8884\n",
            "Epoch 110/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4679 - accuracy: 0.8584\n",
            "Epoch 110: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4679 - accuracy: 0.8584 - val_loss: 0.4010 - val_accuracy: 0.8827\n",
            "Epoch 111/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4770 - accuracy: 0.8590\n",
            "Epoch 111: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4790 - accuracy: 0.8584 - val_loss: 0.3761 - val_accuracy: 0.9027\n",
            "Epoch 112/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4560 - accuracy: 0.8635\n",
            "Epoch 112: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4562 - accuracy: 0.8634 - val_loss: 0.3674 - val_accuracy: 0.8884\n",
            "Epoch 113/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4537 - accuracy: 0.8609\n",
            "Epoch 113: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4540 - accuracy: 0.8607 - val_loss: 0.3963 - val_accuracy: 0.8856\n",
            "Epoch 114/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4743 - accuracy: 0.8563\n",
            "Epoch 114: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4811 - accuracy: 0.8547 - val_loss: 0.3885 - val_accuracy: 0.8870\n",
            "Epoch 115/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4761 - accuracy: 0.8565\n",
            "Epoch 115: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4751 - accuracy: 0.8568 - val_loss: 0.3929 - val_accuracy: 0.8784\n",
            "Epoch 116/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4650 - accuracy: 0.8606\n",
            "Epoch 116: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4648 - accuracy: 0.8606 - val_loss: 0.3992 - val_accuracy: 0.8813\n",
            "Epoch 117/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4247 - accuracy: 0.8686\n",
            "Epoch 117: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4247 - accuracy: 0.8686 - val_loss: 0.3884 - val_accuracy: 0.8798\n",
            "Epoch 118/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.8723\n",
            "Epoch 118: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4221 - accuracy: 0.8723 - val_loss: 0.3700 - val_accuracy: 0.8898\n",
            "Epoch 119/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4505 - accuracy: 0.8663\n",
            "Epoch 119: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4498 - accuracy: 0.8664 - val_loss: 0.3782 - val_accuracy: 0.8970\n",
            "Epoch 120/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4526 - accuracy: 0.8627\n",
            "Epoch 120: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4517 - accuracy: 0.8630 - val_loss: 0.3961 - val_accuracy: 0.8956\n",
            "Epoch 121/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4226 - accuracy: 0.8704\n",
            "Epoch 121: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4218 - accuracy: 0.8706 - val_loss: 0.3973 - val_accuracy: 0.9027\n",
            "Epoch 122/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4535 - accuracy: 0.8626\n",
            "Epoch 122: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4522 - accuracy: 0.8631 - val_loss: 0.3860 - val_accuracy: 0.8884\n",
            "Epoch 123/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.8704\n",
            "Epoch 123: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4308 - accuracy: 0.8699 - val_loss: 0.3999 - val_accuracy: 0.8999\n",
            "Epoch 124/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4388 - accuracy: 0.8614\n",
            "Epoch 124: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4385 - accuracy: 0.8616 - val_loss: 0.3847 - val_accuracy: 0.8898\n",
            "Epoch 125/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4325 - accuracy: 0.8683\n",
            "Epoch 125: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4330 - accuracy: 0.8680 - val_loss: 0.4180 - val_accuracy: 0.8856\n",
            "Epoch 126/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4436 - accuracy: 0.8647\n",
            "Epoch 126: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4427 - accuracy: 0.8647 - val_loss: 0.4110 - val_accuracy: 0.8927\n",
            "Epoch 127/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4755 - accuracy: 0.8653\n",
            "Epoch 127: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4744 - accuracy: 0.8654 - val_loss: 0.4152 - val_accuracy: 0.8941\n",
            "Epoch 128/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4063 - accuracy: 0.8778\n",
            "Epoch 128: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4058 - accuracy: 0.8779 - val_loss: 0.4097 - val_accuracy: 0.8870\n",
            "Epoch 129/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4556 - accuracy: 0.8636\n",
            "Epoch 129: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4534 - accuracy: 0.8637 - val_loss: 0.4553 - val_accuracy: 0.8827\n",
            "Epoch 130/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4395 - accuracy: 0.8735\n",
            "Epoch 130: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4398 - accuracy: 0.8736 - val_loss: 0.3939 - val_accuracy: 0.8984\n",
            "Epoch 131/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4405 - accuracy: 0.8676\n",
            "Epoch 131: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4402 - accuracy: 0.8676 - val_loss: 0.4169 - val_accuracy: 0.8741\n",
            "Epoch 132/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4238 - accuracy: 0.8678\n",
            "Epoch 132: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4242 - accuracy: 0.8680 - val_loss: 0.4251 - val_accuracy: 0.8941\n",
            "Epoch 133/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4360 - accuracy: 0.8722\n",
            "Epoch 133: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4371 - accuracy: 0.8719 - val_loss: 0.4133 - val_accuracy: 0.8898\n",
            "Epoch 134/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4574 - accuracy: 0.8688\n",
            "Epoch 134: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4572 - accuracy: 0.8687 - val_loss: 0.3885 - val_accuracy: 0.8927\n",
            "Epoch 135/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4386 - accuracy: 0.8692\n",
            "Epoch 135: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4392 - accuracy: 0.8690 - val_loss: 0.4383 - val_accuracy: 0.8741\n",
            "Epoch 136/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4186 - accuracy: 0.8717\n",
            "Epoch 136: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4182 - accuracy: 0.8719 - val_loss: 0.4189 - val_accuracy: 0.8884\n",
            "Epoch 137/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4107 - accuracy: 0.8764\n",
            "Epoch 137: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4101 - accuracy: 0.8766 - val_loss: 0.4178 - val_accuracy: 0.8984\n",
            "Epoch 138/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4184 - accuracy: 0.8770\n",
            "Epoch 138: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4184 - accuracy: 0.8770 - val_loss: 0.4052 - val_accuracy: 0.8984\n",
            "Epoch 139/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4155 - accuracy: 0.8738\n",
            "Epoch 139: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4199 - accuracy: 0.8727 - val_loss: 0.4049 - val_accuracy: 0.8999\n",
            "Epoch 140/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4388 - accuracy: 0.8728\n",
            "Epoch 140: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4401 - accuracy: 0.8727 - val_loss: 0.3787 - val_accuracy: 0.8941\n",
            "Epoch 141/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4116 - accuracy: 0.8780\n",
            "Epoch 141: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4110 - accuracy: 0.8782 - val_loss: 0.3848 - val_accuracy: 0.8956\n",
            "Epoch 142/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4038 - accuracy: 0.8827\n",
            "Epoch 142: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4041 - accuracy: 0.8826 - val_loss: 0.3891 - val_accuracy: 0.8827\n",
            "Epoch 143/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3928 - accuracy: 0.8799\n",
            "Epoch 143: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3928 - accuracy: 0.8796 - val_loss: 0.3988 - val_accuracy: 0.8970\n",
            "Epoch 144/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4106 - accuracy: 0.8771\n",
            "Epoch 144: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4091 - accuracy: 0.8776 - val_loss: 0.3850 - val_accuracy: 0.8884\n",
            "Epoch 145/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4136 - accuracy: 0.8740\n",
            "Epoch 145: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4122 - accuracy: 0.8744 - val_loss: 0.3667 - val_accuracy: 0.8984\n",
            "Epoch 146/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4059 - accuracy: 0.8783\n",
            "Epoch 146: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4082 - accuracy: 0.8777 - val_loss: 0.4084 - val_accuracy: 0.8727\n",
            "Epoch 147/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4637 - accuracy: 0.8675\n",
            "Epoch 147: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4619 - accuracy: 0.8680 - val_loss: 0.4133 - val_accuracy: 0.8770\n",
            "Epoch 148/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.8775\n",
            "Epoch 148: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4002 - accuracy: 0.8775 - val_loss: 0.3737 - val_accuracy: 0.8970\n",
            "Epoch 149/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.8770\n",
            "Epoch 149: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4312 - accuracy: 0.8770 - val_loss: 0.3641 - val_accuracy: 0.8841\n",
            "Epoch 150/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3968 - accuracy: 0.8790\n",
            "Epoch 150: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3960 - accuracy: 0.8792 - val_loss: 0.3847 - val_accuracy: 0.8870\n",
            "Epoch 151/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.8772\n",
            "Epoch 151: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4131 - accuracy: 0.8772 - val_loss: 0.3941 - val_accuracy: 0.9041\n",
            "Epoch 152/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4534 - accuracy: 0.8691\n",
            "Epoch 152: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4536 - accuracy: 0.8691 - val_loss: 0.4007 - val_accuracy: 0.9056\n",
            "Epoch 153/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4294 - accuracy: 0.8774\n",
            "Epoch 153: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4281 - accuracy: 0.8777 - val_loss: 0.4007 - val_accuracy: 0.8913\n",
            "Epoch 154/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4131 - accuracy: 0.8806\n",
            "Epoch 154: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4153 - accuracy: 0.8797 - val_loss: 0.4221 - val_accuracy: 0.8827\n",
            "Epoch 155/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4417 - accuracy: 0.8745\n",
            "Epoch 155: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4430 - accuracy: 0.8744 - val_loss: 0.3667 - val_accuracy: 0.8941\n",
            "Epoch 156/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4348 - accuracy: 0.8747\n",
            "Epoch 156: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4348 - accuracy: 0.8747 - val_loss: 0.3948 - val_accuracy: 0.8941\n",
            "Epoch 157/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4354 - accuracy: 0.8759\n",
            "Epoch 157: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4354 - accuracy: 0.8759 - val_loss: 0.4948 - val_accuracy: 0.8741\n",
            "Epoch 158/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4581 - accuracy: 0.8688\n",
            "Epoch 158: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4577 - accuracy: 0.8689 - val_loss: 0.4430 - val_accuracy: 0.8741\n",
            "Epoch 159/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4182 - accuracy: 0.8717\n",
            "Epoch 159: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4174 - accuracy: 0.8719 - val_loss: 0.4078 - val_accuracy: 0.8984\n",
            "Epoch 160/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4182 - accuracy: 0.8742\n",
            "Epoch 160: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4182 - accuracy: 0.8742 - val_loss: 0.4160 - val_accuracy: 0.8927\n",
            "Epoch 161/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3978 - accuracy: 0.8849\n",
            "Epoch 161: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4011 - accuracy: 0.8843 - val_loss: 0.4249 - val_accuracy: 0.8884\n",
            "Epoch 162/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4106 - accuracy: 0.8784\n",
            "Epoch 162: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4101 - accuracy: 0.8786 - val_loss: 0.4657 - val_accuracy: 0.8841\n",
            "Epoch 163/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.8810\n",
            "Epoch 163: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3980 - accuracy: 0.8810 - val_loss: 0.4261 - val_accuracy: 0.9013\n",
            "Epoch 164/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4062 - accuracy: 0.8759\n",
            "Epoch 164: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4088 - accuracy: 0.8752 - val_loss: 0.3969 - val_accuracy: 0.8813\n",
            "Epoch 165/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8845\n",
            "Epoch 165: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3818 - accuracy: 0.8842 - val_loss: 0.4038 - val_accuracy: 0.8956\n",
            "Epoch 166/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4224 - accuracy: 0.8766\n",
            "Epoch 166: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4224 - accuracy: 0.8766 - val_loss: 0.4038 - val_accuracy: 0.8941\n",
            "Epoch 167/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4151 - accuracy: 0.8793\n",
            "Epoch 167: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4112 - accuracy: 0.8805 - val_loss: 0.3899 - val_accuracy: 0.8884\n",
            "Epoch 168/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4006 - accuracy: 0.8786\n",
            "Epoch 168: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4002 - accuracy: 0.8783 - val_loss: 0.3653 - val_accuracy: 0.9070\n",
            "Epoch 169/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.8843\n",
            "Epoch 169: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4041 - accuracy: 0.8843 - val_loss: 0.4091 - val_accuracy: 0.8927\n",
            "Epoch 170/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4173 - accuracy: 0.8748\n",
            "Epoch 170: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4218 - accuracy: 0.8743 - val_loss: 0.3714 - val_accuracy: 0.8941\n",
            "Epoch 171/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4316 - accuracy: 0.8729\n",
            "Epoch 171: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4306 - accuracy: 0.8733 - val_loss: 0.3937 - val_accuracy: 0.8898\n",
            "Epoch 172/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4091 - accuracy: 0.8786\n",
            "Epoch 172: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4082 - accuracy: 0.8789 - val_loss: 0.4085 - val_accuracy: 0.8913\n",
            "Epoch 173/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4046 - accuracy: 0.8788\n",
            "Epoch 173: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4043 - accuracy: 0.8790 - val_loss: 0.3645 - val_accuracy: 0.9027\n",
            "Epoch 174/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4170 - accuracy: 0.8784\n",
            "Epoch 174: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4181 - accuracy: 0.8780 - val_loss: 0.4059 - val_accuracy: 0.8984\n",
            "Epoch 175/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4026 - accuracy: 0.8803\n",
            "Epoch 175: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4058 - accuracy: 0.8802 - val_loss: 0.4304 - val_accuracy: 0.8913\n",
            "Epoch 176/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4272 - accuracy: 0.8783\n",
            "Epoch 176: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4267 - accuracy: 0.8783 - val_loss: 0.4109 - val_accuracy: 0.8927\n",
            "Epoch 177/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8865\n",
            "Epoch 177: val_loss did not improve from 0.36285\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3850 - accuracy: 0.8862 - val_loss: 0.4046 - val_accuracy: 0.8956\n",
            "Epoch 178/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4120 - accuracy: 0.8770\n",
            "Epoch 178: val_loss improved from 0.36285 to 0.35619, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4112 - accuracy: 0.8770 - val_loss: 0.3562 - val_accuracy: 0.9013\n",
            "Epoch 179/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3911 - accuracy: 0.8848\n",
            "Epoch 179: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3911 - accuracy: 0.8846 - val_loss: 0.3752 - val_accuracy: 0.8898\n",
            "Epoch 180/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4096 - accuracy: 0.8791\n",
            "Epoch 180: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4097 - accuracy: 0.8792 - val_loss: 0.3985 - val_accuracy: 0.8913\n",
            "Epoch 181/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.8823\n",
            "Epoch 181: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4047 - accuracy: 0.8823 - val_loss: 0.3645 - val_accuracy: 0.9127\n",
            "Epoch 182/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4234 - accuracy: 0.8777\n",
            "Epoch 182: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4220 - accuracy: 0.8782 - val_loss: 0.4054 - val_accuracy: 0.8884\n",
            "Epoch 183/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3976 - accuracy: 0.8925\n",
            "Epoch 183: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3963 - accuracy: 0.8926 - val_loss: 0.3965 - val_accuracy: 0.8856\n",
            "Epoch 184/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8819\n",
            "Epoch 184: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3864 - accuracy: 0.8817 - val_loss: 0.3862 - val_accuracy: 0.9041\n",
            "Epoch 185/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4070 - accuracy: 0.8824\n",
            "Epoch 185: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4091 - accuracy: 0.8822 - val_loss: 0.3874 - val_accuracy: 0.9056\n",
            "Epoch 186/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3672 - accuracy: 0.8886\n",
            "Epoch 186: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3672 - accuracy: 0.8886 - val_loss: 0.3899 - val_accuracy: 0.8999\n",
            "Epoch 187/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4552 - accuracy: 0.8751\n",
            "Epoch 187: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4543 - accuracy: 0.8753 - val_loss: 0.3995 - val_accuracy: 0.8941\n",
            "Epoch 188/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4196 - accuracy: 0.8745\n",
            "Epoch 188: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4214 - accuracy: 0.8744 - val_loss: 0.3707 - val_accuracy: 0.8941\n",
            "Epoch 189/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8894\n",
            "Epoch 189: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3798 - accuracy: 0.8893 - val_loss: 0.3759 - val_accuracy: 0.8970\n",
            "Epoch 190/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4168 - accuracy: 0.8775\n",
            "Epoch 190: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4151 - accuracy: 0.8779 - val_loss: 0.4056 - val_accuracy: 0.8913\n",
            "Epoch 191/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3745 - accuracy: 0.8872\n",
            "Epoch 191: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3757 - accuracy: 0.8870 - val_loss: 0.4128 - val_accuracy: 0.8913\n",
            "Epoch 192/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4001 - accuracy: 0.8858\n",
            "Epoch 192: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3990 - accuracy: 0.8856 - val_loss: 0.4488 - val_accuracy: 0.8798\n",
            "Epoch 193/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3678 - accuracy: 0.8887\n",
            "Epoch 193: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3667 - accuracy: 0.8886 - val_loss: 0.3962 - val_accuracy: 0.9041\n",
            "Epoch 194/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8879\n",
            "Epoch 194: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3782 - accuracy: 0.8888 - val_loss: 0.4057 - val_accuracy: 0.8984\n",
            "Epoch 195/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4064 - accuracy: 0.8858\n",
            "Epoch 195: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.4061 - accuracy: 0.8859 - val_loss: 0.4139 - val_accuracy: 0.8970\n",
            "Epoch 196/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3910 - accuracy: 0.8871\n",
            "Epoch 196: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3911 - accuracy: 0.8870 - val_loss: 0.4278 - val_accuracy: 0.9041\n",
            "Epoch 197/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3977 - accuracy: 0.8825\n",
            "Epoch 197: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.4025 - accuracy: 0.8820 - val_loss: 0.4063 - val_accuracy: 0.9013\n",
            "Epoch 198/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4021 - accuracy: 0.8839\n",
            "Epoch 198: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.4012 - accuracy: 0.8845 - val_loss: 0.4011 - val_accuracy: 0.8970\n",
            "Epoch 199/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3669 - accuracy: 0.8854\n",
            "Epoch 199: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3670 - accuracy: 0.8856 - val_loss: 0.4119 - val_accuracy: 0.8999\n",
            "Epoch 200/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4013 - accuracy: 0.8812\n",
            "Epoch 200: val_loss did not improve from 0.35619\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.4027 - accuracy: 0.8809 - val_loss: 0.4149 - val_accuracy: 0.8913\n",
            "Epoch 201/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3866 - accuracy: 0.8828\n",
            "Epoch 201: val_loss improved from 0.35619 to 0.34090, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3846 - accuracy: 0.8836 - val_loss: 0.3409 - val_accuracy: 0.9056\n",
            "Epoch 202/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8807\n",
            "Epoch 202: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3799 - accuracy: 0.8806 - val_loss: 0.4120 - val_accuracy: 0.9027\n",
            "Epoch 203/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.8948\n",
            "Epoch 203: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3720 - accuracy: 0.8948 - val_loss: 0.4362 - val_accuracy: 0.8813\n",
            "Epoch 204/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3699 - accuracy: 0.8912\n",
            "Epoch 204: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3697 - accuracy: 0.8915 - val_loss: 0.4503 - val_accuracy: 0.8984\n",
            "Epoch 205/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3924 - accuracy: 0.8852\n",
            "Epoch 205: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3924 - accuracy: 0.8845 - val_loss: 0.4124 - val_accuracy: 0.8884\n",
            "Epoch 206/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4140 - accuracy: 0.8775\n",
            "Epoch 206: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.4125 - accuracy: 0.8776 - val_loss: 0.3930 - val_accuracy: 0.8999\n",
            "Epoch 207/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4186 - accuracy: 0.8816\n",
            "Epoch 207: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.4217 - accuracy: 0.8813 - val_loss: 0.4151 - val_accuracy: 0.8970\n",
            "Epoch 208/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4225 - accuracy: 0.8787\n",
            "Epoch 208: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.4219 - accuracy: 0.8787 - val_loss: 0.3824 - val_accuracy: 0.8970\n",
            "Epoch 209/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3916 - accuracy: 0.8904\n",
            "Epoch 209: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3872 - accuracy: 0.8911 - val_loss: 0.3913 - val_accuracy: 0.8927\n",
            "Epoch 210/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4218 - accuracy: 0.8846\n",
            "Epoch 210: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.4222 - accuracy: 0.8846 - val_loss: 0.4110 - val_accuracy: 0.8798\n",
            "Epoch 211/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4464 - accuracy: 0.8793\n",
            "Epoch 211: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.4456 - accuracy: 0.8790 - val_loss: 0.4164 - val_accuracy: 0.8655\n",
            "Epoch 212/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4287 - accuracy: 0.8788\n",
            "Epoch 212: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.4301 - accuracy: 0.8785 - val_loss: 0.4073 - val_accuracy: 0.8784\n",
            "Epoch 213/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8854\n",
            "Epoch 213: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3857 - accuracy: 0.8856 - val_loss: 0.4208 - val_accuracy: 0.8913\n",
            "Epoch 214/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8888\n",
            "Epoch 214: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3863 - accuracy: 0.8885 - val_loss: 0.3956 - val_accuracy: 0.8956\n",
            "Epoch 215/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3764 - accuracy: 0.8901\n",
            "Epoch 215: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3771 - accuracy: 0.8896 - val_loss: 0.4180 - val_accuracy: 0.9013\n",
            "Epoch 216/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3647 - accuracy: 0.8922\n",
            "Epoch 216: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3650 - accuracy: 0.8921 - val_loss: 0.4240 - val_accuracy: 0.8984\n",
            "Epoch 217/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3569 - accuracy: 0.8938\n",
            "Epoch 217: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3566 - accuracy: 0.8936 - val_loss: 0.4019 - val_accuracy: 0.8913\n",
            "Epoch 218/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4062 - accuracy: 0.8823\n",
            "Epoch 218: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4061 - accuracy: 0.8822 - val_loss: 0.4382 - val_accuracy: 0.9013\n",
            "Epoch 219/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3952 - accuracy: 0.8892\n",
            "Epoch 219: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3940 - accuracy: 0.8895 - val_loss: 0.4776 - val_accuracy: 0.8841\n",
            "Epoch 220/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8886\n",
            "Epoch 220: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3884 - accuracy: 0.8888 - val_loss: 0.4304 - val_accuracy: 0.8984\n",
            "Epoch 221/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3949 - accuracy: 0.8855\n",
            "Epoch 221: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3952 - accuracy: 0.8850 - val_loss: 0.3889 - val_accuracy: 0.9056\n",
            "Epoch 222/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4210 - accuracy: 0.8807\n",
            "Epoch 222: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4191 - accuracy: 0.8809 - val_loss: 0.4136 - val_accuracy: 0.8827\n",
            "Epoch 223/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3999 - accuracy: 0.8872\n",
            "Epoch 223: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3989 - accuracy: 0.8875 - val_loss: 0.4006 - val_accuracy: 0.9013\n",
            "Epoch 224/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8894\n",
            "Epoch 224: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3915 - accuracy: 0.8893 - val_loss: 0.4226 - val_accuracy: 0.8927\n",
            "Epoch 225/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8869\n",
            "Epoch 225: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3866 - accuracy: 0.8872 - val_loss: 0.3966 - val_accuracy: 0.9099\n",
            "Epoch 226/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3765 - accuracy: 0.8928\n",
            "Epoch 226: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3757 - accuracy: 0.8932 - val_loss: 0.4256 - val_accuracy: 0.8984\n",
            "Epoch 227/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3914 - accuracy: 0.8876\n",
            "Epoch 227: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3946 - accuracy: 0.8873 - val_loss: 0.3980 - val_accuracy: 0.8898\n",
            "Epoch 228/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8865\n",
            "Epoch 228: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3796 - accuracy: 0.8868 - val_loss: 0.3772 - val_accuracy: 0.9013\n",
            "Epoch 229/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3555 - accuracy: 0.8903\n",
            "Epoch 229: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3537 - accuracy: 0.8911 - val_loss: 0.3878 - val_accuracy: 0.9027\n",
            "Epoch 230/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3739 - accuracy: 0.8940\n",
            "Epoch 230: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3730 - accuracy: 0.8942 - val_loss: 0.3896 - val_accuracy: 0.8841\n",
            "Epoch 231/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4065 - accuracy: 0.8904\n",
            "Epoch 231: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4062 - accuracy: 0.8905 - val_loss: 0.3845 - val_accuracy: 0.8798\n",
            "Epoch 232/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4060 - accuracy: 0.8868\n",
            "Epoch 232: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4053 - accuracy: 0.8870 - val_loss: 0.3994 - val_accuracy: 0.8927\n",
            "Epoch 233/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3990 - accuracy: 0.8878\n",
            "Epoch 233: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4000 - accuracy: 0.8878 - val_loss: 0.4020 - val_accuracy: 0.8870\n",
            "Epoch 234/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4295 - accuracy: 0.8872\n",
            "Epoch 234: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4310 - accuracy: 0.8866 - val_loss: 0.4170 - val_accuracy: 0.8884\n",
            "Epoch 235/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4606 - accuracy: 0.8755\n",
            "Epoch 235: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4596 - accuracy: 0.8756 - val_loss: 0.3774 - val_accuracy: 0.8941\n",
            "Epoch 236/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4325 - accuracy: 0.8814\n",
            "Epoch 236: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4338 - accuracy: 0.8810 - val_loss: 0.4022 - val_accuracy: 0.8827\n",
            "Epoch 237/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4091 - accuracy: 0.8865\n",
            "Epoch 237: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4094 - accuracy: 0.8863 - val_loss: 0.4622 - val_accuracy: 0.8941\n",
            "Epoch 238/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3919 - accuracy: 0.8865\n",
            "Epoch 238: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3916 - accuracy: 0.8865 - val_loss: 0.3976 - val_accuracy: 0.9013\n",
            "Epoch 239/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3754 - accuracy: 0.8961\n",
            "Epoch 239: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3765 - accuracy: 0.8956 - val_loss: 0.3687 - val_accuracy: 0.9027\n",
            "Epoch 240/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4049 - accuracy: 0.8894\n",
            "Epoch 240: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4038 - accuracy: 0.8895 - val_loss: 0.3943 - val_accuracy: 0.9027\n",
            "Epoch 241/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4167 - accuracy: 0.8891\n",
            "Epoch 241: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4156 - accuracy: 0.8890 - val_loss: 0.3652 - val_accuracy: 0.9027\n",
            "Epoch 242/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3487 - accuracy: 0.8954\n",
            "Epoch 242: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3477 - accuracy: 0.8958 - val_loss: 0.3595 - val_accuracy: 0.9041\n",
            "Epoch 243/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4098 - accuracy: 0.8873\n",
            "Epoch 243: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4092 - accuracy: 0.8873 - val_loss: 0.3882 - val_accuracy: 0.8856\n",
            "Epoch 244/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4170 - accuracy: 0.8829\n",
            "Epoch 244: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4164 - accuracy: 0.8830 - val_loss: 0.3512 - val_accuracy: 0.9142\n",
            "Epoch 245/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3678 - accuracy: 0.8976\n",
            "Epoch 245: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3671 - accuracy: 0.8978 - val_loss: 0.3734 - val_accuracy: 0.9056\n",
            "Epoch 246/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3537 - accuracy: 0.8993\n",
            "Epoch 246: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3544 - accuracy: 0.8994 - val_loss: 0.3903 - val_accuracy: 0.8856\n",
            "Epoch 247/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3937 - accuracy: 0.8882\n",
            "Epoch 247: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3938 - accuracy: 0.8883 - val_loss: 0.3624 - val_accuracy: 0.8927\n",
            "Epoch 248/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8919\n",
            "Epoch 248: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3814 - accuracy: 0.8919 - val_loss: 0.3898 - val_accuracy: 0.8927\n",
            "Epoch 249/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3583 - accuracy: 0.8938\n",
            "Epoch 249: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3600 - accuracy: 0.8933 - val_loss: 0.3799 - val_accuracy: 0.8984\n",
            "Epoch 250/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3781 - accuracy: 0.8902\n",
            "Epoch 250: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3772 - accuracy: 0.8903 - val_loss: 0.3676 - val_accuracy: 0.9013\n",
            "Epoch 251/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8889\n",
            "Epoch 251: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3885 - accuracy: 0.8885 - val_loss: 0.3620 - val_accuracy: 0.9070\n",
            "Epoch 252/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8897\n",
            "Epoch 252: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3893 - accuracy: 0.8896 - val_loss: 0.3745 - val_accuracy: 0.8927\n",
            "Epoch 253/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4046 - accuracy: 0.8873\n",
            "Epoch 253: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4052 - accuracy: 0.8870 - val_loss: 0.4025 - val_accuracy: 0.8784\n",
            "Epoch 254/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8935\n",
            "Epoch 254: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3847 - accuracy: 0.8936 - val_loss: 0.3831 - val_accuracy: 0.8856\n",
            "Epoch 255/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8925\n",
            "Epoch 255: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3865 - accuracy: 0.8923 - val_loss: 0.3752 - val_accuracy: 0.9041\n",
            "Epoch 256/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4247 - accuracy: 0.8873\n",
            "Epoch 256: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4244 - accuracy: 0.8873 - val_loss: 0.3416 - val_accuracy: 0.9113\n",
            "Epoch 257/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3911 - accuracy: 0.8855\n",
            "Epoch 257: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3899 - accuracy: 0.8858 - val_loss: 0.3727 - val_accuracy: 0.9013\n",
            "Epoch 258/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3602 - accuracy: 0.8967\n",
            "Epoch 258: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3592 - accuracy: 0.8969 - val_loss: 0.3689 - val_accuracy: 0.9056\n",
            "Epoch 259/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4081 - accuracy: 0.8856\n",
            "Epoch 259: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4072 - accuracy: 0.8859 - val_loss: 0.3756 - val_accuracy: 0.8999\n",
            "Epoch 260/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3568 - accuracy: 0.8981\n",
            "Epoch 260: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3561 - accuracy: 0.8985 - val_loss: 0.4109 - val_accuracy: 0.8913\n",
            "Epoch 261/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3522 - accuracy: 0.8980\n",
            "Epoch 261: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3509 - accuracy: 0.8984 - val_loss: 0.4365 - val_accuracy: 0.8970\n",
            "Epoch 262/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8957\n",
            "Epoch 262: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3835 - accuracy: 0.8946 - val_loss: 0.4061 - val_accuracy: 0.9027\n",
            "Epoch 263/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3754 - accuracy: 0.8931\n",
            "Epoch 263: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3749 - accuracy: 0.8931 - val_loss: 0.4155 - val_accuracy: 0.9127\n",
            "Epoch 264/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3614 - accuracy: 0.8923\n",
            "Epoch 264: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3600 - accuracy: 0.8925 - val_loss: 0.4005 - val_accuracy: 0.8927\n",
            "Epoch 265/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3556 - accuracy: 0.8984\n",
            "Epoch 265: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3569 - accuracy: 0.8981 - val_loss: 0.3786 - val_accuracy: 0.9013\n",
            "Epoch 266/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3676 - accuracy: 0.8945\n",
            "Epoch 266: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3666 - accuracy: 0.8948 - val_loss: 0.3427 - val_accuracy: 0.9142\n",
            "Epoch 267/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3559 - accuracy: 0.8991\n",
            "Epoch 267: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3554 - accuracy: 0.8992 - val_loss: 0.3839 - val_accuracy: 0.8970\n",
            "Epoch 268/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3439 - accuracy: 0.9040\n",
            "Epoch 268: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3437 - accuracy: 0.9041 - val_loss: 0.4043 - val_accuracy: 0.9013\n",
            "Epoch 269/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3902 - accuracy: 0.8935\n",
            "Epoch 269: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3933 - accuracy: 0.8933 - val_loss: 0.4846 - val_accuracy: 0.8813\n",
            "Epoch 270/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3930 - accuracy: 0.8822\n",
            "Epoch 270: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3925 - accuracy: 0.8823 - val_loss: 0.4535 - val_accuracy: 0.9084\n",
            "Epoch 271/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3747 - accuracy: 0.8951\n",
            "Epoch 271: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3737 - accuracy: 0.8953 - val_loss: 0.4157 - val_accuracy: 0.9056\n",
            "Epoch 272/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8906\n",
            "Epoch 272: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3886 - accuracy: 0.8908 - val_loss: 0.3699 - val_accuracy: 0.9013\n",
            "Epoch 273/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8927\n",
            "Epoch 273: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3807 - accuracy: 0.8931 - val_loss: 0.3648 - val_accuracy: 0.9070\n",
            "Epoch 274/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4040 - accuracy: 0.8847\n",
            "Epoch 274: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.4037 - accuracy: 0.8846 - val_loss: 0.3997 - val_accuracy: 0.8984\n",
            "Epoch 275/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8971\n",
            "Epoch 275: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3836 - accuracy: 0.8969 - val_loss: 0.3915 - val_accuracy: 0.9070\n",
            "Epoch 276/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4017 - accuracy: 0.8888\n",
            "Epoch 276: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3991 - accuracy: 0.8895 - val_loss: 0.4106 - val_accuracy: 0.8913\n",
            "Epoch 277/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8944\n",
            "Epoch 277: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3798 - accuracy: 0.8942 - val_loss: 0.3553 - val_accuracy: 0.9056\n",
            "Epoch 278/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3523 - accuracy: 0.8986\n",
            "Epoch 278: val_loss did not improve from 0.34090\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3532 - accuracy: 0.8981 - val_loss: 0.3720 - val_accuracy: 0.9041\n",
            "Epoch 279/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3485 - accuracy: 0.8996\n",
            "Epoch 279: val_loss improved from 0.34090 to 0.33211, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3488 - accuracy: 0.8994 - val_loss: 0.3321 - val_accuracy: 0.9185\n",
            "Epoch 280/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3455 - accuracy: 0.8988\n",
            "Epoch 280: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3442 - accuracy: 0.8994 - val_loss: 0.3353 - val_accuracy: 0.9156\n",
            "Epoch 281/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3436 - accuracy: 0.9038\n",
            "Epoch 281: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3432 - accuracy: 0.9035 - val_loss: 0.3730 - val_accuracy: 0.9084\n",
            "Epoch 282/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8912\n",
            "Epoch 282: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3784 - accuracy: 0.8916 - val_loss: 0.3571 - val_accuracy: 0.9027\n",
            "Epoch 283/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8952\n",
            "Epoch 283: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3794 - accuracy: 0.8955 - val_loss: 0.3575 - val_accuracy: 0.9041\n",
            "Epoch 284/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3971 - accuracy: 0.8911\n",
            "Epoch 284: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3971 - accuracy: 0.8913 - val_loss: 0.3916 - val_accuracy: 0.8970\n",
            "Epoch 285/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4058 - accuracy: 0.8917\n",
            "Epoch 285: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4057 - accuracy: 0.8918 - val_loss: 0.4235 - val_accuracy: 0.8870\n",
            "Epoch 286/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8907\n",
            "Epoch 286: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3850 - accuracy: 0.8902 - val_loss: 0.3933 - val_accuracy: 0.8970\n",
            "Epoch 287/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3997 - accuracy: 0.8895\n",
            "Epoch 287: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4013 - accuracy: 0.8892 - val_loss: 0.3580 - val_accuracy: 0.9070\n",
            "Epoch 288/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3957 - accuracy: 0.8872\n",
            "Epoch 288: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3960 - accuracy: 0.8875 - val_loss: 0.3916 - val_accuracy: 0.8913\n",
            "Epoch 289/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3772 - accuracy: 0.8987\n",
            "Epoch 289: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3765 - accuracy: 0.8988 - val_loss: 0.4164 - val_accuracy: 0.8999\n",
            "Epoch 290/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8899\n",
            "Epoch 290: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3828 - accuracy: 0.8896 - val_loss: 0.4136 - val_accuracy: 0.8970\n",
            "Epoch 291/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3919 - accuracy: 0.8919\n",
            "Epoch 291: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3911 - accuracy: 0.8925 - val_loss: 0.4014 - val_accuracy: 0.8984\n",
            "Epoch 292/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4150 - accuracy: 0.8892\n",
            "Epoch 292: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4141 - accuracy: 0.8893 - val_loss: 0.3421 - val_accuracy: 0.9127\n",
            "Epoch 293/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3762 - accuracy: 0.8953\n",
            "Epoch 293: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3745 - accuracy: 0.8956 - val_loss: 0.3582 - val_accuracy: 0.9142\n",
            "Epoch 294/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8965\n",
            "Epoch 294: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3788 - accuracy: 0.8968 - val_loss: 0.3859 - val_accuracy: 0.8984\n",
            "Epoch 295/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8970\n",
            "Epoch 295: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3862 - accuracy: 0.8969 - val_loss: 0.3998 - val_accuracy: 0.8856\n",
            "Epoch 296/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4281 - accuracy: 0.8846\n",
            "Epoch 296: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4285 - accuracy: 0.8845 - val_loss: 0.3716 - val_accuracy: 0.8999\n",
            "Epoch 297/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4110 - accuracy: 0.8899\n",
            "Epoch 297: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4110 - accuracy: 0.8898 - val_loss: 0.3698 - val_accuracy: 0.9027\n",
            "Epoch 298/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3982 - accuracy: 0.8883\n",
            "Epoch 298: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4002 - accuracy: 0.8878 - val_loss: 0.3978 - val_accuracy: 0.8984\n",
            "Epoch 299/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3610 - accuracy: 0.8991\n",
            "Epoch 299: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3632 - accuracy: 0.8986 - val_loss: 0.3555 - val_accuracy: 0.9113\n",
            "Epoch 300/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3687 - accuracy: 0.8962\n",
            "Epoch 300: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3671 - accuracy: 0.8963 - val_loss: 0.3808 - val_accuracy: 0.9027\n",
            "Epoch 301/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3612 - accuracy: 0.8993\n",
            "Epoch 301: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3606 - accuracy: 0.8995 - val_loss: 0.4083 - val_accuracy: 0.9113\n",
            "Epoch 302/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3683 - accuracy: 0.8961\n",
            "Epoch 302: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3682 - accuracy: 0.8961 - val_loss: 0.3665 - val_accuracy: 0.9027\n",
            "Epoch 303/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3413 - accuracy: 0.9012\n",
            "Epoch 303: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3409 - accuracy: 0.9014 - val_loss: 0.3726 - val_accuracy: 0.9113\n",
            "Epoch 304/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3640 - accuracy: 0.9000\n",
            "Epoch 304: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3642 - accuracy: 0.8999 - val_loss: 0.3894 - val_accuracy: 0.8970\n",
            "Epoch 305/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3645 - accuracy: 0.8969\n",
            "Epoch 305: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3635 - accuracy: 0.8965 - val_loss: 0.3602 - val_accuracy: 0.9142\n",
            "Epoch 306/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3659 - accuracy: 0.8993\n",
            "Epoch 306: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3669 - accuracy: 0.8985 - val_loss: 0.3956 - val_accuracy: 0.9070\n",
            "Epoch 307/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3511 - accuracy: 0.8946\n",
            "Epoch 307: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3496 - accuracy: 0.8951 - val_loss: 0.4094 - val_accuracy: 0.9113\n",
            "Epoch 308/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3545 - accuracy: 0.8999\n",
            "Epoch 308: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3543 - accuracy: 0.9001 - val_loss: 0.3711 - val_accuracy: 0.9199\n",
            "Epoch 309/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3737 - accuracy: 0.8968\n",
            "Epoch 309: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3722 - accuracy: 0.8975 - val_loss: 0.3486 - val_accuracy: 0.9070\n",
            "Epoch 310/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8990\n",
            "Epoch 310: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3871 - accuracy: 0.8988 - val_loss: 0.3790 - val_accuracy: 0.9056\n",
            "Epoch 311/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3672 - accuracy: 0.8958\n",
            "Epoch 311: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3659 - accuracy: 0.8961 - val_loss: 0.3830 - val_accuracy: 0.8984\n",
            "Epoch 312/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3442 - accuracy: 0.9010\n",
            "Epoch 312: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3440 - accuracy: 0.9008 - val_loss: 0.3464 - val_accuracy: 0.9070\n",
            "Epoch 313/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8942\n",
            "Epoch 313: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3846 - accuracy: 0.8942 - val_loss: 0.3758 - val_accuracy: 0.9013\n",
            "Epoch 314/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3298 - accuracy: 0.9065\n",
            "Epoch 314: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3290 - accuracy: 0.9067 - val_loss: 0.4089 - val_accuracy: 0.8970\n",
            "Epoch 315/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3389 - accuracy: 0.9030\n",
            "Epoch 315: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3384 - accuracy: 0.9031 - val_loss: 0.3688 - val_accuracy: 0.8984\n",
            "Epoch 316/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3743 - accuracy: 0.8951\n",
            "Epoch 316: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3740 - accuracy: 0.8953 - val_loss: 0.4344 - val_accuracy: 0.8956\n",
            "Epoch 317/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3433 - accuracy: 0.9094\n",
            "Epoch 317: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3455 - accuracy: 0.9092 - val_loss: 0.4681 - val_accuracy: 0.8941\n",
            "Epoch 318/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4237 - accuracy: 0.8901\n",
            "Epoch 318: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4232 - accuracy: 0.8901 - val_loss: 0.4024 - val_accuracy: 0.9070\n",
            "Epoch 319/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8986\n",
            "Epoch 319: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3805 - accuracy: 0.8988 - val_loss: 0.3818 - val_accuracy: 0.9170\n",
            "Epoch 320/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4212 - accuracy: 0.8905\n",
            "Epoch 320: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4207 - accuracy: 0.8908 - val_loss: 0.3897 - val_accuracy: 0.9027\n",
            "Epoch 321/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3601 - accuracy: 0.9009\n",
            "Epoch 321: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3597 - accuracy: 0.9006 - val_loss: 0.3712 - val_accuracy: 0.8927\n",
            "Epoch 322/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3930 - accuracy: 0.8948\n",
            "Epoch 322: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3921 - accuracy: 0.8946 - val_loss: 0.3708 - val_accuracy: 0.9041\n",
            "Epoch 323/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3552 - accuracy: 0.9043\n",
            "Epoch 323: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3549 - accuracy: 0.9045 - val_loss: 0.3804 - val_accuracy: 0.8984\n",
            "Epoch 324/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3465 - accuracy: 0.9017\n",
            "Epoch 324: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3455 - accuracy: 0.9019 - val_loss: 0.3978 - val_accuracy: 0.9070\n",
            "Epoch 325/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3700 - accuracy: 0.9010\n",
            "Epoch 325: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3694 - accuracy: 0.9009 - val_loss: 0.3963 - val_accuracy: 0.8984\n",
            "Epoch 326/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8968\n",
            "Epoch 326: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3852 - accuracy: 0.8968 - val_loss: 0.4433 - val_accuracy: 0.9041\n",
            "Epoch 327/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3686 - accuracy: 0.8950\n",
            "Epoch 327: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3678 - accuracy: 0.8952 - val_loss: 0.4332 - val_accuracy: 0.9084\n",
            "Epoch 328/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3539 - accuracy: 0.9010\n",
            "Epoch 328: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3504 - accuracy: 0.9016 - val_loss: 0.4825 - val_accuracy: 0.8970\n",
            "Epoch 329/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8968\n",
            "Epoch 329: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3819 - accuracy: 0.8969 - val_loss: 0.3869 - val_accuracy: 0.9027\n",
            "Epoch 330/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3706 - accuracy: 0.8987\n",
            "Epoch 330: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3724 - accuracy: 0.8991 - val_loss: 0.3512 - val_accuracy: 0.9213\n",
            "Epoch 331/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3507 - accuracy: 0.9047\n",
            "Epoch 331: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3512 - accuracy: 0.9045 - val_loss: 0.3428 - val_accuracy: 0.9270\n",
            "Epoch 332/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3712 - accuracy: 0.9037\n",
            "Epoch 332: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3712 - accuracy: 0.9039 - val_loss: 0.3458 - val_accuracy: 0.9027\n",
            "Epoch 333/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.9012\n",
            "Epoch 333: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3775 - accuracy: 0.9019 - val_loss: 0.3778 - val_accuracy: 0.9084\n",
            "Epoch 334/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3781 - accuracy: 0.8945\n",
            "Epoch 334: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3760 - accuracy: 0.8953 - val_loss: 0.4259 - val_accuracy: 0.8984\n",
            "Epoch 335/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3851 - accuracy: 0.8960\n",
            "Epoch 335: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3859 - accuracy: 0.8948 - val_loss: 0.3824 - val_accuracy: 0.9127\n",
            "Epoch 336/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3550 - accuracy: 0.9004\n",
            "Epoch 336: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3545 - accuracy: 0.9006 - val_loss: 0.3753 - val_accuracy: 0.9099\n",
            "Epoch 337/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3202 - accuracy: 0.9028\n",
            "Epoch 337: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3226 - accuracy: 0.9031 - val_loss: 0.3839 - val_accuracy: 0.9113\n",
            "Epoch 338/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3587 - accuracy: 0.9001\n",
            "Epoch 338: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3579 - accuracy: 0.9004 - val_loss: 0.3797 - val_accuracy: 0.9113\n",
            "Epoch 339/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3440 - accuracy: 0.9084\n",
            "Epoch 339: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3423 - accuracy: 0.9084 - val_loss: 0.3425 - val_accuracy: 0.9070\n",
            "Epoch 340/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4106 - accuracy: 0.8951\n",
            "Epoch 340: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4091 - accuracy: 0.8949 - val_loss: 0.3786 - val_accuracy: 0.9084\n",
            "Epoch 341/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3266 - accuracy: 0.9043\n",
            "Epoch 341: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3271 - accuracy: 0.9048 - val_loss: 0.3860 - val_accuracy: 0.9199\n",
            "Epoch 342/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3913 - accuracy: 0.8950\n",
            "Epoch 342: val_loss did not improve from 0.33211\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3892 - accuracy: 0.8953 - val_loss: 0.3453 - val_accuracy: 0.9113\n",
            "Epoch 343/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3736 - accuracy: 0.9022\n",
            "Epoch 343: val_loss improved from 0.33211 to 0.32905, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3704 - accuracy: 0.9026 - val_loss: 0.3291 - val_accuracy: 0.8970\n",
            "Epoch 344/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3556 - accuracy: 0.8974\n",
            "Epoch 344: val_loss did not improve from 0.32905\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3537 - accuracy: 0.8976 - val_loss: 0.3307 - val_accuracy: 0.9170\n",
            "Epoch 345/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3758 - accuracy: 0.9006\n",
            "Epoch 345: val_loss did not improve from 0.32905\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3785 - accuracy: 0.9001 - val_loss: 0.4006 - val_accuracy: 0.8941\n",
            "Epoch 346/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3657 - accuracy: 0.8986\n",
            "Epoch 346: val_loss improved from 0.32905 to 0.31951, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3649 - accuracy: 0.8985 - val_loss: 0.3195 - val_accuracy: 0.9084\n",
            "Epoch 347/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3555 - accuracy: 0.9046\n",
            "Epoch 347: val_loss improved from 0.31951 to 0.31846, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3571 - accuracy: 0.9042 - val_loss: 0.3185 - val_accuracy: 0.9185\n",
            "Epoch 348/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4083 - accuracy: 0.8929\n",
            "Epoch 348: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4090 - accuracy: 0.8925 - val_loss: 0.3811 - val_accuracy: 0.9056\n",
            "Epoch 349/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3795 - accuracy: 0.8914\n",
            "Epoch 349: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3781 - accuracy: 0.8921 - val_loss: 0.3804 - val_accuracy: 0.9056\n",
            "Epoch 350/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3757 - accuracy: 0.9013\n",
            "Epoch 350: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3764 - accuracy: 0.9015 - val_loss: 0.3620 - val_accuracy: 0.8999\n",
            "Epoch 351/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3725 - accuracy: 0.9009\n",
            "Epoch 351: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3726 - accuracy: 0.9011 - val_loss: 0.3276 - val_accuracy: 0.9113\n",
            "Epoch 352/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.8996\n",
            "Epoch 352: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3766 - accuracy: 0.8996 - val_loss: 0.3362 - val_accuracy: 0.9113\n",
            "Epoch 353/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3358 - accuracy: 0.9039\n",
            "Epoch 353: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3405 - accuracy: 0.9032 - val_loss: 0.3779 - val_accuracy: 0.9070\n",
            "Epoch 354/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3252 - accuracy: 0.9073\n",
            "Epoch 354: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3250 - accuracy: 0.9068 - val_loss: 0.3676 - val_accuracy: 0.8970\n",
            "Epoch 355/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3932 - accuracy: 0.8946\n",
            "Epoch 355: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3903 - accuracy: 0.8958 - val_loss: 0.3609 - val_accuracy: 0.9070\n",
            "Epoch 356/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3373 - accuracy: 0.9046\n",
            "Epoch 356: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3383 - accuracy: 0.9042 - val_loss: 0.3683 - val_accuracy: 0.9013\n",
            "Epoch 357/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3287 - accuracy: 0.9109\n",
            "Epoch 357: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3311 - accuracy: 0.9104 - val_loss: 0.3321 - val_accuracy: 0.9199\n",
            "Epoch 358/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.9031\n",
            "Epoch 358: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3793 - accuracy: 0.9029 - val_loss: 0.3471 - val_accuracy: 0.8913\n",
            "Epoch 359/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3691 - accuracy: 0.9018\n",
            "Epoch 359: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3648 - accuracy: 0.9022 - val_loss: 0.3336 - val_accuracy: 0.9156\n",
            "Epoch 360/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3758 - accuracy: 0.9007\n",
            "Epoch 360: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3769 - accuracy: 0.9001 - val_loss: 0.3283 - val_accuracy: 0.9156\n",
            "Epoch 361/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3653 - accuracy: 0.9003\n",
            "Epoch 361: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3630 - accuracy: 0.9008 - val_loss: 0.3831 - val_accuracy: 0.8956\n",
            "Epoch 362/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3912 - accuracy: 0.9010\n",
            "Epoch 362: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3904 - accuracy: 0.9009 - val_loss: 0.3417 - val_accuracy: 0.9099\n",
            "Epoch 363/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3781 - accuracy: 0.8965\n",
            "Epoch 363: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3760 - accuracy: 0.8965 - val_loss: 0.3575 - val_accuracy: 0.8984\n",
            "Epoch 364/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3741 - accuracy: 0.9009\n",
            "Epoch 364: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3741 - accuracy: 0.9009 - val_loss: 0.3417 - val_accuracy: 0.8927\n",
            "Epoch 365/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.9049\n",
            "Epoch 365: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3406 - accuracy: 0.9049 - val_loss: 0.3802 - val_accuracy: 0.9070\n",
            "Epoch 366/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4016 - accuracy: 0.8956\n",
            "Epoch 366: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4037 - accuracy: 0.8945 - val_loss: 0.3827 - val_accuracy: 0.9056\n",
            "Epoch 367/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3603 - accuracy: 0.8956\n",
            "Epoch 367: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3676 - accuracy: 0.8953 - val_loss: 0.3458 - val_accuracy: 0.9070\n",
            "Epoch 368/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3453 - accuracy: 0.9022\n",
            "Epoch 368: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3441 - accuracy: 0.9025 - val_loss: 0.3275 - val_accuracy: 0.9099\n",
            "Epoch 369/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3316 - accuracy: 0.9101\n",
            "Epoch 369: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3325 - accuracy: 0.9099 - val_loss: 0.3547 - val_accuracy: 0.9013\n",
            "Epoch 370/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.9047\n",
            "Epoch 370: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3800 - accuracy: 0.9038 - val_loss: 0.4046 - val_accuracy: 0.8784\n",
            "Epoch 371/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3753 - accuracy: 0.9018\n",
            "Epoch 371: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3717 - accuracy: 0.9021 - val_loss: 0.3495 - val_accuracy: 0.9013\n",
            "Epoch 372/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3515 - accuracy: 0.8997\n",
            "Epoch 372: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3485 - accuracy: 0.9008 - val_loss: 0.3962 - val_accuracy: 0.9084\n",
            "Epoch 373/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3487 - accuracy: 0.8991\n",
            "Epoch 373: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3487 - accuracy: 0.8991 - val_loss: 0.3792 - val_accuracy: 0.9127\n",
            "Epoch 374/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3200 - accuracy: 0.9089\n",
            "Epoch 374: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3202 - accuracy: 0.9088 - val_loss: 0.3484 - val_accuracy: 0.9056\n",
            "Epoch 375/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.9026\n",
            "Epoch 375: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3547 - accuracy: 0.9028 - val_loss: 0.3768 - val_accuracy: 0.9070\n",
            "Epoch 376/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3670 - accuracy: 0.9042\n",
            "Epoch 376: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3644 - accuracy: 0.9048 - val_loss: 0.3493 - val_accuracy: 0.9041\n",
            "Epoch 377/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3650 - accuracy: 0.9023\n",
            "Epoch 377: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3618 - accuracy: 0.9022 - val_loss: 0.3766 - val_accuracy: 0.9127\n",
            "Epoch 378/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4147 - accuracy: 0.8917\n",
            "Epoch 378: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.4138 - accuracy: 0.8918 - val_loss: 0.4013 - val_accuracy: 0.9013\n",
            "Epoch 379/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4012 - accuracy: 0.8943\n",
            "Epoch 379: val_loss did not improve from 0.31846\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3977 - accuracy: 0.8949 - val_loss: 0.3415 - val_accuracy: 0.9113\n",
            "Epoch 380/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3172 - accuracy: 0.9080\n",
            "Epoch 380: val_loss improved from 0.31846 to 0.30804, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3217 - accuracy: 0.9075 - val_loss: 0.3080 - val_accuracy: 0.9142\n",
            "Epoch 381/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3266 - accuracy: 0.9093\n",
            "Epoch 381: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3245 - accuracy: 0.9095 - val_loss: 0.3514 - val_accuracy: 0.9213\n",
            "Epoch 382/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.9054\n",
            "Epoch 382: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3396 - accuracy: 0.9057 - val_loss: 0.3620 - val_accuracy: 0.9070\n",
            "Epoch 383/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.9009\n",
            "Epoch 383: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3884 - accuracy: 0.9002 - val_loss: 0.3418 - val_accuracy: 0.9142\n",
            "Epoch 384/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3479 - accuracy: 0.9057\n",
            "Epoch 384: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3447 - accuracy: 0.9064 - val_loss: 0.3529 - val_accuracy: 0.9113\n",
            "Epoch 385/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3509 - accuracy: 0.9057\n",
            "Epoch 385: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3526 - accuracy: 0.9057 - val_loss: 0.3681 - val_accuracy: 0.9070\n",
            "Epoch 386/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.8985\n",
            "Epoch 386: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3906 - accuracy: 0.8985 - val_loss: 0.3863 - val_accuracy: 0.9070\n",
            "Epoch 387/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4026 - accuracy: 0.8994\n",
            "Epoch 387: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.4060 - accuracy: 0.8989 - val_loss: 0.3725 - val_accuracy: 0.9227\n",
            "Epoch 388/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4331 - accuracy: 0.8999\n",
            "Epoch 388: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.4334 - accuracy: 0.8998 - val_loss: 0.4278 - val_accuracy: 0.9027\n",
            "Epoch 389/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3428 - accuracy: 0.9093\n",
            "Epoch 389: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3431 - accuracy: 0.9087 - val_loss: 0.3921 - val_accuracy: 0.9113\n",
            "Epoch 390/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3590 - accuracy: 0.9076\n",
            "Epoch 390: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3646 - accuracy: 0.9067 - val_loss: 0.3287 - val_accuracy: 0.9142\n",
            "Epoch 391/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3635 - accuracy: 0.9007\n",
            "Epoch 391: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3638 - accuracy: 0.9008 - val_loss: 0.3633 - val_accuracy: 0.9056\n",
            "Epoch 392/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8928\n",
            "Epoch 392: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3859 - accuracy: 0.8931 - val_loss: 0.3467 - val_accuracy: 0.9127\n",
            "Epoch 393/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3247 - accuracy: 0.9098\n",
            "Epoch 393: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3378 - accuracy: 0.9085 - val_loss: 0.3659 - val_accuracy: 0.9185\n",
            "Epoch 394/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3736 - accuracy: 0.8979\n",
            "Epoch 394: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3710 - accuracy: 0.8985 - val_loss: 0.3544 - val_accuracy: 0.9199\n",
            "Epoch 395/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3771 - accuracy: 0.9038\n",
            "Epoch 395: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3764 - accuracy: 0.9042 - val_loss: 0.3678 - val_accuracy: 0.9156\n",
            "Epoch 396/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.9031\n",
            "Epoch 396: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3411 - accuracy: 0.9031 - val_loss: 0.4100 - val_accuracy: 0.9170\n",
            "Epoch 397/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3116 - accuracy: 0.9138\n",
            "Epoch 397: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3163 - accuracy: 0.9130 - val_loss: 0.3983 - val_accuracy: 0.9113\n",
            "Epoch 398/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3523 - accuracy: 0.9111\n",
            "Epoch 398: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3522 - accuracy: 0.9112 - val_loss: 0.3741 - val_accuracy: 0.9156\n",
            "Epoch 399/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3368 - accuracy: 0.9045\n",
            "Epoch 399: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3350 - accuracy: 0.9044 - val_loss: 0.3761 - val_accuracy: 0.9099\n",
            "Epoch 400/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.9010\n",
            "Epoch 400: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3856 - accuracy: 0.9005 - val_loss: 0.3938 - val_accuracy: 0.9070\n",
            "Epoch 401/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3729 - accuracy: 0.9031\n",
            "Epoch 401: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3737 - accuracy: 0.9032 - val_loss: 0.3692 - val_accuracy: 0.9070\n",
            "Epoch 402/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3368 - accuracy: 0.9024\n",
            "Epoch 402: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3364 - accuracy: 0.9026 - val_loss: 0.4106 - val_accuracy: 0.9041\n",
            "Epoch 403/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3415 - accuracy: 0.9088\n",
            "Epoch 403: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3381 - accuracy: 0.9097 - val_loss: 0.3989 - val_accuracy: 0.9156\n",
            "Epoch 404/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3598 - accuracy: 0.9039\n",
            "Epoch 404: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3593 - accuracy: 0.9041 - val_loss: 0.3646 - val_accuracy: 0.9156\n",
            "Epoch 405/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3451 - accuracy: 0.9102\n",
            "Epoch 405: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3451 - accuracy: 0.9104 - val_loss: 0.3945 - val_accuracy: 0.9185\n",
            "Epoch 406/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3551 - accuracy: 0.9019\n",
            "Epoch 406: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3525 - accuracy: 0.9029 - val_loss: 0.3760 - val_accuracy: 0.9056\n",
            "Epoch 407/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.9021\n",
            "Epoch 407: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3597 - accuracy: 0.9021 - val_loss: 0.3932 - val_accuracy: 0.9027\n",
            "Epoch 408/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3540 - accuracy: 0.9059\n",
            "Epoch 408: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3547 - accuracy: 0.9055 - val_loss: 0.3935 - val_accuracy: 0.9199\n",
            "Epoch 409/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8958\n",
            "Epoch 409: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3840 - accuracy: 0.8959 - val_loss: 0.4199 - val_accuracy: 0.9013\n",
            "Epoch 410/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3712 - accuracy: 0.8993\n",
            "Epoch 410: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3711 - accuracy: 0.8991 - val_loss: 0.3773 - val_accuracy: 0.9242\n",
            "Epoch 411/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3949 - accuracy: 0.9006\n",
            "Epoch 411: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3957 - accuracy: 0.9001 - val_loss: 0.3725 - val_accuracy: 0.9099\n",
            "Epoch 412/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3700 - accuracy: 0.9019\n",
            "Epoch 412: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3692 - accuracy: 0.9022 - val_loss: 0.4038 - val_accuracy: 0.9041\n",
            "Epoch 413/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4145 - accuracy: 0.8944\n",
            "Epoch 413: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4138 - accuracy: 0.8948 - val_loss: 0.4305 - val_accuracy: 0.8970\n",
            "Epoch 414/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3774 - accuracy: 0.8923\n",
            "Epoch 414: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3774 - accuracy: 0.8923 - val_loss: 0.4483 - val_accuracy: 0.9099\n",
            "Epoch 415/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3709 - accuracy: 0.9004\n",
            "Epoch 415: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3709 - accuracy: 0.9004 - val_loss: 0.4152 - val_accuracy: 0.9142\n",
            "Epoch 416/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3749 - accuracy: 0.9009\n",
            "Epoch 416: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3735 - accuracy: 0.9012 - val_loss: 0.4106 - val_accuracy: 0.9027\n",
            "Epoch 417/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3923 - accuracy: 0.9031\n",
            "Epoch 417: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3938 - accuracy: 0.9024 - val_loss: 0.4133 - val_accuracy: 0.8999\n",
            "Epoch 418/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.9035\n",
            "Epoch 418: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3809 - accuracy: 0.9031 - val_loss: 0.4154 - val_accuracy: 0.9256\n",
            "Epoch 419/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3768 - accuracy: 0.8973\n",
            "Epoch 419: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3759 - accuracy: 0.8985 - val_loss: 0.3869 - val_accuracy: 0.9099\n",
            "Epoch 420/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3632 - accuracy: 0.9036\n",
            "Epoch 420: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3627 - accuracy: 0.9037 - val_loss: 0.3974 - val_accuracy: 0.9127\n",
            "Epoch 421/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3519 - accuracy: 0.9059\n",
            "Epoch 421: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3489 - accuracy: 0.9061 - val_loss: 0.4058 - val_accuracy: 0.9070\n",
            "Epoch 422/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3631 - accuracy: 0.9082\n",
            "Epoch 422: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3876 - accuracy: 0.9074 - val_loss: 0.3757 - val_accuracy: 0.9056\n",
            "Epoch 423/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3644 - accuracy: 0.8986\n",
            "Epoch 423: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3644 - accuracy: 0.8986 - val_loss: 0.3631 - val_accuracy: 0.9070\n",
            "Epoch 424/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3303 - accuracy: 0.9070\n",
            "Epoch 424: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3288 - accuracy: 0.9075 - val_loss: 0.3564 - val_accuracy: 0.9185\n",
            "Epoch 425/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3670 - accuracy: 0.9069\n",
            "Epoch 425: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3652 - accuracy: 0.9068 - val_loss: 0.3689 - val_accuracy: 0.9113\n",
            "Epoch 426/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3200 - accuracy: 0.9098\n",
            "Epoch 426: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3186 - accuracy: 0.9101 - val_loss: 0.3987 - val_accuracy: 0.9113\n",
            "Epoch 427/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3122 - accuracy: 0.9099\n",
            "Epoch 427: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3122 - accuracy: 0.9099 - val_loss: 0.3761 - val_accuracy: 0.9084\n",
            "Epoch 428/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3561 - accuracy: 0.9048\n",
            "Epoch 428: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3527 - accuracy: 0.9057 - val_loss: 0.3922 - val_accuracy: 0.9113\n",
            "Epoch 429/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 0.9098\n",
            "Epoch 429: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3334 - accuracy: 0.9098 - val_loss: 0.3897 - val_accuracy: 0.9185\n",
            "Epoch 430/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3725 - accuracy: 0.9018\n",
            "Epoch 430: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3712 - accuracy: 0.9019 - val_loss: 0.3852 - val_accuracy: 0.9199\n",
            "Epoch 431/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3529 - accuracy: 0.9013\n",
            "Epoch 431: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3516 - accuracy: 0.9019 - val_loss: 0.4148 - val_accuracy: 0.8970\n",
            "Epoch 432/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3964 - accuracy: 0.8974\n",
            "Epoch 432: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3993 - accuracy: 0.8978 - val_loss: 0.3740 - val_accuracy: 0.9227\n",
            "Epoch 433/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3302 - accuracy: 0.9101\n",
            "Epoch 433: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3285 - accuracy: 0.9099 - val_loss: 0.3651 - val_accuracy: 0.9113\n",
            "Epoch 434/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3746 - accuracy: 0.9007\n",
            "Epoch 434: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3737 - accuracy: 0.9008 - val_loss: 0.3355 - val_accuracy: 0.9213\n",
            "Epoch 435/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3651 - accuracy: 0.9053\n",
            "Epoch 435: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3673 - accuracy: 0.9059 - val_loss: 0.4147 - val_accuracy: 0.8941\n",
            "Epoch 436/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3775 - accuracy: 0.8997\n",
            "Epoch 436: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3816 - accuracy: 0.8985 - val_loss: 0.4038 - val_accuracy: 0.9185\n",
            "Epoch 437/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3438 - accuracy: 0.9143\n",
            "Epoch 437: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3437 - accuracy: 0.9137 - val_loss: 0.3538 - val_accuracy: 0.9113\n",
            "Epoch 438/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3299 - accuracy: 0.9069\n",
            "Epoch 438: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3291 - accuracy: 0.9071 - val_loss: 0.3635 - val_accuracy: 0.9027\n",
            "Epoch 439/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3550 - accuracy: 0.9077\n",
            "Epoch 439: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3560 - accuracy: 0.9079 - val_loss: 0.3727 - val_accuracy: 0.8999\n",
            "Epoch 440/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3512 - accuracy: 0.9038\n",
            "Epoch 440: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3501 - accuracy: 0.9045 - val_loss: 0.3309 - val_accuracy: 0.9099\n",
            "Epoch 441/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3523 - accuracy: 0.9048\n",
            "Epoch 441: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3553 - accuracy: 0.9035 - val_loss: 0.3635 - val_accuracy: 0.9127\n",
            "Epoch 442/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3417 - accuracy: 0.9058\n",
            "Epoch 442: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3452 - accuracy: 0.9048 - val_loss: 0.4204 - val_accuracy: 0.9056\n",
            "Epoch 443/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3303 - accuracy: 0.9121\n",
            "Epoch 443: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3334 - accuracy: 0.9112 - val_loss: 0.4004 - val_accuracy: 0.9084\n",
            "Epoch 444/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3920 - accuracy: 0.8960\n",
            "Epoch 444: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3926 - accuracy: 0.8963 - val_loss: 0.3507 - val_accuracy: 0.9127\n",
            "Epoch 445/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3048 - accuracy: 0.9113\n",
            "Epoch 445: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3118 - accuracy: 0.9098 - val_loss: 0.3705 - val_accuracy: 0.9099\n",
            "Epoch 446/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3607 - accuracy: 0.9010\n",
            "Epoch 446: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3591 - accuracy: 0.9015 - val_loss: 0.3605 - val_accuracy: 0.9056\n",
            "Epoch 447/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3540 - accuracy: 0.9101\n",
            "Epoch 447: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3534 - accuracy: 0.9102 - val_loss: 0.3739 - val_accuracy: 0.9070\n",
            "Epoch 448/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3613 - accuracy: 0.9071\n",
            "Epoch 448: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3602 - accuracy: 0.9071 - val_loss: 0.3155 - val_accuracy: 0.9113\n",
            "Epoch 449/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3523 - accuracy: 0.9038\n",
            "Epoch 449: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3523 - accuracy: 0.9038 - val_loss: 0.3280 - val_accuracy: 0.9070\n",
            "Epoch 450/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.9031\n",
            "Epoch 450: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3879 - accuracy: 0.9034 - val_loss: 0.3395 - val_accuracy: 0.8956\n",
            "Epoch 451/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3434 - accuracy: 0.9123\n",
            "Epoch 451: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3420 - accuracy: 0.9127 - val_loss: 0.3357 - val_accuracy: 0.9070\n",
            "Epoch 452/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3296 - accuracy: 0.9111\n",
            "Epoch 452: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3281 - accuracy: 0.9115 - val_loss: 0.3454 - val_accuracy: 0.9099\n",
            "Epoch 453/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3251 - accuracy: 0.9120\n",
            "Epoch 453: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3263 - accuracy: 0.9115 - val_loss: 0.3729 - val_accuracy: 0.8970\n",
            "Epoch 454/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3519 - accuracy: 0.9025\n",
            "Epoch 454: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3504 - accuracy: 0.9028 - val_loss: 0.3899 - val_accuracy: 0.9041\n",
            "Epoch 455/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3496 - accuracy: 0.9082\n",
            "Epoch 455: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3490 - accuracy: 0.9084 - val_loss: 0.3435 - val_accuracy: 0.9056\n",
            "Epoch 456/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3581 - accuracy: 0.9072\n",
            "Epoch 456: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3602 - accuracy: 0.9069 - val_loss: 0.3690 - val_accuracy: 0.9099\n",
            "Epoch 457/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3405 - accuracy: 0.9066\n",
            "Epoch 457: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3425 - accuracy: 0.9064 - val_loss: 0.3562 - val_accuracy: 0.9113\n",
            "Epoch 458/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.9065\n",
            "Epoch 458: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3865 - accuracy: 0.9065 - val_loss: 0.4062 - val_accuracy: 0.9142\n",
            "Epoch 459/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.9041\n",
            "Epoch 459: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3883 - accuracy: 0.9039 - val_loss: 0.3282 - val_accuracy: 0.9084\n",
            "Epoch 460/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3677 - accuracy: 0.9047\n",
            "Epoch 460: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3665 - accuracy: 0.9052 - val_loss: 0.3657 - val_accuracy: 0.9185\n",
            "Epoch 461/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3458 - accuracy: 0.9121\n",
            "Epoch 461: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3459 - accuracy: 0.9121 - val_loss: 0.3497 - val_accuracy: 0.9185\n",
            "Epoch 462/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3692 - accuracy: 0.9059\n",
            "Epoch 462: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3678 - accuracy: 0.9064 - val_loss: 0.3669 - val_accuracy: 0.9099\n",
            "Epoch 463/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3778 - accuracy: 0.9022\n",
            "Epoch 463: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3771 - accuracy: 0.9022 - val_loss: 0.3605 - val_accuracy: 0.9170\n",
            "Epoch 464/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3570 - accuracy: 0.9104\n",
            "Epoch 464: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3559 - accuracy: 0.9107 - val_loss: 0.3724 - val_accuracy: 0.9084\n",
            "Epoch 465/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4332 - accuracy: 0.8970\n",
            "Epoch 465: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.4352 - accuracy: 0.8971 - val_loss: 0.4081 - val_accuracy: 0.9027\n",
            "Epoch 466/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3952 - accuracy: 0.8991\n",
            "Epoch 466: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3940 - accuracy: 0.8994 - val_loss: 0.3455 - val_accuracy: 0.9156\n",
            "Epoch 467/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3036 - accuracy: 0.9165\n",
            "Epoch 467: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3036 - accuracy: 0.9165 - val_loss: 0.4046 - val_accuracy: 0.9041\n",
            "Epoch 468/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3620 - accuracy: 0.9075\n",
            "Epoch 468: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3631 - accuracy: 0.9074 - val_loss: 0.3970 - val_accuracy: 0.9127\n",
            "Epoch 469/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3912 - accuracy: 0.8988\n",
            "Epoch 469: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.4070 - accuracy: 0.8985 - val_loss: 0.3800 - val_accuracy: 0.9084\n",
            "Epoch 470/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3748 - accuracy: 0.9009\n",
            "Epoch 470: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3815 - accuracy: 0.9009 - val_loss: 0.3626 - val_accuracy: 0.9084\n",
            "Epoch 471/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.9148\n",
            "Epoch 471: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3225 - accuracy: 0.9148 - val_loss: 0.3745 - val_accuracy: 0.9170\n",
            "Epoch 472/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3341 - accuracy: 0.9104\n",
            "Epoch 472: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3343 - accuracy: 0.9101 - val_loss: 0.3706 - val_accuracy: 0.9027\n",
            "Epoch 473/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3476 - accuracy: 0.9055\n",
            "Epoch 473: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3487 - accuracy: 0.9057 - val_loss: 0.3851 - val_accuracy: 0.9013\n",
            "Epoch 474/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3583 - accuracy: 0.9110\n",
            "Epoch 474: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3552 - accuracy: 0.9111 - val_loss: 0.4015 - val_accuracy: 0.9113\n",
            "Epoch 475/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.9032\n",
            "Epoch 475: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3829 - accuracy: 0.9034 - val_loss: 0.3937 - val_accuracy: 0.9142\n",
            "Epoch 476/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3353 - accuracy: 0.9139\n",
            "Epoch 476: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3356 - accuracy: 0.9134 - val_loss: 0.4027 - val_accuracy: 0.9142\n",
            "Epoch 477/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3454 - accuracy: 0.9121\n",
            "Epoch 477: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3474 - accuracy: 0.9111 - val_loss: 0.4576 - val_accuracy: 0.9142\n",
            "Epoch 478/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4030 - accuracy: 0.9026\n",
            "Epoch 478: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.4007 - accuracy: 0.9029 - val_loss: 0.4096 - val_accuracy: 0.8898\n",
            "Epoch 479/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3452 - accuracy: 0.9006\n",
            "Epoch 479: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3454 - accuracy: 0.8999 - val_loss: 0.3432 - val_accuracy: 0.9113\n",
            "Epoch 480/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3542 - accuracy: 0.9037\n",
            "Epoch 480: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3542 - accuracy: 0.9037 - val_loss: 0.3625 - val_accuracy: 0.9013\n",
            "Epoch 481/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3720 - accuracy: 0.9023\n",
            "Epoch 481: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3707 - accuracy: 0.9025 - val_loss: 0.3799 - val_accuracy: 0.9127\n",
            "Epoch 482/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3466 - accuracy: 0.9059\n",
            "Epoch 482: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3450 - accuracy: 0.9064 - val_loss: 0.3742 - val_accuracy: 0.9142\n",
            "Epoch 483/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3346 - accuracy: 0.9137\n",
            "Epoch 483: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3346 - accuracy: 0.9137 - val_loss: 0.3536 - val_accuracy: 0.9185\n",
            "Epoch 484/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3465 - accuracy: 0.9081\n",
            "Epoch 484: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3444 - accuracy: 0.9081 - val_loss: 0.4086 - val_accuracy: 0.9056\n",
            "Epoch 485/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3696 - accuracy: 0.9043\n",
            "Epoch 485: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3695 - accuracy: 0.9038 - val_loss: 0.3743 - val_accuracy: 0.9127\n",
            "Epoch 486/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3604 - accuracy: 0.9042\n",
            "Epoch 486: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3607 - accuracy: 0.9042 - val_loss: 0.3819 - val_accuracy: 0.9185\n",
            "Epoch 487/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3626 - accuracy: 0.9094\n",
            "Epoch 487: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3626 - accuracy: 0.9094 - val_loss: 0.4044 - val_accuracy: 0.8927\n",
            "Epoch 488/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3772 - accuracy: 0.9003\n",
            "Epoch 488: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3747 - accuracy: 0.9008 - val_loss: 0.3700 - val_accuracy: 0.9070\n",
            "Epoch 489/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3496 - accuracy: 0.9070\n",
            "Epoch 489: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3460 - accuracy: 0.9072 - val_loss: 0.3505 - val_accuracy: 0.9127\n",
            "Epoch 490/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3180 - accuracy: 0.9129\n",
            "Epoch 490: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3333 - accuracy: 0.9137 - val_loss: 0.4026 - val_accuracy: 0.9099\n",
            "Epoch 491/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3370 - accuracy: 0.9131\n",
            "Epoch 491: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3351 - accuracy: 0.9131 - val_loss: 0.4130 - val_accuracy: 0.9070\n",
            "Epoch 492/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3652 - accuracy: 0.9100\n",
            "Epoch 492: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3624 - accuracy: 0.9105 - val_loss: 0.3813 - val_accuracy: 0.9084\n",
            "Epoch 493/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3646 - accuracy: 0.9077\n",
            "Epoch 493: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3705 - accuracy: 0.9077 - val_loss: 0.3694 - val_accuracy: 0.9056\n",
            "Epoch 494/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.9050\n",
            "Epoch 494: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3822 - accuracy: 0.9054 - val_loss: 0.3832 - val_accuracy: 0.9099\n",
            "Epoch 495/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3535 - accuracy: 0.9091\n",
            "Epoch 495: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3535 - accuracy: 0.9091 - val_loss: 0.4288 - val_accuracy: 0.9056\n",
            "Epoch 496/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3313 - accuracy: 0.9110\n",
            "Epoch 496: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3267 - accuracy: 0.9120 - val_loss: 0.3325 - val_accuracy: 0.9027\n",
            "Epoch 497/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3522 - accuracy: 0.9032\n",
            "Epoch 497: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3517 - accuracy: 0.9031 - val_loss: 0.3658 - val_accuracy: 0.9170\n",
            "Epoch 498/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3371 - accuracy: 0.9096\n",
            "Epoch 498: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3429 - accuracy: 0.9079 - val_loss: 0.3637 - val_accuracy: 0.9142\n",
            "Epoch 499/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3499 - accuracy: 0.9100\n",
            "Epoch 499: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3493 - accuracy: 0.9099 - val_loss: 0.4135 - val_accuracy: 0.9099\n",
            "Epoch 500/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.9057\n",
            "Epoch 500: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3771 - accuracy: 0.9061 - val_loss: 0.4161 - val_accuracy: 0.9027\n",
            "Epoch 501/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3750 - accuracy: 0.9055\n",
            "Epoch 501: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3750 - accuracy: 0.9055 - val_loss: 0.3973 - val_accuracy: 0.8956\n",
            "Epoch 502/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3363 - accuracy: 0.9101\n",
            "Epoch 502: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3352 - accuracy: 0.9101 - val_loss: 0.4540 - val_accuracy: 0.9084\n",
            "Epoch 503/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3215 - accuracy: 0.9182\n",
            "Epoch 503: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3213 - accuracy: 0.9181 - val_loss: 0.5056 - val_accuracy: 0.9113\n",
            "Epoch 504/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3602 - accuracy: 0.9067\n",
            "Epoch 504: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3571 - accuracy: 0.9069 - val_loss: 0.4338 - val_accuracy: 0.9170\n",
            "Epoch 505/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3347 - accuracy: 0.9090\n",
            "Epoch 505: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3363 - accuracy: 0.9088 - val_loss: 0.4864 - val_accuracy: 0.9099\n",
            "Epoch 506/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3490 - accuracy: 0.9048\n",
            "Epoch 506: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3502 - accuracy: 0.9044 - val_loss: 0.4239 - val_accuracy: 0.9170\n",
            "Epoch 507/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3420 - accuracy: 0.9138\n",
            "Epoch 507: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3412 - accuracy: 0.9140 - val_loss: 0.4315 - val_accuracy: 0.9113\n",
            "Epoch 508/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3905 - accuracy: 0.9091\n",
            "Epoch 508: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3900 - accuracy: 0.9089 - val_loss: 0.4292 - val_accuracy: 0.9170\n",
            "Epoch 509/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3423 - accuracy: 0.9055\n",
            "Epoch 509: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3397 - accuracy: 0.9059 - val_loss: 0.3640 - val_accuracy: 0.9213\n",
            "Epoch 510/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3785 - accuracy: 0.9032\n",
            "Epoch 510: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3799 - accuracy: 0.9026 - val_loss: 0.4131 - val_accuracy: 0.9113\n",
            "Epoch 511/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3521 - accuracy: 0.9113\n",
            "Epoch 511: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3530 - accuracy: 0.9107 - val_loss: 0.3927 - val_accuracy: 0.9127\n",
            "Epoch 512/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3065 - accuracy: 0.9176\n",
            "Epoch 512: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3081 - accuracy: 0.9173 - val_loss: 0.3889 - val_accuracy: 0.9041\n",
            "Epoch 513/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3501 - accuracy: 0.9142\n",
            "Epoch 513: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3492 - accuracy: 0.9140 - val_loss: 0.3780 - val_accuracy: 0.9127\n",
            "Epoch 514/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3238 - accuracy: 0.9131\n",
            "Epoch 514: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3238 - accuracy: 0.9131 - val_loss: 0.4318 - val_accuracy: 0.9041\n",
            "Epoch 515/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3547 - accuracy: 0.9069\n",
            "Epoch 515: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3545 - accuracy: 0.9068 - val_loss: 0.4597 - val_accuracy: 0.9113\n",
            "Epoch 516/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.9044\n",
            "Epoch 516: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3785 - accuracy: 0.9051 - val_loss: 0.3900 - val_accuracy: 0.8999\n",
            "Epoch 517/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3404 - accuracy: 0.9087\n",
            "Epoch 517: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3378 - accuracy: 0.9097 - val_loss: 0.3905 - val_accuracy: 0.9142\n",
            "Epoch 518/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3547 - accuracy: 0.9066\n",
            "Epoch 518: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3540 - accuracy: 0.9069 - val_loss: 0.4138 - val_accuracy: 0.9056\n",
            "Epoch 519/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3368 - accuracy: 0.9104\n",
            "Epoch 519: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3343 - accuracy: 0.9115 - val_loss: 0.4361 - val_accuracy: 0.9056\n",
            "Epoch 520/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3602 - accuracy: 0.9079\n",
            "Epoch 520: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3567 - accuracy: 0.9082 - val_loss: 0.4700 - val_accuracy: 0.8956\n",
            "Epoch 521/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.9077\n",
            "Epoch 521: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4021 - accuracy: 0.9077 - val_loss: 0.3545 - val_accuracy: 0.9070\n",
            "Epoch 522/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3436 - accuracy: 0.9093\n",
            "Epoch 522: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3401 - accuracy: 0.9098 - val_loss: 0.4212 - val_accuracy: 0.9127\n",
            "Epoch 523/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3523 - accuracy: 0.9101\n",
            "Epoch 523: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3501 - accuracy: 0.9105 - val_loss: 0.4454 - val_accuracy: 0.9084\n",
            "Epoch 524/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3966 - accuracy: 0.9004\n",
            "Epoch 524: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3954 - accuracy: 0.9005 - val_loss: 0.4124 - val_accuracy: 0.9041\n",
            "Epoch 525/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3633 - accuracy: 0.9074\n",
            "Epoch 525: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.3680 - accuracy: 0.9061 - val_loss: 0.4063 - val_accuracy: 0.8956\n",
            "Epoch 526/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3266 - accuracy: 0.9101\n",
            "Epoch 526: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3274 - accuracy: 0.9095 - val_loss: 0.4498 - val_accuracy: 0.9056\n",
            "Epoch 527/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4102 - accuracy: 0.9060\n",
            "Epoch 527: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4078 - accuracy: 0.9065 - val_loss: 0.4437 - val_accuracy: 0.9013\n",
            "Epoch 528/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3461 - accuracy: 0.9064\n",
            "Epoch 528: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3461 - accuracy: 0.9064 - val_loss: 0.3984 - val_accuracy: 0.9142\n",
            "Epoch 529/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3357 - accuracy: 0.9144\n",
            "Epoch 529: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3323 - accuracy: 0.9148 - val_loss: 0.3911 - val_accuracy: 0.9142\n",
            "Epoch 530/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3641 - accuracy: 0.9116\n",
            "Epoch 530: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3612 - accuracy: 0.9118 - val_loss: 0.4660 - val_accuracy: 0.9156\n",
            "Epoch 531/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3296 - accuracy: 0.9133\n",
            "Epoch 531: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3342 - accuracy: 0.9137 - val_loss: 0.4345 - val_accuracy: 0.9199\n",
            "Epoch 532/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3357 - accuracy: 0.9119\n",
            "Epoch 532: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3347 - accuracy: 0.9117 - val_loss: 0.4194 - val_accuracy: 0.9185\n",
            "Epoch 533/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3835 - accuracy: 0.9089\n",
            "Epoch 533: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3847 - accuracy: 0.9092 - val_loss: 0.3840 - val_accuracy: 0.9127\n",
            "Epoch 534/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3561 - accuracy: 0.9079\n",
            "Epoch 534: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3563 - accuracy: 0.9072 - val_loss: 0.3766 - val_accuracy: 0.9113\n",
            "Epoch 535/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3615 - accuracy: 0.9130\n",
            "Epoch 535: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3611 - accuracy: 0.9125 - val_loss: 0.4102 - val_accuracy: 0.9127\n",
            "Epoch 536/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3432 - accuracy: 0.9091\n",
            "Epoch 536: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3446 - accuracy: 0.9087 - val_loss: 0.4143 - val_accuracy: 0.9084\n",
            "Epoch 537/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3992 - accuracy: 0.9015\n",
            "Epoch 537: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3977 - accuracy: 0.9009 - val_loss: 0.3980 - val_accuracy: 0.9127\n",
            "Epoch 538/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.9118\n",
            "Epoch 538: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3242 - accuracy: 0.9120 - val_loss: 0.4333 - val_accuracy: 0.9185\n",
            "Epoch 539/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3974 - accuracy: 0.9038\n",
            "Epoch 539: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3937 - accuracy: 0.9039 - val_loss: 0.4342 - val_accuracy: 0.9013\n",
            "Epoch 540/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3589 - accuracy: 0.9099\n",
            "Epoch 540: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3562 - accuracy: 0.9104 - val_loss: 0.4125 - val_accuracy: 0.9099\n",
            "Epoch 541/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4036 - accuracy: 0.9101\n",
            "Epoch 541: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4057 - accuracy: 0.9097 - val_loss: 0.3619 - val_accuracy: 0.9199\n",
            "Epoch 542/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3770 - accuracy: 0.9114\n",
            "Epoch 542: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3748 - accuracy: 0.9112 - val_loss: 0.4304 - val_accuracy: 0.9013\n",
            "Epoch 543/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3308 - accuracy: 0.9123\n",
            "Epoch 543: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3335 - accuracy: 0.9117 - val_loss: 0.4122 - val_accuracy: 0.9070\n",
            "Epoch 544/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3689 - accuracy: 0.9098\n",
            "Epoch 544: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3680 - accuracy: 0.9097 - val_loss: 0.4350 - val_accuracy: 0.9070\n",
            "Epoch 545/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.9165\n",
            "Epoch 545: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3219 - accuracy: 0.9165 - val_loss: 0.4269 - val_accuracy: 0.9070\n",
            "Epoch 546/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3203 - accuracy: 0.9178\n",
            "Epoch 546: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3202 - accuracy: 0.9175 - val_loss: 0.4289 - val_accuracy: 0.9156\n",
            "Epoch 547/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3614 - accuracy: 0.9105\n",
            "Epoch 547: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3602 - accuracy: 0.9108 - val_loss: 0.3964 - val_accuracy: 0.9270\n",
            "Epoch 548/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.9141\n",
            "Epoch 548: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3406 - accuracy: 0.9138 - val_loss: 0.3647 - val_accuracy: 0.9156\n",
            "Epoch 549/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3725 - accuracy: 0.9082\n",
            "Epoch 549: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3707 - accuracy: 0.9088 - val_loss: 0.4071 - val_accuracy: 0.9213\n",
            "Epoch 550/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3619 - accuracy: 0.9036\n",
            "Epoch 550: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3583 - accuracy: 0.9044 - val_loss: 0.3756 - val_accuracy: 0.9127\n",
            "Epoch 551/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3435 - accuracy: 0.9135\n",
            "Epoch 551: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3431 - accuracy: 0.9131 - val_loss: 0.4076 - val_accuracy: 0.9099\n",
            "Epoch 552/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3339 - accuracy: 0.9109\n",
            "Epoch 552: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3356 - accuracy: 0.9107 - val_loss: 0.3672 - val_accuracy: 0.9199\n",
            "Epoch 553/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3337 - accuracy: 0.9147\n",
            "Epoch 553: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3332 - accuracy: 0.9151 - val_loss: 0.3762 - val_accuracy: 0.9185\n",
            "Epoch 554/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3141 - accuracy: 0.9176\n",
            "Epoch 554: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3149 - accuracy: 0.9181 - val_loss: 0.3825 - val_accuracy: 0.9084\n",
            "Epoch 555/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3517 - accuracy: 0.9107\n",
            "Epoch 555: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3502 - accuracy: 0.9108 - val_loss: 0.3834 - val_accuracy: 0.8984\n",
            "Epoch 556/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3458 - accuracy: 0.9138\n",
            "Epoch 556: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3493 - accuracy: 0.9122 - val_loss: 0.3743 - val_accuracy: 0.9070\n",
            "Epoch 557/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3161 - accuracy: 0.9151\n",
            "Epoch 557: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3148 - accuracy: 0.9155 - val_loss: 0.3824 - val_accuracy: 0.9142\n",
            "Epoch 558/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.9155\n",
            "Epoch 558: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3331 - accuracy: 0.9152 - val_loss: 0.4337 - val_accuracy: 0.9027\n",
            "Epoch 559/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3984 - accuracy: 0.9017\n",
            "Epoch 559: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3999 - accuracy: 0.9008 - val_loss: 0.3993 - val_accuracy: 0.9013\n",
            "Epoch 560/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3788 - accuracy: 0.9069\n",
            "Epoch 560: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3794 - accuracy: 0.9067 - val_loss: 0.4272 - val_accuracy: 0.9013\n",
            "Epoch 561/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3381 - accuracy: 0.9098\n",
            "Epoch 561: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3398 - accuracy: 0.9098 - val_loss: 0.4196 - val_accuracy: 0.8999\n",
            "Epoch 562/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3932 - accuracy: 0.9107\n",
            "Epoch 562: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3968 - accuracy: 0.9097 - val_loss: 0.5045 - val_accuracy: 0.9099\n",
            "Epoch 563/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3634 - accuracy: 0.9068\n",
            "Epoch 563: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3636 - accuracy: 0.9067 - val_loss: 0.3827 - val_accuracy: 0.9084\n",
            "Epoch 564/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3415 - accuracy: 0.9121\n",
            "Epoch 564: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3417 - accuracy: 0.9120 - val_loss: 0.4088 - val_accuracy: 0.9013\n",
            "Epoch 565/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3214 - accuracy: 0.9173\n",
            "Epoch 565: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3216 - accuracy: 0.9167 - val_loss: 0.4114 - val_accuracy: 0.9041\n",
            "Epoch 566/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3057 - accuracy: 0.9193\n",
            "Epoch 566: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3053 - accuracy: 0.9193 - val_loss: 0.4044 - val_accuracy: 0.8999\n",
            "Epoch 567/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3254 - accuracy: 0.9179\n",
            "Epoch 567: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3225 - accuracy: 0.9185 - val_loss: 0.4061 - val_accuracy: 0.9156\n",
            "Epoch 568/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3905 - accuracy: 0.9074\n",
            "Epoch 568: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3883 - accuracy: 0.9079 - val_loss: 0.3986 - val_accuracy: 0.9027\n",
            "Epoch 569/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3300 - accuracy: 0.9136\n",
            "Epoch 569: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3290 - accuracy: 0.9138 - val_loss: 0.3625 - val_accuracy: 0.9070\n",
            "Epoch 570/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3053 - accuracy: 0.9168\n",
            "Epoch 570: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3060 - accuracy: 0.9162 - val_loss: 0.3761 - val_accuracy: 0.8984\n",
            "Epoch 571/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.9102\n",
            "Epoch 571: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3924 - accuracy: 0.9097 - val_loss: 0.3954 - val_accuracy: 0.8999\n",
            "Epoch 572/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3304 - accuracy: 0.9181\n",
            "Epoch 572: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3319 - accuracy: 0.9181 - val_loss: 0.3690 - val_accuracy: 0.9084\n",
            "Epoch 573/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3287 - accuracy: 0.9193\n",
            "Epoch 573: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3296 - accuracy: 0.9187 - val_loss: 0.3506 - val_accuracy: 0.9113\n",
            "Epoch 574/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3487 - accuracy: 0.9139\n",
            "Epoch 574: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3463 - accuracy: 0.9138 - val_loss: 0.3428 - val_accuracy: 0.9185\n",
            "Epoch 575/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3050 - accuracy: 0.9226\n",
            "Epoch 575: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3051 - accuracy: 0.9225 - val_loss: 0.3299 - val_accuracy: 0.9099\n",
            "Epoch 576/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3353 - accuracy: 0.9134\n",
            "Epoch 576: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3355 - accuracy: 0.9131 - val_loss: 0.3954 - val_accuracy: 0.9199\n",
            "Epoch 577/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3377 - accuracy: 0.9126\n",
            "Epoch 577: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3380 - accuracy: 0.9125 - val_loss: 0.4123 - val_accuracy: 0.9199\n",
            "Epoch 578/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3473 - accuracy: 0.9159\n",
            "Epoch 578: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3444 - accuracy: 0.9164 - val_loss: 0.3776 - val_accuracy: 0.9142\n",
            "Epoch 579/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3557 - accuracy: 0.9111\n",
            "Epoch 579: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3556 - accuracy: 0.9110 - val_loss: 0.4232 - val_accuracy: 0.9127\n",
            "Epoch 580/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.9107\n",
            "Epoch 580: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3336 - accuracy: 0.9110 - val_loss: 0.3550 - val_accuracy: 0.9127\n",
            "Epoch 581/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3311 - accuracy: 0.9121\n",
            "Epoch 581: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3309 - accuracy: 0.9122 - val_loss: 0.3552 - val_accuracy: 0.9113\n",
            "Epoch 582/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3483 - accuracy: 0.9104\n",
            "Epoch 582: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3524 - accuracy: 0.9108 - val_loss: 0.4374 - val_accuracy: 0.9027\n",
            "Epoch 583/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3496 - accuracy: 0.9104\n",
            "Epoch 583: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3481 - accuracy: 0.9108 - val_loss: 0.4308 - val_accuracy: 0.9113\n",
            "Epoch 584/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3629 - accuracy: 0.9076\n",
            "Epoch 584: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3642 - accuracy: 0.9079 - val_loss: 0.3712 - val_accuracy: 0.9070\n",
            "Epoch 585/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3118 - accuracy: 0.9210\n",
            "Epoch 585: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3097 - accuracy: 0.9214 - val_loss: 0.4161 - val_accuracy: 0.9113\n",
            "Epoch 586/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3196 - accuracy: 0.9133\n",
            "Epoch 586: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3262 - accuracy: 0.9134 - val_loss: 0.4295 - val_accuracy: 0.9213\n",
            "Epoch 587/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3244 - accuracy: 0.9124\n",
            "Epoch 587: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3292 - accuracy: 0.9114 - val_loss: 0.4433 - val_accuracy: 0.9099\n",
            "Epoch 588/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3774 - accuracy: 0.9095\n",
            "Epoch 588: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3775 - accuracy: 0.9092 - val_loss: 0.3943 - val_accuracy: 0.9099\n",
            "Epoch 589/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3297 - accuracy: 0.9155\n",
            "Epoch 589: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3290 - accuracy: 0.9158 - val_loss: 0.4153 - val_accuracy: 0.9084\n",
            "Epoch 590/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4218 - accuracy: 0.8994\n",
            "Epoch 590: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4183 - accuracy: 0.9001 - val_loss: 0.4091 - val_accuracy: 0.9041\n",
            "Epoch 591/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3158 - accuracy: 0.9117\n",
            "Epoch 591: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3140 - accuracy: 0.9122 - val_loss: 0.4860 - val_accuracy: 0.9142\n",
            "Epoch 592/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3009 - accuracy: 0.9213\n",
            "Epoch 592: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3006 - accuracy: 0.9220 - val_loss: 0.4524 - val_accuracy: 0.9242\n",
            "Epoch 593/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3184 - accuracy: 0.9176\n",
            "Epoch 593: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3181 - accuracy: 0.9175 - val_loss: 0.4281 - val_accuracy: 0.9242\n",
            "Epoch 594/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3540 - accuracy: 0.9171\n",
            "Epoch 594: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3522 - accuracy: 0.9174 - val_loss: 0.3642 - val_accuracy: 0.9185\n",
            "Epoch 595/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3138 - accuracy: 0.9141\n",
            "Epoch 595: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3138 - accuracy: 0.9141 - val_loss: 0.4361 - val_accuracy: 0.9056\n",
            "Epoch 596/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3335 - accuracy: 0.9146\n",
            "Epoch 596: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3310 - accuracy: 0.9137 - val_loss: 0.4557 - val_accuracy: 0.9084\n",
            "Epoch 597/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3208 - accuracy: 0.9139\n",
            "Epoch 597: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3213 - accuracy: 0.9140 - val_loss: 0.3826 - val_accuracy: 0.9084\n",
            "Epoch 598/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3638 - accuracy: 0.9091\n",
            "Epoch 598: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3642 - accuracy: 0.9088 - val_loss: 0.3683 - val_accuracy: 0.9013\n",
            "Epoch 599/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4081 - accuracy: 0.9017\n",
            "Epoch 599: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4068 - accuracy: 0.9016 - val_loss: 0.4342 - val_accuracy: 0.8970\n",
            "Epoch 600/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4046 - accuracy: 0.8980\n",
            "Epoch 600: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4034 - accuracy: 0.8979 - val_loss: 0.3889 - val_accuracy: 0.9113\n",
            "Epoch 601/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3586 - accuracy: 0.9077\n",
            "Epoch 601: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3660 - accuracy: 0.9082 - val_loss: 0.3849 - val_accuracy: 0.9084\n",
            "Epoch 602/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3537 - accuracy: 0.9056\n",
            "Epoch 602: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3541 - accuracy: 0.9057 - val_loss: 0.4239 - val_accuracy: 0.9113\n",
            "Epoch 603/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3598 - accuracy: 0.9120\n",
            "Epoch 603: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3578 - accuracy: 0.9118 - val_loss: 0.3914 - val_accuracy: 0.9127\n",
            "Epoch 604/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3391 - accuracy: 0.9168\n",
            "Epoch 604: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3355 - accuracy: 0.9174 - val_loss: 0.4342 - val_accuracy: 0.9056\n",
            "Epoch 605/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3438 - accuracy: 0.9139\n",
            "Epoch 605: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3576 - accuracy: 0.9132 - val_loss: 0.4526 - val_accuracy: 0.9084\n",
            "Epoch 606/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3361 - accuracy: 0.9126\n",
            "Epoch 606: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3352 - accuracy: 0.9122 - val_loss: 0.4266 - val_accuracy: 0.9127\n",
            "Epoch 607/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.9070\n",
            "Epoch 607: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3384 - accuracy: 0.9075 - val_loss: 0.4080 - val_accuracy: 0.9027\n",
            "Epoch 608/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3280 - accuracy: 0.9106\n",
            "Epoch 608: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3268 - accuracy: 0.9110 - val_loss: 0.3981 - val_accuracy: 0.9127\n",
            "Epoch 609/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3343 - accuracy: 0.9162\n",
            "Epoch 609: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3348 - accuracy: 0.9158 - val_loss: 0.4038 - val_accuracy: 0.9127\n",
            "Epoch 610/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3557 - accuracy: 0.9152\n",
            "Epoch 610: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3530 - accuracy: 0.9150 - val_loss: 0.3710 - val_accuracy: 0.9199\n",
            "Epoch 611/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3261 - accuracy: 0.9196\n",
            "Epoch 611: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3255 - accuracy: 0.9193 - val_loss: 0.3932 - val_accuracy: 0.9070\n",
            "Epoch 612/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2974 - accuracy: 0.9219\n",
            "Epoch 612: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3010 - accuracy: 0.9211 - val_loss: 0.3890 - val_accuracy: 0.9113\n",
            "Epoch 613/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3459 - accuracy: 0.9146\n",
            "Epoch 613: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3468 - accuracy: 0.9141 - val_loss: 0.4257 - val_accuracy: 0.9070\n",
            "Epoch 614/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3683 - accuracy: 0.9090\n",
            "Epoch 614: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3620 - accuracy: 0.9101 - val_loss: 0.4850 - val_accuracy: 0.9142\n",
            "Epoch 615/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3473 - accuracy: 0.9146\n",
            "Epoch 615: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3444 - accuracy: 0.9150 - val_loss: 0.4373 - val_accuracy: 0.9185\n",
            "Epoch 616/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3704 - accuracy: 0.9069\n",
            "Epoch 616: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3699 - accuracy: 0.9069 - val_loss: 0.4025 - val_accuracy: 0.9127\n",
            "Epoch 617/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3552 - accuracy: 0.9089\n",
            "Epoch 617: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3512 - accuracy: 0.9098 - val_loss: 0.3760 - val_accuracy: 0.9113\n",
            "Epoch 618/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3548 - accuracy: 0.9194\n",
            "Epoch 618: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3577 - accuracy: 0.9187 - val_loss: 0.4928 - val_accuracy: 0.8970\n",
            "Epoch 619/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4214 - accuracy: 0.9010\n",
            "Epoch 619: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4223 - accuracy: 0.9006 - val_loss: 0.3886 - val_accuracy: 0.9013\n",
            "Epoch 620/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3484 - accuracy: 0.9120\n",
            "Epoch 620: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3460 - accuracy: 0.9127 - val_loss: 0.4376 - val_accuracy: 0.8970\n",
            "Epoch 621/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3300 - accuracy: 0.9175\n",
            "Epoch 621: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3315 - accuracy: 0.9164 - val_loss: 0.3592 - val_accuracy: 0.9213\n",
            "Epoch 622/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3730 - accuracy: 0.9083\n",
            "Epoch 622: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3774 - accuracy: 0.9078 - val_loss: 0.4347 - val_accuracy: 0.9142\n",
            "Epoch 623/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.9085\n",
            "Epoch 623: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3262 - accuracy: 0.9085 - val_loss: 0.3843 - val_accuracy: 0.9156\n",
            "Epoch 624/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3383 - accuracy: 0.9178\n",
            "Epoch 624: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3383 - accuracy: 0.9174 - val_loss: 0.4170 - val_accuracy: 0.9113\n",
            "Epoch 625/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3177 - accuracy: 0.9150\n",
            "Epoch 625: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3215 - accuracy: 0.9144 - val_loss: 0.4137 - val_accuracy: 0.9156\n",
            "Epoch 626/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3161 - accuracy: 0.9178\n",
            "Epoch 626: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3161 - accuracy: 0.9178 - val_loss: 0.4304 - val_accuracy: 0.8999\n",
            "Epoch 627/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.9118\n",
            "Epoch 627: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3250 - accuracy: 0.9118 - val_loss: 0.3804 - val_accuracy: 0.9156\n",
            "Epoch 628/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3719 - accuracy: 0.9076\n",
            "Epoch 628: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3713 - accuracy: 0.9075 - val_loss: 0.3784 - val_accuracy: 0.9213\n",
            "Epoch 629/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3184 - accuracy: 0.9170\n",
            "Epoch 629: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3187 - accuracy: 0.9170 - val_loss: 0.4018 - val_accuracy: 0.9227\n",
            "Epoch 630/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3508 - accuracy: 0.9098\n",
            "Epoch 630: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3502 - accuracy: 0.9098 - val_loss: 0.4415 - val_accuracy: 0.9285\n",
            "Epoch 631/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3201 - accuracy: 0.9178\n",
            "Epoch 631: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3221 - accuracy: 0.9167 - val_loss: 0.4332 - val_accuracy: 0.9170\n",
            "Epoch 632/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3132 - accuracy: 0.9209\n",
            "Epoch 632: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3109 - accuracy: 0.9208 - val_loss: 0.4018 - val_accuracy: 0.9156\n",
            "Epoch 633/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.9137\n",
            "Epoch 633: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3504 - accuracy: 0.9137 - val_loss: 0.4228 - val_accuracy: 0.8999\n",
            "Epoch 634/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3485 - accuracy: 0.9120\n",
            "Epoch 634: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3494 - accuracy: 0.9117 - val_loss: 0.4057 - val_accuracy: 0.9127\n",
            "Epoch 635/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4097 - accuracy: 0.9145\n",
            "Epoch 635: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4101 - accuracy: 0.9142 - val_loss: 0.3792 - val_accuracy: 0.9127\n",
            "Epoch 636/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3303 - accuracy: 0.9140\n",
            "Epoch 636: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3297 - accuracy: 0.9140 - val_loss: 0.3940 - val_accuracy: 0.9156\n",
            "Epoch 637/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.9055\n",
            "Epoch 637: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3857 - accuracy: 0.9054 - val_loss: 0.4184 - val_accuracy: 0.8898\n",
            "Epoch 638/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3641 - accuracy: 0.9113\n",
            "Epoch 638: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3670 - accuracy: 0.9110 - val_loss: 0.4007 - val_accuracy: 0.9185\n",
            "Epoch 639/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3038 - accuracy: 0.9200\n",
            "Epoch 639: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3037 - accuracy: 0.9198 - val_loss: 0.3715 - val_accuracy: 0.9213\n",
            "Epoch 640/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3441 - accuracy: 0.9117\n",
            "Epoch 640: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3441 - accuracy: 0.9117 - val_loss: 0.3934 - val_accuracy: 0.9070\n",
            "Epoch 641/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3369 - accuracy: 0.9115\n",
            "Epoch 641: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3354 - accuracy: 0.9120 - val_loss: 0.3601 - val_accuracy: 0.9227\n",
            "Epoch 642/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.9193\n",
            "Epoch 642: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3228 - accuracy: 0.9193 - val_loss: 0.3700 - val_accuracy: 0.9142\n",
            "Epoch 643/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3623 - accuracy: 0.9082\n",
            "Epoch 643: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3640 - accuracy: 0.9075 - val_loss: 0.3432 - val_accuracy: 0.9113\n",
            "Epoch 644/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3600 - accuracy: 0.9142\n",
            "Epoch 644: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3582 - accuracy: 0.9138 - val_loss: 0.4033 - val_accuracy: 0.9270\n",
            "Epoch 645/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3717 - accuracy: 0.9129\n",
            "Epoch 645: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3697 - accuracy: 0.9132 - val_loss: 0.3863 - val_accuracy: 0.9199\n",
            "Epoch 646/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3157 - accuracy: 0.9197\n",
            "Epoch 646: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3143 - accuracy: 0.9201 - val_loss: 0.3876 - val_accuracy: 0.9199\n",
            "Epoch 647/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.9215\n",
            "Epoch 647: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2759 - accuracy: 0.9215 - val_loss: 0.4409 - val_accuracy: 0.9027\n",
            "Epoch 648/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3221 - accuracy: 0.9170\n",
            "Epoch 648: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3227 - accuracy: 0.9167 - val_loss: 0.3910 - val_accuracy: 0.9041\n",
            "Epoch 649/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3146 - accuracy: 0.9204\n",
            "Epoch 649: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3167 - accuracy: 0.9201 - val_loss: 0.3810 - val_accuracy: 0.9185\n",
            "Epoch 650/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.9079\n",
            "Epoch 650: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3618 - accuracy: 0.9079 - val_loss: 0.4149 - val_accuracy: 0.9156\n",
            "Epoch 651/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3377 - accuracy: 0.9127\n",
            "Epoch 651: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3380 - accuracy: 0.9121 - val_loss: 0.3854 - val_accuracy: 0.9113\n",
            "Epoch 652/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3622 - accuracy: 0.9137\n",
            "Epoch 652: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3819 - accuracy: 0.9134 - val_loss: 0.4148 - val_accuracy: 0.9056\n",
            "Epoch 653/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3696 - accuracy: 0.9060\n",
            "Epoch 653: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3665 - accuracy: 0.9059 - val_loss: 0.4060 - val_accuracy: 0.9070\n",
            "Epoch 654/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3264 - accuracy: 0.9128\n",
            "Epoch 654: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3277 - accuracy: 0.9130 - val_loss: 0.4273 - val_accuracy: 0.9056\n",
            "Epoch 655/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3436 - accuracy: 0.9138\n",
            "Epoch 655: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3424 - accuracy: 0.9140 - val_loss: 0.3862 - val_accuracy: 0.9056\n",
            "Epoch 656/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.9175\n",
            "Epoch 656: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3228 - accuracy: 0.9175 - val_loss: 0.4167 - val_accuracy: 0.9084\n",
            "Epoch 657/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3424 - accuracy: 0.9142\n",
            "Epoch 657: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3411 - accuracy: 0.9145 - val_loss: 0.4130 - val_accuracy: 0.9027\n",
            "Epoch 658/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3168 - accuracy: 0.9148\n",
            "Epoch 658: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3230 - accuracy: 0.9142 - val_loss: 0.4530 - val_accuracy: 0.9070\n",
            "Epoch 659/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3196 - accuracy: 0.9136\n",
            "Epoch 659: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3209 - accuracy: 0.9135 - val_loss: 0.4353 - val_accuracy: 0.9113\n",
            "Epoch 660/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.9181\n",
            "Epoch 660: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3424 - accuracy: 0.9181 - val_loss: 0.4159 - val_accuracy: 0.8970\n",
            "Epoch 661/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3242 - accuracy: 0.9097\n",
            "Epoch 661: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3242 - accuracy: 0.9097 - val_loss: 0.4453 - val_accuracy: 0.8999\n",
            "Epoch 662/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3367 - accuracy: 0.9141\n",
            "Epoch 662: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3369 - accuracy: 0.9147 - val_loss: 0.3988 - val_accuracy: 0.9142\n",
            "Epoch 663/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3225 - accuracy: 0.9187\n",
            "Epoch 663: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3263 - accuracy: 0.9187 - val_loss: 0.4305 - val_accuracy: 0.9156\n",
            "Epoch 664/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3504 - accuracy: 0.9128\n",
            "Epoch 664: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3529 - accuracy: 0.9125 - val_loss: 0.4794 - val_accuracy: 0.8984\n",
            "Epoch 665/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3936 - accuracy: 0.9035\n",
            "Epoch 665: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3925 - accuracy: 0.9038 - val_loss: 0.4196 - val_accuracy: 0.9070\n",
            "Epoch 666/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3135 - accuracy: 0.9136\n",
            "Epoch 666: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3170 - accuracy: 0.9128 - val_loss: 0.4269 - val_accuracy: 0.8970\n",
            "Epoch 667/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.9219\n",
            "Epoch 667: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3055 - accuracy: 0.9220 - val_loss: 0.4447 - val_accuracy: 0.9070\n",
            "Epoch 668/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3222 - accuracy: 0.9129\n",
            "Epoch 668: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3175 - accuracy: 0.9135 - val_loss: 0.4609 - val_accuracy: 0.9027\n",
            "Epoch 669/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3012 - accuracy: 0.9250\n",
            "Epoch 669: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3005 - accuracy: 0.9250 - val_loss: 0.5084 - val_accuracy: 0.8999\n",
            "Epoch 670/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3218 - accuracy: 0.9151\n",
            "Epoch 670: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3215 - accuracy: 0.9151 - val_loss: 0.3944 - val_accuracy: 0.9027\n",
            "Epoch 671/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3174 - accuracy: 0.9236\n",
            "Epoch 671: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3170 - accuracy: 0.9236 - val_loss: 0.4480 - val_accuracy: 0.9113\n",
            "Epoch 672/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3225 - accuracy: 0.9236\n",
            "Epoch 672: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3230 - accuracy: 0.9234 - val_loss: 0.4069 - val_accuracy: 0.9099\n",
            "Epoch 673/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3035 - accuracy: 0.9194\n",
            "Epoch 673: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3039 - accuracy: 0.9191 - val_loss: 0.4376 - val_accuracy: 0.9056\n",
            "Epoch 674/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3546 - accuracy: 0.9137\n",
            "Epoch 674: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3526 - accuracy: 0.9134 - val_loss: 0.4201 - val_accuracy: 0.9084\n",
            "Epoch 675/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3222 - accuracy: 0.9226\n",
            "Epoch 675: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3224 - accuracy: 0.9221 - val_loss: 0.3653 - val_accuracy: 0.9213\n",
            "Epoch 676/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3045 - accuracy: 0.9198\n",
            "Epoch 676: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3045 - accuracy: 0.9198 - val_loss: 0.3957 - val_accuracy: 0.9170\n",
            "Epoch 677/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3444 - accuracy: 0.9109\n",
            "Epoch 677: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3427 - accuracy: 0.9105 - val_loss: 0.4052 - val_accuracy: 0.9099\n",
            "Epoch 678/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3213 - accuracy: 0.9143\n",
            "Epoch 678: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3218 - accuracy: 0.9145 - val_loss: 0.4263 - val_accuracy: 0.9142\n",
            "Epoch 679/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3503 - accuracy: 0.9112\n",
            "Epoch 679: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3492 - accuracy: 0.9114 - val_loss: 0.4047 - val_accuracy: 0.9142\n",
            "Epoch 680/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.9111\n",
            "Epoch 680: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3663 - accuracy: 0.9111 - val_loss: 0.3653 - val_accuracy: 0.9099\n",
            "Epoch 681/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3521 - accuracy: 0.9157\n",
            "Epoch 681: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3521 - accuracy: 0.9157 - val_loss: 0.4013 - val_accuracy: 0.9142\n",
            "Epoch 682/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3415 - accuracy: 0.9174\n",
            "Epoch 682: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3433 - accuracy: 0.9174 - val_loss: 0.4313 - val_accuracy: 0.9113\n",
            "Epoch 683/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3471 - accuracy: 0.9140\n",
            "Epoch 683: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3465 - accuracy: 0.9138 - val_loss: 0.4682 - val_accuracy: 0.9127\n",
            "Epoch 684/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3385 - accuracy: 0.9128\n",
            "Epoch 684: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3375 - accuracy: 0.9130 - val_loss: 0.4338 - val_accuracy: 0.9170\n",
            "Epoch 685/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3345 - accuracy: 0.9174\n",
            "Epoch 685: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3344 - accuracy: 0.9177 - val_loss: 0.3976 - val_accuracy: 0.9084\n",
            "Epoch 686/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3390 - accuracy: 0.9132\n",
            "Epoch 686: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3372 - accuracy: 0.9134 - val_loss: 0.4189 - val_accuracy: 0.9070\n",
            "Epoch 687/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3477 - accuracy: 0.9092\n",
            "Epoch 687: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3457 - accuracy: 0.9088 - val_loss: 0.4171 - val_accuracy: 0.9041\n",
            "Epoch 688/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.9131\n",
            "Epoch 688: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3851 - accuracy: 0.9121 - val_loss: 0.4305 - val_accuracy: 0.9056\n",
            "Epoch 689/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3663 - accuracy: 0.9122\n",
            "Epoch 689: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3649 - accuracy: 0.9125 - val_loss: 0.4600 - val_accuracy: 0.8970\n",
            "Epoch 690/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3092 - accuracy: 0.9190\n",
            "Epoch 690: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3107 - accuracy: 0.9184 - val_loss: 0.4169 - val_accuracy: 0.9185\n",
            "Epoch 691/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3394 - accuracy: 0.9218\n",
            "Epoch 691: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3414 - accuracy: 0.9215 - val_loss: 0.3928 - val_accuracy: 0.9099\n",
            "Epoch 692/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3275 - accuracy: 0.9196\n",
            "Epoch 692: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3285 - accuracy: 0.9188 - val_loss: 0.3862 - val_accuracy: 0.9142\n",
            "Epoch 693/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3355 - accuracy: 0.9131\n",
            "Epoch 693: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3355 - accuracy: 0.9131 - val_loss: 0.4178 - val_accuracy: 0.9113\n",
            "Epoch 694/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3140 - accuracy: 0.9137\n",
            "Epoch 694: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3141 - accuracy: 0.9135 - val_loss: 0.4130 - val_accuracy: 0.9170\n",
            "Epoch 695/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.9028\n",
            "Epoch 695: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3963 - accuracy: 0.9028 - val_loss: 0.3947 - val_accuracy: 0.9099\n",
            "Epoch 696/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4581 - accuracy: 0.8981\n",
            "Epoch 696: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4581 - accuracy: 0.8981 - val_loss: 0.4008 - val_accuracy: 0.9013\n",
            "Epoch 697/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4218 - accuracy: 0.8972\n",
            "Epoch 697: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4243 - accuracy: 0.8972 - val_loss: 0.4167 - val_accuracy: 0.9013\n",
            "Epoch 698/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.9138\n",
            "Epoch 698: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3816 - accuracy: 0.9138 - val_loss: 0.4220 - val_accuracy: 0.9099\n",
            "Epoch 699/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3568 - accuracy: 0.9114\n",
            "Epoch 699: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3568 - accuracy: 0.9114 - val_loss: 0.3806 - val_accuracy: 0.9199\n",
            "Epoch 700/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3505 - accuracy: 0.9143\n",
            "Epoch 700: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3487 - accuracy: 0.9140 - val_loss: 0.4035 - val_accuracy: 0.9084\n",
            "Epoch 701/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3515 - accuracy: 0.9118\n",
            "Epoch 701: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3515 - accuracy: 0.9118 - val_loss: 0.4177 - val_accuracy: 0.9070\n",
            "Epoch 702/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3365 - accuracy: 0.9176\n",
            "Epoch 702: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3365 - accuracy: 0.9177 - val_loss: 0.3743 - val_accuracy: 0.9041\n",
            "Epoch 703/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3333 - accuracy: 0.9157\n",
            "Epoch 703: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3321 - accuracy: 0.9160 - val_loss: 0.3965 - val_accuracy: 0.9070\n",
            "Epoch 704/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2695 - accuracy: 0.9241\n",
            "Epoch 704: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2680 - accuracy: 0.9243 - val_loss: 0.3658 - val_accuracy: 0.9099\n",
            "Epoch 705/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3057 - accuracy: 0.9199\n",
            "Epoch 705: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3028 - accuracy: 0.9203 - val_loss: 0.3856 - val_accuracy: 0.9156\n",
            "Epoch 706/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3060 - accuracy: 0.9190\n",
            "Epoch 706: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3085 - accuracy: 0.9188 - val_loss: 0.3913 - val_accuracy: 0.9156\n",
            "Epoch 707/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3463 - accuracy: 0.9171\n",
            "Epoch 707: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3453 - accuracy: 0.9165 - val_loss: 0.3930 - val_accuracy: 0.9041\n",
            "Epoch 708/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2987 - accuracy: 0.9250\n",
            "Epoch 708: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3047 - accuracy: 0.9244 - val_loss: 0.3889 - val_accuracy: 0.9256\n",
            "Epoch 709/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3226 - accuracy: 0.9191\n",
            "Epoch 709: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3230 - accuracy: 0.9187 - val_loss: 0.4754 - val_accuracy: 0.9242\n",
            "Epoch 710/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3569 - accuracy: 0.9116\n",
            "Epoch 710: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3568 - accuracy: 0.9117 - val_loss: 0.3922 - val_accuracy: 0.9127\n",
            "Epoch 711/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4009 - accuracy: 0.9059\n",
            "Epoch 711: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3953 - accuracy: 0.9065 - val_loss: 0.3772 - val_accuracy: 0.9213\n",
            "Epoch 712/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4510 - accuracy: 0.9117\n",
            "Epoch 712: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4500 - accuracy: 0.9117 - val_loss: 0.3956 - val_accuracy: 0.9099\n",
            "Epoch 713/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3484 - accuracy: 0.9116\n",
            "Epoch 713: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3466 - accuracy: 0.9114 - val_loss: 0.4164 - val_accuracy: 0.9113\n",
            "Epoch 714/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.9213\n",
            "Epoch 714: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2957 - accuracy: 0.9213 - val_loss: 0.3704 - val_accuracy: 0.9213\n",
            "Epoch 715/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3526 - accuracy: 0.9171\n",
            "Epoch 715: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3526 - accuracy: 0.9171 - val_loss: 0.3708 - val_accuracy: 0.9156\n",
            "Epoch 716/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3078 - accuracy: 0.9201\n",
            "Epoch 716: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3102 - accuracy: 0.9201 - val_loss: 0.5035 - val_accuracy: 0.9242\n",
            "Epoch 717/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3900 - accuracy: 0.9062\n",
            "Epoch 717: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3872 - accuracy: 0.9068 - val_loss: 0.4426 - val_accuracy: 0.9113\n",
            "Epoch 718/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3486 - accuracy: 0.9124\n",
            "Epoch 718: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3448 - accuracy: 0.9130 - val_loss: 0.4686 - val_accuracy: 0.9027\n",
            "Epoch 719/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3289 - accuracy: 0.9156\n",
            "Epoch 719: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3317 - accuracy: 0.9152 - val_loss: 0.4118 - val_accuracy: 0.9056\n",
            "Epoch 720/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4372 - accuracy: 0.9013\n",
            "Epoch 720: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4383 - accuracy: 0.9006 - val_loss: 0.4942 - val_accuracy: 0.9127\n",
            "Epoch 721/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3623 - accuracy: 0.9087\n",
            "Epoch 721: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3657 - accuracy: 0.9091 - val_loss: 0.4378 - val_accuracy: 0.9113\n",
            "Epoch 722/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3304 - accuracy: 0.9176\n",
            "Epoch 722: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3273 - accuracy: 0.9184 - val_loss: 0.4414 - val_accuracy: 0.9113\n",
            "Epoch 723/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.9141\n",
            "Epoch 723: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3756 - accuracy: 0.9144 - val_loss: 0.3932 - val_accuracy: 0.9213\n",
            "Epoch 724/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3611 - accuracy: 0.9144\n",
            "Epoch 724: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3602 - accuracy: 0.9147 - val_loss: 0.3873 - val_accuracy: 0.9270\n",
            "Epoch 725/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.9160\n",
            "Epoch 725: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3673 - accuracy: 0.9160 - val_loss: 0.4758 - val_accuracy: 0.9142\n",
            "Epoch 726/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3510 - accuracy: 0.9142\n",
            "Epoch 726: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3504 - accuracy: 0.9144 - val_loss: 0.4086 - val_accuracy: 0.9185\n",
            "Epoch 727/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3051 - accuracy: 0.9212\n",
            "Epoch 727: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3057 - accuracy: 0.9213 - val_loss: 0.4224 - val_accuracy: 0.9070\n",
            "Epoch 728/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3272 - accuracy: 0.9207\n",
            "Epoch 728: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3269 - accuracy: 0.9207 - val_loss: 0.4281 - val_accuracy: 0.9185\n",
            "Epoch 729/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3011 - accuracy: 0.9201\n",
            "Epoch 729: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3011 - accuracy: 0.9201 - val_loss: 0.4065 - val_accuracy: 0.9242\n",
            "Epoch 730/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3533 - accuracy: 0.9167\n",
            "Epoch 730: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3520 - accuracy: 0.9170 - val_loss: 0.4097 - val_accuracy: 0.9142\n",
            "Epoch 731/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3559 - accuracy: 0.9224\n",
            "Epoch 731: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3554 - accuracy: 0.9224 - val_loss: 0.3843 - val_accuracy: 0.9070\n",
            "Epoch 732/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3245 - accuracy: 0.9210\n",
            "Epoch 732: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3223 - accuracy: 0.9211 - val_loss: 0.3647 - val_accuracy: 0.9242\n",
            "Epoch 733/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2896 - accuracy: 0.9255\n",
            "Epoch 733: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2889 - accuracy: 0.9256 - val_loss: 0.3689 - val_accuracy: 0.9142\n",
            "Epoch 734/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2880 - accuracy: 0.9264\n",
            "Epoch 734: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2880 - accuracy: 0.9263 - val_loss: 0.4393 - val_accuracy: 0.9084\n",
            "Epoch 735/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3334 - accuracy: 0.9144\n",
            "Epoch 735: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3331 - accuracy: 0.9141 - val_loss: 0.4524 - val_accuracy: 0.8984\n",
            "Epoch 736/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3237 - accuracy: 0.9147\n",
            "Epoch 736: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3215 - accuracy: 0.9145 - val_loss: 0.4671 - val_accuracy: 0.9213\n",
            "Epoch 737/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3062 - accuracy: 0.9197\n",
            "Epoch 737: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3062 - accuracy: 0.9198 - val_loss: 0.4315 - val_accuracy: 0.9013\n",
            "Epoch 738/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3122 - accuracy: 0.9253\n",
            "Epoch 738: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3102 - accuracy: 0.9248 - val_loss: 0.4267 - val_accuracy: 0.9185\n",
            "Epoch 739/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3023 - accuracy: 0.9200\n",
            "Epoch 739: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3028 - accuracy: 0.9191 - val_loss: 0.3708 - val_accuracy: 0.9256\n",
            "Epoch 740/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3631 - accuracy: 0.9132\n",
            "Epoch 740: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3628 - accuracy: 0.9134 - val_loss: 0.4041 - val_accuracy: 0.9156\n",
            "Epoch 741/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3334 - accuracy: 0.9175\n",
            "Epoch 741: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3324 - accuracy: 0.9177 - val_loss: 0.4363 - val_accuracy: 0.9099\n",
            "Epoch 742/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3385 - accuracy: 0.9153\n",
            "Epoch 742: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3379 - accuracy: 0.9154 - val_loss: 0.3992 - val_accuracy: 0.9070\n",
            "Epoch 743/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3725 - accuracy: 0.9122\n",
            "Epoch 743: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3743 - accuracy: 0.9115 - val_loss: 0.4110 - val_accuracy: 0.9185\n",
            "Epoch 744/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3496 - accuracy: 0.9142\n",
            "Epoch 744: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3498 - accuracy: 0.9140 - val_loss: 0.4817 - val_accuracy: 0.9056\n",
            "Epoch 745/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3899 - accuracy: 0.9104\n",
            "Epoch 745: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3904 - accuracy: 0.9099 - val_loss: 0.4391 - val_accuracy: 0.9127\n",
            "Epoch 746/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3361 - accuracy: 0.9129\n",
            "Epoch 746: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3358 - accuracy: 0.9131 - val_loss: 0.4055 - val_accuracy: 0.9084\n",
            "Epoch 747/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3251 - accuracy: 0.9160\n",
            "Epoch 747: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3244 - accuracy: 0.9161 - val_loss: 0.4465 - val_accuracy: 0.9170\n",
            "Epoch 748/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3301 - accuracy: 0.9209\n",
            "Epoch 748: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3253 - accuracy: 0.9217 - val_loss: 0.4357 - val_accuracy: 0.9242\n",
            "Epoch 749/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3251 - accuracy: 0.9230\n",
            "Epoch 749: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3254 - accuracy: 0.9227 - val_loss: 0.3992 - val_accuracy: 0.9170\n",
            "Epoch 750/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3554 - accuracy: 0.9140\n",
            "Epoch 750: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3546 - accuracy: 0.9141 - val_loss: 0.4589 - val_accuracy: 0.9170\n",
            "Epoch 751/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3259 - accuracy: 0.9246\n",
            "Epoch 751: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3298 - accuracy: 0.9246 - val_loss: 0.3824 - val_accuracy: 0.9156\n",
            "Epoch 752/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3273 - accuracy: 0.9187\n",
            "Epoch 752: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3304 - accuracy: 0.9170 - val_loss: 0.4135 - val_accuracy: 0.9142\n",
            "Epoch 753/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3610 - accuracy: 0.9127\n",
            "Epoch 753: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3629 - accuracy: 0.9122 - val_loss: 0.3855 - val_accuracy: 0.9056\n",
            "Epoch 754/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3652 - accuracy: 0.9153\n",
            "Epoch 754: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3653 - accuracy: 0.9151 - val_loss: 0.3635 - val_accuracy: 0.9185\n",
            "Epoch 755/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3735 - accuracy: 0.9131\n",
            "Epoch 755: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3736 - accuracy: 0.9131 - val_loss: 0.3680 - val_accuracy: 0.9156\n",
            "Epoch 756/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3584 - accuracy: 0.9108\n",
            "Epoch 756: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3584 - accuracy: 0.9108 - val_loss: 0.3678 - val_accuracy: 0.9070\n",
            "Epoch 757/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3118 - accuracy: 0.9199\n",
            "Epoch 757: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3231 - accuracy: 0.9194 - val_loss: 0.3458 - val_accuracy: 0.9142\n",
            "Epoch 758/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3308 - accuracy: 0.9213\n",
            "Epoch 758: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3299 - accuracy: 0.9214 - val_loss: 0.3223 - val_accuracy: 0.9142\n",
            "Epoch 759/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3248 - accuracy: 0.9237\n",
            "Epoch 759: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3269 - accuracy: 0.9228 - val_loss: 0.3264 - val_accuracy: 0.9041\n",
            "Epoch 760/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3040 - accuracy: 0.9222\n",
            "Epoch 760: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3044 - accuracy: 0.9218 - val_loss: 0.3478 - val_accuracy: 0.9185\n",
            "Epoch 761/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3015 - accuracy: 0.9221\n",
            "Epoch 761: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2990 - accuracy: 0.9228 - val_loss: 0.3875 - val_accuracy: 0.9113\n",
            "Epoch 762/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3507 - accuracy: 0.9203\n",
            "Epoch 762: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3508 - accuracy: 0.9203 - val_loss: 0.3638 - val_accuracy: 0.9142\n",
            "Epoch 763/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3574 - accuracy: 0.9207\n",
            "Epoch 763: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3564 - accuracy: 0.9208 - val_loss: 0.4384 - val_accuracy: 0.9013\n",
            "Epoch 764/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.9190\n",
            "Epoch 764: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3489 - accuracy: 0.9190 - val_loss: 0.4007 - val_accuracy: 0.9170\n",
            "Epoch 765/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3715 - accuracy: 0.9204\n",
            "Epoch 765: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3715 - accuracy: 0.9204 - val_loss: 0.4384 - val_accuracy: 0.9127\n",
            "Epoch 766/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3600 - accuracy: 0.9144\n",
            "Epoch 766: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3572 - accuracy: 0.9147 - val_loss: 0.3466 - val_accuracy: 0.9113\n",
            "Epoch 767/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4081 - accuracy: 0.9096\n",
            "Epoch 767: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4079 - accuracy: 0.9091 - val_loss: 0.4098 - val_accuracy: 0.9027\n",
            "Epoch 768/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3635 - accuracy: 0.9106\n",
            "Epoch 768: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3634 - accuracy: 0.9102 - val_loss: 0.3796 - val_accuracy: 0.9142\n",
            "Epoch 769/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3939 - accuracy: 0.9104\n",
            "Epoch 769: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3912 - accuracy: 0.9104 - val_loss: 0.4277 - val_accuracy: 0.9084\n",
            "Epoch 770/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3647 - accuracy: 0.9101\n",
            "Epoch 770: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3641 - accuracy: 0.9101 - val_loss: 0.4044 - val_accuracy: 0.9170\n",
            "Epoch 771/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2973 - accuracy: 0.9184\n",
            "Epoch 771: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2972 - accuracy: 0.9185 - val_loss: 0.4057 - val_accuracy: 0.9156\n",
            "Epoch 772/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3301 - accuracy: 0.9161\n",
            "Epoch 772: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3358 - accuracy: 0.9154 - val_loss: 0.3975 - val_accuracy: 0.9170\n",
            "Epoch 773/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3421 - accuracy: 0.9158\n",
            "Epoch 773: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3426 - accuracy: 0.9154 - val_loss: 0.4662 - val_accuracy: 0.9127\n",
            "Epoch 774/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2951 - accuracy: 0.9221\n",
            "Epoch 774: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2986 - accuracy: 0.9225 - val_loss: 0.4464 - val_accuracy: 0.9170\n",
            "Epoch 775/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2901 - accuracy: 0.9246\n",
            "Epoch 775: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2901 - accuracy: 0.9246 - val_loss: 0.3682 - val_accuracy: 0.9270\n",
            "Epoch 776/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.9203\n",
            "Epoch 776: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3056 - accuracy: 0.9205 - val_loss: 0.4646 - val_accuracy: 0.9070\n",
            "Epoch 777/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3716 - accuracy: 0.9135\n",
            "Epoch 777: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3704 - accuracy: 0.9138 - val_loss: 0.5058 - val_accuracy: 0.9084\n",
            "Epoch 778/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3556 - accuracy: 0.9183\n",
            "Epoch 778: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3556 - accuracy: 0.9183 - val_loss: 0.4341 - val_accuracy: 0.9227\n",
            "Epoch 779/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3376 - accuracy: 0.9178\n",
            "Epoch 779: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3373 - accuracy: 0.9180 - val_loss: 0.4246 - val_accuracy: 0.8984\n",
            "Epoch 780/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3512 - accuracy: 0.9113\n",
            "Epoch 780: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3499 - accuracy: 0.9114 - val_loss: 0.3878 - val_accuracy: 0.9099\n",
            "Epoch 781/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3410 - accuracy: 0.9117\n",
            "Epoch 781: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3385 - accuracy: 0.9125 - val_loss: 0.3603 - val_accuracy: 0.9084\n",
            "Epoch 782/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3525 - accuracy: 0.9127\n",
            "Epoch 782: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3515 - accuracy: 0.9128 - val_loss: 0.4066 - val_accuracy: 0.9199\n",
            "Epoch 783/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3698 - accuracy: 0.9103\n",
            "Epoch 783: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3772 - accuracy: 0.9104 - val_loss: 0.4273 - val_accuracy: 0.9170\n",
            "Epoch 784/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3593 - accuracy: 0.9147\n",
            "Epoch 784: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3591 - accuracy: 0.9141 - val_loss: 0.4020 - val_accuracy: 0.9113\n",
            "Epoch 785/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.9157\n",
            "Epoch 785: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3386 - accuracy: 0.9157 - val_loss: 0.4306 - val_accuracy: 0.9170\n",
            "Epoch 786/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.9144\n",
            "Epoch 786: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3408 - accuracy: 0.9144 - val_loss: 0.4056 - val_accuracy: 0.9142\n",
            "Epoch 787/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3226 - accuracy: 0.9206\n",
            "Epoch 787: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3218 - accuracy: 0.9197 - val_loss: 0.4138 - val_accuracy: 0.9027\n",
            "Epoch 788/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3128 - accuracy: 0.9191\n",
            "Epoch 788: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3128 - accuracy: 0.9191 - val_loss: 0.4188 - val_accuracy: 0.9127\n",
            "Epoch 789/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3180 - accuracy: 0.9210\n",
            "Epoch 789: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3175 - accuracy: 0.9211 - val_loss: 0.4670 - val_accuracy: 0.9142\n",
            "Epoch 790/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2582 - accuracy: 0.9310\n",
            "Epoch 790: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2589 - accuracy: 0.9304 - val_loss: 0.4002 - val_accuracy: 0.9142\n",
            "Epoch 791/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.9194\n",
            "Epoch 791: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3227 - accuracy: 0.9195 - val_loss: 0.4597 - val_accuracy: 0.9213\n",
            "Epoch 792/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3117 - accuracy: 0.9209\n",
            "Epoch 792: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3169 - accuracy: 0.9204 - val_loss: 0.4300 - val_accuracy: 0.9127\n",
            "Epoch 793/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3296 - accuracy: 0.9200\n",
            "Epoch 793: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3307 - accuracy: 0.9201 - val_loss: 0.3893 - val_accuracy: 0.9084\n",
            "Epoch 794/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3539 - accuracy: 0.9204\n",
            "Epoch 794: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3711 - accuracy: 0.9213 - val_loss: 0.3426 - val_accuracy: 0.9213\n",
            "Epoch 795/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3474 - accuracy: 0.9150\n",
            "Epoch 795: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3419 - accuracy: 0.9155 - val_loss: 0.3827 - val_accuracy: 0.9213\n",
            "Epoch 796/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3479 - accuracy: 0.9138\n",
            "Epoch 796: val_loss did not improve from 0.30804\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3479 - accuracy: 0.9138 - val_loss: 0.3984 - val_accuracy: 0.9170\n",
            "Epoch 797/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2857 - accuracy: 0.9256\n",
            "Epoch 797: val_loss improved from 0.30804 to 0.30403, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2849 - accuracy: 0.9253 - val_loss: 0.3040 - val_accuracy: 0.9227\n",
            "Epoch 798/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.9157\n",
            "Epoch 798: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3785 - accuracy: 0.9157 - val_loss: 0.3365 - val_accuracy: 0.9156\n",
            "Epoch 799/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3286 - accuracy: 0.9163\n",
            "Epoch 799: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3255 - accuracy: 0.9165 - val_loss: 0.3343 - val_accuracy: 0.9199\n",
            "Epoch 800/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3362 - accuracy: 0.9178\n",
            "Epoch 800: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3389 - accuracy: 0.9180 - val_loss: 0.3842 - val_accuracy: 0.9056\n",
            "Epoch 801/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3775 - accuracy: 0.9086\n",
            "Epoch 801: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3745 - accuracy: 0.9087 - val_loss: 0.4116 - val_accuracy: 0.9099\n",
            "Epoch 802/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.9182\n",
            "Epoch 802: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3795 - accuracy: 0.9181 - val_loss: 0.4150 - val_accuracy: 0.8984\n",
            "Epoch 803/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3573 - accuracy: 0.9120\n",
            "Epoch 803: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3566 - accuracy: 0.9122 - val_loss: 0.3752 - val_accuracy: 0.9142\n",
            "Epoch 804/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.9067\n",
            "Epoch 804: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3854 - accuracy: 0.9067 - val_loss: 0.3902 - val_accuracy: 0.9127\n",
            "Epoch 805/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3889 - accuracy: 0.9134\n",
            "Epoch 805: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3889 - accuracy: 0.9134 - val_loss: 0.3723 - val_accuracy: 0.9070\n",
            "Epoch 806/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3942 - accuracy: 0.9071\n",
            "Epoch 806: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3936 - accuracy: 0.9067 - val_loss: 0.4106 - val_accuracy: 0.9142\n",
            "Epoch 807/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.9109\n",
            "Epoch 807: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3846 - accuracy: 0.9107 - val_loss: 0.3899 - val_accuracy: 0.9213\n",
            "Epoch 808/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3500 - accuracy: 0.9122\n",
            "Epoch 808: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3516 - accuracy: 0.9121 - val_loss: 0.3609 - val_accuracy: 0.9113\n",
            "Epoch 809/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3417 - accuracy: 0.9170\n",
            "Epoch 809: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3411 - accuracy: 0.9167 - val_loss: 0.4380 - val_accuracy: 0.9013\n",
            "Epoch 810/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.9126\n",
            "Epoch 810: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3359 - accuracy: 0.9128 - val_loss: 0.4081 - val_accuracy: 0.9170\n",
            "Epoch 811/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3437 - accuracy: 0.9146\n",
            "Epoch 811: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3432 - accuracy: 0.9155 - val_loss: 0.3662 - val_accuracy: 0.9156\n",
            "Epoch 812/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3649 - accuracy: 0.9114\n",
            "Epoch 812: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3654 - accuracy: 0.9114 - val_loss: 0.3796 - val_accuracy: 0.9213\n",
            "Epoch 813/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3592 - accuracy: 0.9169\n",
            "Epoch 813: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3597 - accuracy: 0.9167 - val_loss: 0.4204 - val_accuracy: 0.9199\n",
            "Epoch 814/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.9178\n",
            "Epoch 814: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3301 - accuracy: 0.9178 - val_loss: 0.3817 - val_accuracy: 0.9227\n",
            "Epoch 815/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3181 - accuracy: 0.9226\n",
            "Epoch 815: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3170 - accuracy: 0.9228 - val_loss: 0.4032 - val_accuracy: 0.9099\n",
            "Epoch 816/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.9231\n",
            "Epoch 816: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2903 - accuracy: 0.9231 - val_loss: 0.4329 - val_accuracy: 0.9142\n",
            "Epoch 817/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3322 - accuracy: 0.9173\n",
            "Epoch 817: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3300 - accuracy: 0.9171 - val_loss: 0.3970 - val_accuracy: 0.9199\n",
            "Epoch 818/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3771 - accuracy: 0.9220\n",
            "Epoch 818: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3764 - accuracy: 0.9218 - val_loss: 0.4134 - val_accuracy: 0.9270\n",
            "Epoch 819/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.9160\n",
            "Epoch 819: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3820 - accuracy: 0.9158 - val_loss: 0.4297 - val_accuracy: 0.9142\n",
            "Epoch 820/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3580 - accuracy: 0.9170\n",
            "Epoch 820: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3547 - accuracy: 0.9175 - val_loss: 0.3934 - val_accuracy: 0.9156\n",
            "Epoch 821/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3978 - accuracy: 0.9164\n",
            "Epoch 821: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3978 - accuracy: 0.9164 - val_loss: 0.3699 - val_accuracy: 0.9156\n",
            "Epoch 822/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3327 - accuracy: 0.9204\n",
            "Epoch 822: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3297 - accuracy: 0.9201 - val_loss: 0.3783 - val_accuracy: 0.9227\n",
            "Epoch 823/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.2960 - accuracy: 0.9255\n",
            "Epoch 823: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2944 - accuracy: 0.9260 - val_loss: 0.3869 - val_accuracy: 0.9199\n",
            "Epoch 824/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3290 - accuracy: 0.9165\n",
            "Epoch 824: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3270 - accuracy: 0.9167 - val_loss: 0.3939 - val_accuracy: 0.9199\n",
            "Epoch 825/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3364 - accuracy: 0.9186\n",
            "Epoch 825: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3360 - accuracy: 0.9184 - val_loss: 0.3835 - val_accuracy: 0.9113\n",
            "Epoch 826/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2709 - accuracy: 0.9269\n",
            "Epoch 826: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2715 - accuracy: 0.9267 - val_loss: 0.3944 - val_accuracy: 0.9185\n",
            "Epoch 827/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2919 - accuracy: 0.9266\n",
            "Epoch 827: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2912 - accuracy: 0.9267 - val_loss: 0.4853 - val_accuracy: 0.9170\n",
            "Epoch 828/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.2546 - accuracy: 0.9322\n",
            "Epoch 828: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2596 - accuracy: 0.9313 - val_loss: 0.4569 - val_accuracy: 0.9299\n",
            "Epoch 829/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3170 - accuracy: 0.9223\n",
            "Epoch 829: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3189 - accuracy: 0.9217 - val_loss: 0.3773 - val_accuracy: 0.9199\n",
            "Epoch 830/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3704 - accuracy: 0.9096\n",
            "Epoch 830: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3717 - accuracy: 0.9092 - val_loss: 0.4529 - val_accuracy: 0.9027\n",
            "Epoch 831/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3601 - accuracy: 0.9105\n",
            "Epoch 831: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3575 - accuracy: 0.9108 - val_loss: 0.4007 - val_accuracy: 0.9156\n",
            "Epoch 832/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3028 - accuracy: 0.9203\n",
            "Epoch 832: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3023 - accuracy: 0.9205 - val_loss: 0.4018 - val_accuracy: 0.9242\n",
            "Epoch 833/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.9178\n",
            "Epoch 833: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3298 - accuracy: 0.9184 - val_loss: 0.4375 - val_accuracy: 0.9084\n",
            "Epoch 834/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3373 - accuracy: 0.9177\n",
            "Epoch 834: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3404 - accuracy: 0.9178 - val_loss: 0.3883 - val_accuracy: 0.9084\n",
            "Epoch 835/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2883 - accuracy: 0.9212\n",
            "Epoch 835: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2893 - accuracy: 0.9210 - val_loss: 0.4080 - val_accuracy: 0.9170\n",
            "Epoch 836/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3120 - accuracy: 0.9191\n",
            "Epoch 836: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3170 - accuracy: 0.9183 - val_loss: 0.3941 - val_accuracy: 0.9185\n",
            "Epoch 837/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3013 - accuracy: 0.9207\n",
            "Epoch 837: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3116 - accuracy: 0.9210 - val_loss: 0.3545 - val_accuracy: 0.9242\n",
            "Epoch 838/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3098 - accuracy: 0.9270\n",
            "Epoch 838: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3121 - accuracy: 0.9276 - val_loss: 0.4129 - val_accuracy: 0.9270\n",
            "Epoch 839/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3143 - accuracy: 0.9178\n",
            "Epoch 839: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3109 - accuracy: 0.9184 - val_loss: 0.3837 - val_accuracy: 0.9242\n",
            "Epoch 840/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3356 - accuracy: 0.9215\n",
            "Epoch 840: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3355 - accuracy: 0.9205 - val_loss: 0.4539 - val_accuracy: 0.9270\n",
            "Epoch 841/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2991 - accuracy: 0.9231\n",
            "Epoch 841: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3000 - accuracy: 0.9237 - val_loss: 0.4039 - val_accuracy: 0.9342\n",
            "Epoch 842/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3017 - accuracy: 0.9252\n",
            "Epoch 842: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2967 - accuracy: 0.9258 - val_loss: 0.4098 - val_accuracy: 0.9185\n",
            "Epoch 843/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2825 - accuracy: 0.9266\n",
            "Epoch 843: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2818 - accuracy: 0.9266 - val_loss: 0.4339 - val_accuracy: 0.9242\n",
            "Epoch 844/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3397 - accuracy: 0.9176\n",
            "Epoch 844: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3413 - accuracy: 0.9170 - val_loss: 0.3502 - val_accuracy: 0.9199\n",
            "Epoch 845/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4000 - accuracy: 0.9187\n",
            "Epoch 845: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4017 - accuracy: 0.9184 - val_loss: 0.3642 - val_accuracy: 0.9213\n",
            "Epoch 846/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3936 - accuracy: 0.9105\n",
            "Epoch 846: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3936 - accuracy: 0.9105 - val_loss: 0.3681 - val_accuracy: 0.9227\n",
            "Epoch 847/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3203 - accuracy: 0.9201\n",
            "Epoch 847: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3253 - accuracy: 0.9203 - val_loss: 0.4363 - val_accuracy: 0.9227\n",
            "Epoch 848/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3499 - accuracy: 0.9168\n",
            "Epoch 848: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3472 - accuracy: 0.9168 - val_loss: 0.3908 - val_accuracy: 0.9185\n",
            "Epoch 849/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3460 - accuracy: 0.9177\n",
            "Epoch 849: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3451 - accuracy: 0.9178 - val_loss: 0.4462 - val_accuracy: 0.9127\n",
            "Epoch 850/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3185 - accuracy: 0.9206\n",
            "Epoch 850: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3141 - accuracy: 0.9211 - val_loss: 0.4033 - val_accuracy: 0.9213\n",
            "Epoch 851/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.9286\n",
            "Epoch 851: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2988 - accuracy: 0.9286 - val_loss: 0.3526 - val_accuracy: 0.9127\n",
            "Epoch 852/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.9240\n",
            "Epoch 852: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3071 - accuracy: 0.9240 - val_loss: 0.3815 - val_accuracy: 0.9156\n",
            "Epoch 853/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3294 - accuracy: 0.9228\n",
            "Epoch 853: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3357 - accuracy: 0.9220 - val_loss: 0.4412 - val_accuracy: 0.9142\n",
            "Epoch 854/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3620 - accuracy: 0.9180\n",
            "Epoch 854: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3617 - accuracy: 0.9177 - val_loss: 0.3853 - val_accuracy: 0.9227\n",
            "Epoch 855/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3425 - accuracy: 0.9168\n",
            "Epoch 855: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3411 - accuracy: 0.9165 - val_loss: 0.4415 - val_accuracy: 0.9256\n",
            "Epoch 856/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3572 - accuracy: 0.9194\n",
            "Epoch 856: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3603 - accuracy: 0.9195 - val_loss: 0.3927 - val_accuracy: 0.9242\n",
            "Epoch 857/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3562 - accuracy: 0.9107\n",
            "Epoch 857: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3562 - accuracy: 0.9107 - val_loss: 0.3846 - val_accuracy: 0.9213\n",
            "Epoch 858/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3414 - accuracy: 0.9087\n",
            "Epoch 858: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3433 - accuracy: 0.9098 - val_loss: 0.4093 - val_accuracy: 0.9127\n",
            "Epoch 859/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3530 - accuracy: 0.9163\n",
            "Epoch 859: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3542 - accuracy: 0.9170 - val_loss: 0.3874 - val_accuracy: 0.9299\n",
            "Epoch 860/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3679 - accuracy: 0.9177\n",
            "Epoch 860: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3679 - accuracy: 0.9177 - val_loss: 0.3950 - val_accuracy: 0.9156\n",
            "Epoch 861/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3201 - accuracy: 0.9212\n",
            "Epoch 861: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3179 - accuracy: 0.9218 - val_loss: 0.3776 - val_accuracy: 0.9127\n",
            "Epoch 862/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3154 - accuracy: 0.9263\n",
            "Epoch 862: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3148 - accuracy: 0.9264 - val_loss: 0.4060 - val_accuracy: 0.9199\n",
            "Epoch 863/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3464 - accuracy: 0.9128\n",
            "Epoch 863: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3438 - accuracy: 0.9134 - val_loss: 0.5234 - val_accuracy: 0.9170\n",
            "Epoch 864/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3606 - accuracy: 0.9188\n",
            "Epoch 864: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3612 - accuracy: 0.9183 - val_loss: 0.4258 - val_accuracy: 0.9084\n",
            "Epoch 865/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3113 - accuracy: 0.9213\n",
            "Epoch 865: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3059 - accuracy: 0.9224 - val_loss: 0.4324 - val_accuracy: 0.9270\n",
            "Epoch 866/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3354 - accuracy: 0.9244\n",
            "Epoch 866: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3370 - accuracy: 0.9233 - val_loss: 0.4162 - val_accuracy: 0.9256\n",
            "Epoch 867/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3722 - accuracy: 0.9163\n",
            "Epoch 867: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3710 - accuracy: 0.9165 - val_loss: 0.4655 - val_accuracy: 0.9070\n",
            "Epoch 868/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3410 - accuracy: 0.9145\n",
            "Epoch 868: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3393 - accuracy: 0.9158 - val_loss: 0.4302 - val_accuracy: 0.9256\n",
            "Epoch 869/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3247 - accuracy: 0.9235\n",
            "Epoch 869: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3238 - accuracy: 0.9237 - val_loss: 0.3858 - val_accuracy: 0.9156\n",
            "Epoch 870/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3370 - accuracy: 0.9227\n",
            "Epoch 870: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3361 - accuracy: 0.9227 - val_loss: 0.3652 - val_accuracy: 0.9156\n",
            "Epoch 871/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3761 - accuracy: 0.9207\n",
            "Epoch 871: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3761 - accuracy: 0.9207 - val_loss: 0.4058 - val_accuracy: 0.9156\n",
            "Epoch 872/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3566 - accuracy: 0.9154\n",
            "Epoch 872: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3552 - accuracy: 0.9155 - val_loss: 0.4336 - val_accuracy: 0.9099\n",
            "Epoch 873/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3983 - accuracy: 0.9116\n",
            "Epoch 873: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3970 - accuracy: 0.9115 - val_loss: 0.3795 - val_accuracy: 0.9156\n",
            "Epoch 874/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3342 - accuracy: 0.9141\n",
            "Epoch 874: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3334 - accuracy: 0.9142 - val_loss: 0.3748 - val_accuracy: 0.9084\n",
            "Epoch 875/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3384 - accuracy: 0.9161\n",
            "Epoch 875: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3345 - accuracy: 0.9170 - val_loss: 0.3649 - val_accuracy: 0.9199\n",
            "Epoch 876/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.2770 - accuracy: 0.9278\n",
            "Epoch 876: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2785 - accuracy: 0.9268 - val_loss: 0.3658 - val_accuracy: 0.9242\n",
            "Epoch 877/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3015 - accuracy: 0.9278\n",
            "Epoch 877: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2998 - accuracy: 0.9281 - val_loss: 0.3834 - val_accuracy: 0.9227\n",
            "Epoch 878/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3313 - accuracy: 0.9228\n",
            "Epoch 878: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3300 - accuracy: 0.9221 - val_loss: 0.3623 - val_accuracy: 0.9156\n",
            "Epoch 879/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3291 - accuracy: 0.9175\n",
            "Epoch 879: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3240 - accuracy: 0.9184 - val_loss: 0.3848 - val_accuracy: 0.9156\n",
            "Epoch 880/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.9247\n",
            "Epoch 880: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3222 - accuracy: 0.9251 - val_loss: 0.4115 - val_accuracy: 0.9170\n",
            "Epoch 881/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3455 - accuracy: 0.9178\n",
            "Epoch 881: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3487 - accuracy: 0.9165 - val_loss: 0.4031 - val_accuracy: 0.9199\n",
            "Epoch 882/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.9246\n",
            "Epoch 882: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3091 - accuracy: 0.9246 - val_loss: 0.5516 - val_accuracy: 0.9127\n",
            "Epoch 883/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3034 - accuracy: 0.9248\n",
            "Epoch 883: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2985 - accuracy: 0.9253 - val_loss: 0.4483 - val_accuracy: 0.9285\n",
            "Epoch 884/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3398 - accuracy: 0.9175\n",
            "Epoch 884: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3357 - accuracy: 0.9178 - val_loss: 0.4684 - val_accuracy: 0.9041\n",
            "Epoch 885/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.9111\n",
            "Epoch 885: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3366 - accuracy: 0.9111 - val_loss: 0.4388 - val_accuracy: 0.9142\n",
            "Epoch 886/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.9087\n",
            "Epoch 886: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3759 - accuracy: 0.9099 - val_loss: 0.4493 - val_accuracy: 0.9170\n",
            "Epoch 887/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3544 - accuracy: 0.9152\n",
            "Epoch 887: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3494 - accuracy: 0.9157 - val_loss: 0.5461 - val_accuracy: 0.9056\n",
            "Epoch 888/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3684 - accuracy: 0.9171\n",
            "Epoch 888: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3652 - accuracy: 0.9174 - val_loss: 0.4198 - val_accuracy: 0.9156\n",
            "Epoch 889/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3409 - accuracy: 0.9136\n",
            "Epoch 889: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3524 - accuracy: 0.9127 - val_loss: 0.5483 - val_accuracy: 0.8913\n",
            "Epoch 890/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3491 - accuracy: 0.9172\n",
            "Epoch 890: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3507 - accuracy: 0.9170 - val_loss: 0.4059 - val_accuracy: 0.9056\n",
            "Epoch 891/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3692 - accuracy: 0.9087\n",
            "Epoch 891: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3787 - accuracy: 0.9088 - val_loss: 0.4490 - val_accuracy: 0.8956\n",
            "Epoch 892/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3995 - accuracy: 0.9092\n",
            "Epoch 892: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3955 - accuracy: 0.9091 - val_loss: 0.4106 - val_accuracy: 0.9056\n",
            "Epoch 893/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4324 - accuracy: 0.9095\n",
            "Epoch 893: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4315 - accuracy: 0.9094 - val_loss: 0.4513 - val_accuracy: 0.9142\n",
            "Epoch 894/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4032 - accuracy: 0.9157\n",
            "Epoch 894: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3997 - accuracy: 0.9155 - val_loss: 0.4321 - val_accuracy: 0.9185\n",
            "Epoch 895/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3312 - accuracy: 0.9169\n",
            "Epoch 895: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3287 - accuracy: 0.9170 - val_loss: 0.4598 - val_accuracy: 0.9213\n",
            "Epoch 896/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3387 - accuracy: 0.9190\n",
            "Epoch 896: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3363 - accuracy: 0.9191 - val_loss: 0.3997 - val_accuracy: 0.9185\n",
            "Epoch 897/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.9217\n",
            "Epoch 897: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3297 - accuracy: 0.9217 - val_loss: 0.4202 - val_accuracy: 0.9227\n",
            "Epoch 898/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3152 - accuracy: 0.9206\n",
            "Epoch 898: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3138 - accuracy: 0.9210 - val_loss: 0.3955 - val_accuracy: 0.9299\n",
            "Epoch 899/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3176 - accuracy: 0.9253\n",
            "Epoch 899: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3176 - accuracy: 0.9240 - val_loss: 0.3708 - val_accuracy: 0.9356\n",
            "Epoch 900/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3480 - accuracy: 0.9167\n",
            "Epoch 900: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3479 - accuracy: 0.9171 - val_loss: 0.4567 - val_accuracy: 0.9299\n",
            "Epoch 901/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3042 - accuracy: 0.9284\n",
            "Epoch 901: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3100 - accuracy: 0.9276 - val_loss: 0.4476 - val_accuracy: 0.9199\n",
            "Epoch 902/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2856 - accuracy: 0.9326\n",
            "Epoch 902: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2865 - accuracy: 0.9321 - val_loss: 0.5030 - val_accuracy: 0.9242\n",
            "Epoch 903/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3282 - accuracy: 0.9249\n",
            "Epoch 903: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3266 - accuracy: 0.9250 - val_loss: 0.3473 - val_accuracy: 0.9185\n",
            "Epoch 904/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.9287\n",
            "Epoch 904: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3056 - accuracy: 0.9287 - val_loss: 0.3299 - val_accuracy: 0.9242\n",
            "Epoch 905/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3163 - accuracy: 0.9238\n",
            "Epoch 905: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3163 - accuracy: 0.9238 - val_loss: 0.3281 - val_accuracy: 0.9213\n",
            "Epoch 906/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3690 - accuracy: 0.9185\n",
            "Epoch 906: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3690 - accuracy: 0.9185 - val_loss: 0.3507 - val_accuracy: 0.9213\n",
            "Epoch 907/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4112 - accuracy: 0.9129\n",
            "Epoch 907: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4095 - accuracy: 0.9131 - val_loss: 0.3480 - val_accuracy: 0.9256\n",
            "Epoch 908/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3544 - accuracy: 0.9130\n",
            "Epoch 908: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3550 - accuracy: 0.9128 - val_loss: 0.3631 - val_accuracy: 0.9256\n",
            "Epoch 909/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3522 - accuracy: 0.9184\n",
            "Epoch 909: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3515 - accuracy: 0.9184 - val_loss: 0.3216 - val_accuracy: 0.9270\n",
            "Epoch 910/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3373 - accuracy: 0.9208\n",
            "Epoch 910: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3373 - accuracy: 0.9208 - val_loss: 0.3354 - val_accuracy: 0.9113\n",
            "Epoch 911/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.9168\n",
            "Epoch 911: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3429 - accuracy: 0.9168 - val_loss: 0.3385 - val_accuracy: 0.9156\n",
            "Epoch 912/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3972 - accuracy: 0.9055\n",
            "Epoch 912: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4026 - accuracy: 0.9057 - val_loss: 0.3379 - val_accuracy: 0.9199\n",
            "Epoch 913/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3616 - accuracy: 0.9135\n",
            "Epoch 913: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3624 - accuracy: 0.9131 - val_loss: 0.3447 - val_accuracy: 0.9113\n",
            "Epoch 914/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3360 - accuracy: 0.9171\n",
            "Epoch 914: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3334 - accuracy: 0.9173 - val_loss: 0.3133 - val_accuracy: 0.9127\n",
            "Epoch 915/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3178 - accuracy: 0.9194\n",
            "Epoch 915: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3182 - accuracy: 0.9195 - val_loss: 0.3374 - val_accuracy: 0.9199\n",
            "Epoch 916/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3759 - accuracy: 0.9194\n",
            "Epoch 916: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3754 - accuracy: 0.9193 - val_loss: 0.3566 - val_accuracy: 0.9227\n",
            "Epoch 917/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3346 - accuracy: 0.9147\n",
            "Epoch 917: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3346 - accuracy: 0.9147 - val_loss: 0.3489 - val_accuracy: 0.9084\n",
            "Epoch 918/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2971 - accuracy: 0.9262\n",
            "Epoch 918: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2943 - accuracy: 0.9267 - val_loss: 0.3453 - val_accuracy: 0.9227\n",
            "Epoch 919/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3596 - accuracy: 0.9181\n",
            "Epoch 919: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3602 - accuracy: 0.9180 - val_loss: 0.3627 - val_accuracy: 0.9185\n",
            "Epoch 920/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3217 - accuracy: 0.9237\n",
            "Epoch 920: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3193 - accuracy: 0.9237 - val_loss: 0.4106 - val_accuracy: 0.9070\n",
            "Epoch 921/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3456 - accuracy: 0.9220\n",
            "Epoch 921: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3417 - accuracy: 0.9228 - val_loss: 0.4149 - val_accuracy: 0.9142\n",
            "Epoch 922/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3458 - accuracy: 0.9181\n",
            "Epoch 922: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3431 - accuracy: 0.9187 - val_loss: 0.3808 - val_accuracy: 0.9156\n",
            "Epoch 923/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3153 - accuracy: 0.9223\n",
            "Epoch 923: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3161 - accuracy: 0.9223 - val_loss: 0.3752 - val_accuracy: 0.9099\n",
            "Epoch 924/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.9211\n",
            "Epoch 924: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3447 - accuracy: 0.9211 - val_loss: 0.3965 - val_accuracy: 0.9084\n",
            "Epoch 925/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3259 - accuracy: 0.9178\n",
            "Epoch 925: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3274 - accuracy: 0.9170 - val_loss: 0.4185 - val_accuracy: 0.9113\n",
            "Epoch 926/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4451 - accuracy: 0.9152\n",
            "Epoch 926: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4458 - accuracy: 0.9145 - val_loss: 0.4548 - val_accuracy: 0.9113\n",
            "Epoch 927/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3501 - accuracy: 0.9201\n",
            "Epoch 927: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3504 - accuracy: 0.9198 - val_loss: 0.3565 - val_accuracy: 0.9127\n",
            "Epoch 928/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3259 - accuracy: 0.9199\n",
            "Epoch 928: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3274 - accuracy: 0.9187 - val_loss: 0.3759 - val_accuracy: 0.9113\n",
            "Epoch 929/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3246 - accuracy: 0.9170\n",
            "Epoch 929: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3254 - accuracy: 0.9168 - val_loss: 0.3934 - val_accuracy: 0.9099\n",
            "Epoch 930/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3433 - accuracy: 0.9200\n",
            "Epoch 930: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3467 - accuracy: 0.9205 - val_loss: 0.3555 - val_accuracy: 0.9185\n",
            "Epoch 931/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2833 - accuracy: 0.9276\n",
            "Epoch 931: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2840 - accuracy: 0.9276 - val_loss: 0.3444 - val_accuracy: 0.9256\n",
            "Epoch 932/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3238 - accuracy: 0.9287\n",
            "Epoch 932: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3204 - accuracy: 0.9291 - val_loss: 0.3756 - val_accuracy: 0.9213\n",
            "Epoch 933/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3076 - accuracy: 0.9254\n",
            "Epoch 933: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3070 - accuracy: 0.9251 - val_loss: 0.4238 - val_accuracy: 0.9156\n",
            "Epoch 934/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2973 - accuracy: 0.9251\n",
            "Epoch 934: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2968 - accuracy: 0.9248 - val_loss: 0.3567 - val_accuracy: 0.9313\n",
            "Epoch 935/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2963 - accuracy: 0.9285\n",
            "Epoch 935: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2953 - accuracy: 0.9284 - val_loss: 0.4261 - val_accuracy: 0.9142\n",
            "Epoch 936/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3085 - accuracy: 0.9278\n",
            "Epoch 936: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3085 - accuracy: 0.9278 - val_loss: 0.4556 - val_accuracy: 0.9170\n",
            "Epoch 937/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3149 - accuracy: 0.9213\n",
            "Epoch 937: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3128 - accuracy: 0.9218 - val_loss: 0.4306 - val_accuracy: 0.9056\n",
            "Epoch 938/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2792 - accuracy: 0.9312\n",
            "Epoch 938: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2798 - accuracy: 0.9307 - val_loss: 0.4712 - val_accuracy: 0.9070\n",
            "Epoch 939/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3127 - accuracy: 0.9240\n",
            "Epoch 939: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3135 - accuracy: 0.9241 - val_loss: 0.4237 - val_accuracy: 0.9170\n",
            "Epoch 940/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3187 - accuracy: 0.9266\n",
            "Epoch 940: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3184 - accuracy: 0.9266 - val_loss: 0.3701 - val_accuracy: 0.9213\n",
            "Epoch 941/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3407 - accuracy: 0.9267\n",
            "Epoch 941: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3515 - accuracy: 0.9267 - val_loss: 0.3636 - val_accuracy: 0.9242\n",
            "Epoch 942/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.9139\n",
            "Epoch 942: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3809 - accuracy: 0.9140 - val_loss: 0.4050 - val_accuracy: 0.9199\n",
            "Epoch 943/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3625 - accuracy: 0.9168\n",
            "Epoch 943: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3603 - accuracy: 0.9167 - val_loss: 0.3771 - val_accuracy: 0.9242\n",
            "Epoch 944/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.9059\n",
            "Epoch 944: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4601 - accuracy: 0.9059 - val_loss: 0.4430 - val_accuracy: 0.9099\n",
            "Epoch 945/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3481 - accuracy: 0.9151\n",
            "Epoch 945: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3496 - accuracy: 0.9141 - val_loss: 0.3777 - val_accuracy: 0.9199\n",
            "Epoch 946/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3260 - accuracy: 0.9201\n",
            "Epoch 946: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3260 - accuracy: 0.9201 - val_loss: 0.4392 - val_accuracy: 0.9099\n",
            "Epoch 947/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3691 - accuracy: 0.9168\n",
            "Epoch 947: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3698 - accuracy: 0.9161 - val_loss: 0.4567 - val_accuracy: 0.9127\n",
            "Epoch 948/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3467 - accuracy: 0.9187\n",
            "Epoch 948: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3467 - accuracy: 0.9187 - val_loss: 0.4487 - val_accuracy: 0.9099\n",
            "Epoch 949/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.9219\n",
            "Epoch 949: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3870 - accuracy: 0.9221 - val_loss: 0.3814 - val_accuracy: 0.9256\n",
            "Epoch 950/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2774 - accuracy: 0.9279\n",
            "Epoch 950: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2769 - accuracy: 0.9273 - val_loss: 0.3648 - val_accuracy: 0.9242\n",
            "Epoch 951/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3492 - accuracy: 0.9264\n",
            "Epoch 951: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3476 - accuracy: 0.9261 - val_loss: 0.4054 - val_accuracy: 0.9213\n",
            "Epoch 952/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3349 - accuracy: 0.9225\n",
            "Epoch 952: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3335 - accuracy: 0.9228 - val_loss: 0.3998 - val_accuracy: 0.9185\n",
            "Epoch 953/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3098 - accuracy: 0.9226\n",
            "Epoch 953: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3087 - accuracy: 0.9228 - val_loss: 0.4184 - val_accuracy: 0.9227\n",
            "Epoch 954/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3789 - accuracy: 0.9141\n",
            "Epoch 954: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3723 - accuracy: 0.9151 - val_loss: 0.3325 - val_accuracy: 0.9256\n",
            "Epoch 955/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3712 - accuracy: 0.9178\n",
            "Epoch 955: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3781 - accuracy: 0.9175 - val_loss: 0.3191 - val_accuracy: 0.9242\n",
            "Epoch 956/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3418 - accuracy: 0.9181\n",
            "Epoch 956: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3471 - accuracy: 0.9177 - val_loss: 0.3192 - val_accuracy: 0.9256\n",
            "Epoch 957/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3492 - accuracy: 0.9148\n",
            "Epoch 957: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3483 - accuracy: 0.9138 - val_loss: 0.3426 - val_accuracy: 0.9213\n",
            "Epoch 958/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3600 - accuracy: 0.9191\n",
            "Epoch 958: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3612 - accuracy: 0.9181 - val_loss: 0.3468 - val_accuracy: 0.9256\n",
            "Epoch 959/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3317 - accuracy: 0.9226\n",
            "Epoch 959: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3311 - accuracy: 0.9227 - val_loss: 0.3201 - val_accuracy: 0.9285\n",
            "Epoch 960/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3480 - accuracy: 0.9213\n",
            "Epoch 960: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3488 - accuracy: 0.9215 - val_loss: 0.3738 - val_accuracy: 0.9227\n",
            "Epoch 961/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3960 - accuracy: 0.9199\n",
            "Epoch 961: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3944 - accuracy: 0.9193 - val_loss: 0.3743 - val_accuracy: 0.9084\n",
            "Epoch 962/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4406 - accuracy: 0.9065\n",
            "Epoch 962: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4368 - accuracy: 0.9062 - val_loss: 0.4008 - val_accuracy: 0.9099\n",
            "Epoch 963/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3743 - accuracy: 0.9199\n",
            "Epoch 963: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3738 - accuracy: 0.9200 - val_loss: 0.3953 - val_accuracy: 0.9242\n",
            "Epoch 964/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4596 - accuracy: 0.8988\n",
            "Epoch 964: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4591 - accuracy: 0.8988 - val_loss: 0.4347 - val_accuracy: 0.9084\n",
            "Epoch 965/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3610 - accuracy: 0.9086\n",
            "Epoch 965: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3580 - accuracy: 0.9091 - val_loss: 0.3722 - val_accuracy: 0.9185\n",
            "Epoch 966/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3432 - accuracy: 0.9176\n",
            "Epoch 966: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3457 - accuracy: 0.9167 - val_loss: 0.4309 - val_accuracy: 0.9185\n",
            "Epoch 967/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3061 - accuracy: 0.9239\n",
            "Epoch 967: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3068 - accuracy: 0.9230 - val_loss: 0.4050 - val_accuracy: 0.9256\n",
            "Epoch 968/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3672 - accuracy: 0.9188\n",
            "Epoch 968: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3696 - accuracy: 0.9191 - val_loss: 0.4165 - val_accuracy: 0.9227\n",
            "Epoch 969/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3588 - accuracy: 0.9237\n",
            "Epoch 969: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3613 - accuracy: 0.9224 - val_loss: 0.3979 - val_accuracy: 0.9299\n",
            "Epoch 970/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3528 - accuracy: 0.9132\n",
            "Epoch 970: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3643 - accuracy: 0.9121 - val_loss: 0.3597 - val_accuracy: 0.9227\n",
            "Epoch 971/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3394 - accuracy: 0.9203\n",
            "Epoch 971: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3383 - accuracy: 0.9201 - val_loss: 0.3960 - val_accuracy: 0.9127\n",
            "Epoch 972/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3266 - accuracy: 0.9271\n",
            "Epoch 972: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3265 - accuracy: 0.9273 - val_loss: 0.4064 - val_accuracy: 0.9142\n",
            "Epoch 973/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3418 - accuracy: 0.9236\n",
            "Epoch 973: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3417 - accuracy: 0.9234 - val_loss: 0.4095 - val_accuracy: 0.8984\n",
            "Epoch 974/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3524 - accuracy: 0.9143\n",
            "Epoch 974: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3711 - accuracy: 0.9148 - val_loss: 0.3969 - val_accuracy: 0.9170\n",
            "Epoch 975/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3100 - accuracy: 0.9244\n",
            "Epoch 975: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3123 - accuracy: 0.9244 - val_loss: 0.4063 - val_accuracy: 0.9256\n",
            "Epoch 976/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4234 - accuracy: 0.9141\n",
            "Epoch 976: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4233 - accuracy: 0.9142 - val_loss: 0.3836 - val_accuracy: 0.9156\n",
            "Epoch 977/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3278 - accuracy: 0.9171\n",
            "Epoch 977: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3269 - accuracy: 0.9171 - val_loss: 0.3601 - val_accuracy: 0.9256\n",
            "Epoch 978/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3055 - accuracy: 0.9197\n",
            "Epoch 978: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3028 - accuracy: 0.9205 - val_loss: 0.3524 - val_accuracy: 0.9285\n",
            "Epoch 979/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2943 - accuracy: 0.9286\n",
            "Epoch 979: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2940 - accuracy: 0.9284 - val_loss: 0.3620 - val_accuracy: 0.9199\n",
            "Epoch 980/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.9268\n",
            "Epoch 980: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3144 - accuracy: 0.9268 - val_loss: 0.4038 - val_accuracy: 0.9156\n",
            "Epoch 981/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3306 - accuracy: 0.9222\n",
            "Epoch 981: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3282 - accuracy: 0.9223 - val_loss: 0.4243 - val_accuracy: 0.9170\n",
            "Epoch 982/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3345 - accuracy: 0.9207\n",
            "Epoch 982: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3409 - accuracy: 0.9201 - val_loss: 0.3885 - val_accuracy: 0.9142\n",
            "Epoch 983/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2670 - accuracy: 0.9326\n",
            "Epoch 983: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2674 - accuracy: 0.9321 - val_loss: 0.3600 - val_accuracy: 0.9199\n",
            "Epoch 984/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.9310\n",
            "Epoch 984: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2738 - accuracy: 0.9310 - val_loss: 0.4142 - val_accuracy: 0.9256\n",
            "Epoch 985/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3486 - accuracy: 0.9244\n",
            "Epoch 985: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3483 - accuracy: 0.9246 - val_loss: 0.4430 - val_accuracy: 0.9242\n",
            "Epoch 986/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3057 - accuracy: 0.9188\n",
            "Epoch 986: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3118 - accuracy: 0.9194 - val_loss: 0.3828 - val_accuracy: 0.9170\n",
            "Epoch 987/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3213 - accuracy: 0.9200\n",
            "Epoch 987: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3200 - accuracy: 0.9197 - val_loss: 0.3856 - val_accuracy: 0.9242\n",
            "Epoch 988/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2865 - accuracy: 0.9266\n",
            "Epoch 988: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2835 - accuracy: 0.9276 - val_loss: 0.3739 - val_accuracy: 0.9156\n",
            "Epoch 989/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3884 - accuracy: 0.9197\n",
            "Epoch 989: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3884 - accuracy: 0.9197 - val_loss: 0.4111 - val_accuracy: 0.9156\n",
            "Epoch 990/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3741 - accuracy: 0.9161\n",
            "Epoch 990: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3703 - accuracy: 0.9165 - val_loss: 0.4376 - val_accuracy: 0.9213\n",
            "Epoch 991/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3364 - accuracy: 0.9248\n",
            "Epoch 991: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3361 - accuracy: 0.9248 - val_loss: 0.3873 - val_accuracy: 0.9270\n",
            "Epoch 992/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3183 - accuracy: 0.9276\n",
            "Epoch 992: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3181 - accuracy: 0.9280 - val_loss: 0.3390 - val_accuracy: 0.9270\n",
            "Epoch 993/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3300 - accuracy: 0.9179\n",
            "Epoch 993: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3298 - accuracy: 0.9185 - val_loss: 0.4506 - val_accuracy: 0.9156\n",
            "Epoch 994/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3459 - accuracy: 0.9196\n",
            "Epoch 994: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3490 - accuracy: 0.9193 - val_loss: 0.4318 - val_accuracy: 0.9070\n",
            "Epoch 995/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3451 - accuracy: 0.9204\n",
            "Epoch 995: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3495 - accuracy: 0.9195 - val_loss: 0.4065 - val_accuracy: 0.9270\n",
            "Epoch 996/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3497 - accuracy: 0.9207\n",
            "Epoch 996: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3540 - accuracy: 0.9194 - val_loss: 0.3953 - val_accuracy: 0.9113\n",
            "Epoch 997/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3742 - accuracy: 0.9126\n",
            "Epoch 997: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3758 - accuracy: 0.9124 - val_loss: 0.4640 - val_accuracy: 0.8999\n",
            "Epoch 998/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3355 - accuracy: 0.9172\n",
            "Epoch 998: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3372 - accuracy: 0.9177 - val_loss: 0.4503 - val_accuracy: 0.9313\n",
            "Epoch 999/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3422 - accuracy: 0.9183\n",
            "Epoch 999: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3415 - accuracy: 0.9183 - val_loss: 0.3969 - val_accuracy: 0.9127\n",
            "Epoch 1000/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3319 - accuracy: 0.9178\n",
            "Epoch 1000: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3264 - accuracy: 0.9191 - val_loss: 0.3628 - val_accuracy: 0.9099\n",
            "Epoch 1001/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3267 - accuracy: 0.9217\n",
            "Epoch 1001: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3267 - accuracy: 0.9217 - val_loss: 0.3827 - val_accuracy: 0.9199\n",
            "Epoch 1002/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3258 - accuracy: 0.9213\n",
            "Epoch 1002: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3258 - accuracy: 0.9213 - val_loss: 0.3226 - val_accuracy: 0.9199\n",
            "Epoch 1003/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3201 - accuracy: 0.9230\n",
            "Epoch 1003: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3195 - accuracy: 0.9231 - val_loss: 0.3413 - val_accuracy: 0.9199\n",
            "Epoch 1004/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.2988 - accuracy: 0.9288\n",
            "Epoch 1004: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2983 - accuracy: 0.9291 - val_loss: 0.3287 - val_accuracy: 0.9213\n",
            "Epoch 1005/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3097 - accuracy: 0.9271\n",
            "Epoch 1005: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3130 - accuracy: 0.9264 - val_loss: 0.3585 - val_accuracy: 0.9084\n",
            "Epoch 1006/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3390 - accuracy: 0.9187\n",
            "Epoch 1006: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3380 - accuracy: 0.9190 - val_loss: 0.3245 - val_accuracy: 0.9299\n",
            "Epoch 1007/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2831 - accuracy: 0.9246\n",
            "Epoch 1007: val_loss did not improve from 0.30403\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2852 - accuracy: 0.9246 - val_loss: 0.3395 - val_accuracy: 0.9199\n",
            "Epoch 1008/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3291 - accuracy: 0.9279\n",
            "Epoch 1008: val_loss improved from 0.30403 to 0.28055, saving model to Models\\audio_classification2.hdf5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3254 - accuracy: 0.9277 - val_loss: 0.2806 - val_accuracy: 0.9342\n",
            "Epoch 1009/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3621 - accuracy: 0.9187\n",
            "Epoch 1009: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4028 - accuracy: 0.9184 - val_loss: 0.3339 - val_accuracy: 0.9185\n",
            "Epoch 1010/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3614 - accuracy: 0.9162\n",
            "Epoch 1010: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3661 - accuracy: 0.9162 - val_loss: 0.3297 - val_accuracy: 0.9242\n",
            "Epoch 1011/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3043 - accuracy: 0.9216\n",
            "Epoch 1011: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3029 - accuracy: 0.9215 - val_loss: 0.3302 - val_accuracy: 0.9113\n",
            "Epoch 1012/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4151 - accuracy: 0.9143\n",
            "Epoch 1012: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4095 - accuracy: 0.9152 - val_loss: 0.3703 - val_accuracy: 0.9185\n",
            "Epoch 1013/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3758 - accuracy: 0.9183\n",
            "Epoch 1013: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3758 - accuracy: 0.9183 - val_loss: 0.3348 - val_accuracy: 0.9242\n",
            "Epoch 1014/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3384 - accuracy: 0.9132\n",
            "Epoch 1014: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3375 - accuracy: 0.9130 - val_loss: 0.3727 - val_accuracy: 0.9213\n",
            "Epoch 1015/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3269 - accuracy: 0.9204\n",
            "Epoch 1015: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3267 - accuracy: 0.9205 - val_loss: 0.4758 - val_accuracy: 0.9070\n",
            "Epoch 1016/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.9216\n",
            "Epoch 1016: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3549 - accuracy: 0.9210 - val_loss: 0.4296 - val_accuracy: 0.9113\n",
            "Epoch 1017/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3404 - accuracy: 0.9143\n",
            "Epoch 1017: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3405 - accuracy: 0.9141 - val_loss: 0.4087 - val_accuracy: 0.9084\n",
            "Epoch 1018/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3398 - accuracy: 0.9209\n",
            "Epoch 1018: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3390 - accuracy: 0.9210 - val_loss: 0.4306 - val_accuracy: 0.9170\n",
            "Epoch 1019/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3476 - accuracy: 0.9221\n",
            "Epoch 1019: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3474 - accuracy: 0.9224 - val_loss: 0.3983 - val_accuracy: 0.9185\n",
            "Epoch 1020/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3726 - accuracy: 0.9132\n",
            "Epoch 1020: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3701 - accuracy: 0.9137 - val_loss: 0.4270 - val_accuracy: 0.9156\n",
            "Epoch 1021/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4179 - accuracy: 0.9061\n",
            "Epoch 1021: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4179 - accuracy: 0.9061 - val_loss: 0.4566 - val_accuracy: 0.9041\n",
            "Epoch 1022/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4653 - accuracy: 0.9035\n",
            "Epoch 1022: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4698 - accuracy: 0.9035 - val_loss: 0.4047 - val_accuracy: 0.9070\n",
            "Epoch 1023/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3761 - accuracy: 0.9149\n",
            "Epoch 1023: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3734 - accuracy: 0.9148 - val_loss: 0.3773 - val_accuracy: 0.9056\n",
            "Epoch 1024/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4264 - accuracy: 0.9094\n",
            "Epoch 1024: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4276 - accuracy: 0.9098 - val_loss: 0.3838 - val_accuracy: 0.9027\n",
            "Epoch 1025/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3246 - accuracy: 0.9251\n",
            "Epoch 1025: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3223 - accuracy: 0.9254 - val_loss: 0.3369 - val_accuracy: 0.9227\n",
            "Epoch 1026/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2999 - accuracy: 0.9253\n",
            "Epoch 1026: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3058 - accuracy: 0.9256 - val_loss: 0.4023 - val_accuracy: 0.9185\n",
            "Epoch 1027/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3024 - accuracy: 0.9283\n",
            "Epoch 1027: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3008 - accuracy: 0.9283 - val_loss: 0.4343 - val_accuracy: 0.9242\n",
            "Epoch 1028/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2890 - accuracy: 0.9276\n",
            "Epoch 1028: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2948 - accuracy: 0.9260 - val_loss: 0.3916 - val_accuracy: 0.9213\n",
            "Epoch 1029/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2961 - accuracy: 0.9263\n",
            "Epoch 1029: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2967 - accuracy: 0.9257 - val_loss: 0.4174 - val_accuracy: 0.9113\n",
            "Epoch 1030/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.9230\n",
            "Epoch 1030: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3251 - accuracy: 0.9230 - val_loss: 0.4277 - val_accuracy: 0.9142\n",
            "Epoch 1031/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2874 - accuracy: 0.9294\n",
            "Epoch 1031: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2883 - accuracy: 0.9291 - val_loss: 0.3902 - val_accuracy: 0.9242\n",
            "Epoch 1032/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3024 - accuracy: 0.9295\n",
            "Epoch 1032: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2966 - accuracy: 0.9301 - val_loss: 0.3612 - val_accuracy: 0.9242\n",
            "Epoch 1033/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2837 - accuracy: 0.9305\n",
            "Epoch 1033: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2840 - accuracy: 0.9306 - val_loss: 0.3927 - val_accuracy: 0.9270\n",
            "Epoch 1034/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3476 - accuracy: 0.9244\n",
            "Epoch 1034: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3461 - accuracy: 0.9241 - val_loss: 0.3973 - val_accuracy: 0.9342\n",
            "Epoch 1035/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3159 - accuracy: 0.9255\n",
            "Epoch 1035: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3151 - accuracy: 0.9258 - val_loss: 0.3897 - val_accuracy: 0.9227\n",
            "Epoch 1036/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3933 - accuracy: 0.9156\n",
            "Epoch 1036: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3904 - accuracy: 0.9155 - val_loss: 0.3760 - val_accuracy: 0.9142\n",
            "Epoch 1037/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3263 - accuracy: 0.9241\n",
            "Epoch 1037: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3262 - accuracy: 0.9244 - val_loss: 0.4006 - val_accuracy: 0.9256\n",
            "Epoch 1038/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3960 - accuracy: 0.9114\n",
            "Epoch 1038: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3968 - accuracy: 0.9104 - val_loss: 0.3730 - val_accuracy: 0.9113\n",
            "Epoch 1039/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.9186\n",
            "Epoch 1039: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3211 - accuracy: 0.9184 - val_loss: 0.3664 - val_accuracy: 0.9099\n",
            "Epoch 1040/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3425 - accuracy: 0.9287\n",
            "Epoch 1040: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3417 - accuracy: 0.9277 - val_loss: 0.3512 - val_accuracy: 0.9127\n",
            "Epoch 1041/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3468 - accuracy: 0.9222\n",
            "Epoch 1041: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3472 - accuracy: 0.9217 - val_loss: 0.3414 - val_accuracy: 0.9099\n",
            "Epoch 1042/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3256 - accuracy: 0.9240\n",
            "Epoch 1042: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3244 - accuracy: 0.9241 - val_loss: 0.3650 - val_accuracy: 0.9084\n",
            "Epoch 1043/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3443 - accuracy: 0.9180\n",
            "Epoch 1043: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3433 - accuracy: 0.9184 - val_loss: 0.3670 - val_accuracy: 0.9127\n",
            "Epoch 1044/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3032 - accuracy: 0.9293\n",
            "Epoch 1044: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2996 - accuracy: 0.9293 - val_loss: 0.4186 - val_accuracy: 0.9242\n",
            "Epoch 1045/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3045 - accuracy: 0.9240\n",
            "Epoch 1045: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3066 - accuracy: 0.9236 - val_loss: 0.4132 - val_accuracy: 0.9199\n",
            "Epoch 1046/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3000 - accuracy: 0.9249\n",
            "Epoch 1046: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2993 - accuracy: 0.9253 - val_loss: 0.4647 - val_accuracy: 0.9142\n",
            "Epoch 1047/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.9193\n",
            "Epoch 1047: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3510 - accuracy: 0.9193 - val_loss: 0.4863 - val_accuracy: 0.9113\n",
            "Epoch 1048/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3428 - accuracy: 0.9215\n",
            "Epoch 1048: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3470 - accuracy: 0.9208 - val_loss: 0.4106 - val_accuracy: 0.9227\n",
            "Epoch 1049/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3476 - accuracy: 0.9132\n",
            "Epoch 1049: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3416 - accuracy: 0.9147 - val_loss: 0.3813 - val_accuracy: 0.9142\n",
            "Epoch 1050/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2519 - accuracy: 0.9318\n",
            "Epoch 1050: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2522 - accuracy: 0.9317 - val_loss: 0.3413 - val_accuracy: 0.9313\n",
            "Epoch 1051/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2965 - accuracy: 0.9263\n",
            "Epoch 1051: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2916 - accuracy: 0.9270 - val_loss: 0.4091 - val_accuracy: 0.9199\n",
            "Epoch 1052/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.2705 - accuracy: 0.9287\n",
            "Epoch 1052: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2701 - accuracy: 0.9288 - val_loss: 0.3750 - val_accuracy: 0.9342\n",
            "Epoch 1053/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3180 - accuracy: 0.9283\n",
            "Epoch 1053: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3157 - accuracy: 0.9283 - val_loss: 0.3940 - val_accuracy: 0.9256\n",
            "Epoch 1054/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3065 - accuracy: 0.9293\n",
            "Epoch 1054: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3112 - accuracy: 0.9281 - val_loss: 0.3760 - val_accuracy: 0.9213\n",
            "Epoch 1055/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3174 - accuracy: 0.9235\n",
            "Epoch 1055: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3213 - accuracy: 0.9233 - val_loss: 0.3607 - val_accuracy: 0.9185\n",
            "Epoch 1056/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3798 - accuracy: 0.9138\n",
            "Epoch 1056: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3833 - accuracy: 0.9145 - val_loss: 0.4446 - val_accuracy: 0.9041\n",
            "Epoch 1057/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3272 - accuracy: 0.9213\n",
            "Epoch 1057: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3245 - accuracy: 0.9217 - val_loss: 0.4740 - val_accuracy: 0.9256\n",
            "Epoch 1058/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3664 - accuracy: 0.9156\n",
            "Epoch 1058: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3687 - accuracy: 0.9147 - val_loss: 0.4620 - val_accuracy: 0.9227\n",
            "Epoch 1059/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3578 - accuracy: 0.9185\n",
            "Epoch 1059: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3561 - accuracy: 0.9191 - val_loss: 0.4199 - val_accuracy: 0.9285\n",
            "Epoch 1060/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3566 - accuracy: 0.9218\n",
            "Epoch 1060: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3578 - accuracy: 0.9214 - val_loss: 0.3615 - val_accuracy: 0.9213\n",
            "Epoch 1061/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4101 - accuracy: 0.9224\n",
            "Epoch 1061: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4090 - accuracy: 0.9224 - val_loss: 0.4038 - val_accuracy: 0.9142\n",
            "Epoch 1062/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3593 - accuracy: 0.9126\n",
            "Epoch 1062: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3602 - accuracy: 0.9120 - val_loss: 0.3830 - val_accuracy: 0.9227\n",
            "Epoch 1063/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3662 - accuracy: 0.9190\n",
            "Epoch 1063: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3640 - accuracy: 0.9194 - val_loss: 0.4304 - val_accuracy: 0.9170\n",
            "Epoch 1064/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3583 - accuracy: 0.9230\n",
            "Epoch 1064: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3572 - accuracy: 0.9231 - val_loss: 0.4117 - val_accuracy: 0.9242\n",
            "Epoch 1065/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3223 - accuracy: 0.9204\n",
            "Epoch 1065: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3226 - accuracy: 0.9205 - val_loss: 0.4101 - val_accuracy: 0.9227\n",
            "Epoch 1066/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3004 - accuracy: 0.9283\n",
            "Epoch 1066: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3004 - accuracy: 0.9283 - val_loss: 0.4084 - val_accuracy: 0.9270\n",
            "Epoch 1067/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.9223\n",
            "Epoch 1067: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3739 - accuracy: 0.9223 - val_loss: 0.5619 - val_accuracy: 0.9185\n",
            "Epoch 1068/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.9290\n",
            "Epoch 1068: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3169 - accuracy: 0.9290 - val_loss: 0.4252 - val_accuracy: 0.9242\n",
            "Epoch 1069/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2765 - accuracy: 0.9271\n",
            "Epoch 1069: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2783 - accuracy: 0.9258 - val_loss: 0.3980 - val_accuracy: 0.9270\n",
            "Epoch 1070/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.2733 - accuracy: 0.9340\n",
            "Epoch 1070: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2687 - accuracy: 0.9340 - val_loss: 0.4371 - val_accuracy: 0.9170\n",
            "Epoch 1071/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3490 - accuracy: 0.9275\n",
            "Epoch 1071: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3494 - accuracy: 0.9271 - val_loss: 0.4463 - val_accuracy: 0.9185\n",
            "Epoch 1072/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.9317\n",
            "Epoch 1072: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2579 - accuracy: 0.9317 - val_loss: 0.4014 - val_accuracy: 0.9256\n",
            "Epoch 1073/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3226 - accuracy: 0.9263\n",
            "Epoch 1073: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3234 - accuracy: 0.9257 - val_loss: 0.3928 - val_accuracy: 0.9213\n",
            "Epoch 1074/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3037 - accuracy: 0.9293\n",
            "Epoch 1074: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2999 - accuracy: 0.9298 - val_loss: 0.4065 - val_accuracy: 0.9299\n",
            "Epoch 1075/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3365 - accuracy: 0.9250\n",
            "Epoch 1075: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3344 - accuracy: 0.9251 - val_loss: 0.4523 - val_accuracy: 0.9127\n",
            "Epoch 1076/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3723 - accuracy: 0.9174\n",
            "Epoch 1076: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3732 - accuracy: 0.9164 - val_loss: 0.4102 - val_accuracy: 0.9185\n",
            "Epoch 1077/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4528 - accuracy: 0.9004\n",
            "Epoch 1077: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4516 - accuracy: 0.9011 - val_loss: 0.4266 - val_accuracy: 0.9170\n",
            "Epoch 1078/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3215 - accuracy: 0.9201\n",
            "Epoch 1078: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3203 - accuracy: 0.9205 - val_loss: 0.4107 - val_accuracy: 0.9213\n",
            "Epoch 1079/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3292 - accuracy: 0.9196\n",
            "Epoch 1079: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3255 - accuracy: 0.9201 - val_loss: 0.4409 - val_accuracy: 0.9156\n",
            "Epoch 1080/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3664 - accuracy: 0.9077\n",
            "Epoch 1080: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3794 - accuracy: 0.9079 - val_loss: 0.4022 - val_accuracy: 0.9213\n",
            "Epoch 1081/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3360 - accuracy: 0.9210\n",
            "Epoch 1081: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3360 - accuracy: 0.9210 - val_loss: 0.3986 - val_accuracy: 0.9242\n",
            "Epoch 1082/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3745 - accuracy: 0.9235\n",
            "Epoch 1082: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3738 - accuracy: 0.9233 - val_loss: 0.4829 - val_accuracy: 0.9070\n",
            "Epoch 1083/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3684 - accuracy: 0.9223\n",
            "Epoch 1083: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3688 - accuracy: 0.9218 - val_loss: 0.4507 - val_accuracy: 0.9056\n",
            "Epoch 1084/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3539 - accuracy: 0.9186\n",
            "Epoch 1084: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3567 - accuracy: 0.9183 - val_loss: 0.4289 - val_accuracy: 0.9227\n",
            "Epoch 1085/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3370 - accuracy: 0.9215\n",
            "Epoch 1085: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3396 - accuracy: 0.9217 - val_loss: 0.4218 - val_accuracy: 0.9113\n",
            "Epoch 1086/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.9217\n",
            "Epoch 1086: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3389 - accuracy: 0.9217 - val_loss: 0.4568 - val_accuracy: 0.9242\n",
            "Epoch 1087/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3616 - accuracy: 0.9220\n",
            "Epoch 1087: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3626 - accuracy: 0.9220 - val_loss: 0.4085 - val_accuracy: 0.9256\n",
            "Epoch 1088/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.9266\n",
            "Epoch 1088: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3460 - accuracy: 0.9266 - val_loss: 0.4664 - val_accuracy: 0.9270\n",
            "Epoch 1089/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.9231\n",
            "Epoch 1089: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3205 - accuracy: 0.9231 - val_loss: 0.4775 - val_accuracy: 0.9185\n",
            "Epoch 1090/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3602 - accuracy: 0.9207\n",
            "Epoch 1090: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3620 - accuracy: 0.9205 - val_loss: 0.3975 - val_accuracy: 0.9185\n",
            "Epoch 1091/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.9198\n",
            "Epoch 1091: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3228 - accuracy: 0.9198 - val_loss: 0.3950 - val_accuracy: 0.9199\n",
            "Epoch 1092/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3159 - accuracy: 0.9271\n",
            "Epoch 1092: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3164 - accuracy: 0.9273 - val_loss: 0.4662 - val_accuracy: 0.9099\n",
            "Epoch 1093/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3376 - accuracy: 0.9232\n",
            "Epoch 1093: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3385 - accuracy: 0.9231 - val_loss: 0.4026 - val_accuracy: 0.9170\n",
            "Epoch 1094/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.9224\n",
            "Epoch 1094: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3229 - accuracy: 0.9221 - val_loss: 0.3544 - val_accuracy: 0.9213\n",
            "Epoch 1095/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3163 - accuracy: 0.9223\n",
            "Epoch 1095: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3215 - accuracy: 0.9218 - val_loss: 0.4317 - val_accuracy: 0.9099\n",
            "Epoch 1096/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3282 - accuracy: 0.9196\n",
            "Epoch 1096: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3267 - accuracy: 0.9200 - val_loss: 0.3435 - val_accuracy: 0.9227\n",
            "Epoch 1097/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3542 - accuracy: 0.9228\n",
            "Epoch 1097: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3516 - accuracy: 0.9230 - val_loss: 0.3711 - val_accuracy: 0.9242\n",
            "Epoch 1098/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3171 - accuracy: 0.9268\n",
            "Epoch 1098: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3220 - accuracy: 0.9257 - val_loss: 0.3788 - val_accuracy: 0.9084\n",
            "Epoch 1099/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3540 - accuracy: 0.9223\n",
            "Epoch 1099: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3534 - accuracy: 0.9225 - val_loss: 0.4098 - val_accuracy: 0.9185\n",
            "Epoch 1100/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3479 - accuracy: 0.9230\n",
            "Epoch 1100: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3477 - accuracy: 0.9230 - val_loss: 0.4648 - val_accuracy: 0.9185\n",
            "Epoch 1101/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3526 - accuracy: 0.9214\n",
            "Epoch 1101: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3511 - accuracy: 0.9218 - val_loss: 0.3926 - val_accuracy: 0.9199\n",
            "Epoch 1102/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3669 - accuracy: 0.9193\n",
            "Epoch 1102: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3669 - accuracy: 0.9193 - val_loss: 0.4394 - val_accuracy: 0.9185\n",
            "Epoch 1103/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3249 - accuracy: 0.9254\n",
            "Epoch 1103: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3238 - accuracy: 0.9254 - val_loss: 0.4124 - val_accuracy: 0.9256\n",
            "Epoch 1104/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3485 - accuracy: 0.9233\n",
            "Epoch 1104: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3472 - accuracy: 0.9236 - val_loss: 0.3819 - val_accuracy: 0.9299\n",
            "Epoch 1105/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3458 - accuracy: 0.9158\n",
            "Epoch 1105: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3468 - accuracy: 0.9160 - val_loss: 0.3773 - val_accuracy: 0.9170\n",
            "Epoch 1106/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2981 - accuracy: 0.9305\n",
            "Epoch 1106: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3006 - accuracy: 0.9304 - val_loss: 0.3976 - val_accuracy: 0.9142\n",
            "Epoch 1107/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2808 - accuracy: 0.9310\n",
            "Epoch 1107: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2808 - accuracy: 0.9310 - val_loss: 0.4166 - val_accuracy: 0.9328\n",
            "Epoch 1108/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2867 - accuracy: 0.9324\n",
            "Epoch 1108: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2864 - accuracy: 0.9324 - val_loss: 0.4620 - val_accuracy: 0.9299\n",
            "Epoch 1109/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3554 - accuracy: 0.9204\n",
            "Epoch 1109: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3600 - accuracy: 0.9203 - val_loss: 0.4096 - val_accuracy: 0.9299\n",
            "Epoch 1110/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3545 - accuracy: 0.9191\n",
            "Epoch 1110: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3552 - accuracy: 0.9188 - val_loss: 0.3872 - val_accuracy: 0.9313\n",
            "Epoch 1111/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3056 - accuracy: 0.9239\n",
            "Epoch 1111: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3064 - accuracy: 0.9228 - val_loss: 0.4071 - val_accuracy: 0.9328\n",
            "Epoch 1112/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3082 - accuracy: 0.9313\n",
            "Epoch 1112: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3064 - accuracy: 0.9313 - val_loss: 0.3562 - val_accuracy: 0.9213\n",
            "Epoch 1113/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4194 - accuracy: 0.9149\n",
            "Epoch 1113: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4135 - accuracy: 0.9151 - val_loss: 0.4292 - val_accuracy: 0.8999\n",
            "Epoch 1114/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3911 - accuracy: 0.9133\n",
            "Epoch 1114: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3877 - accuracy: 0.9132 - val_loss: 0.3808 - val_accuracy: 0.9213\n",
            "Epoch 1115/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3688 - accuracy: 0.9251\n",
            "Epoch 1115: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3719 - accuracy: 0.9253 - val_loss: 0.3530 - val_accuracy: 0.9227\n",
            "Epoch 1116/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3595 - accuracy: 0.9204\n",
            "Epoch 1116: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3593 - accuracy: 0.9203 - val_loss: 0.3169 - val_accuracy: 0.9227\n",
            "Epoch 1117/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3370 - accuracy: 0.9259\n",
            "Epoch 1117: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3364 - accuracy: 0.9260 - val_loss: 0.3722 - val_accuracy: 0.9156\n",
            "Epoch 1118/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3035 - accuracy: 0.9291\n",
            "Epoch 1118: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3027 - accuracy: 0.9293 - val_loss: 0.4516 - val_accuracy: 0.9170\n",
            "Epoch 1119/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2646 - accuracy: 0.9326\n",
            "Epoch 1119: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2730 - accuracy: 0.9329 - val_loss: 0.3867 - val_accuracy: 0.9185\n",
            "Epoch 1120/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2974 - accuracy: 0.9337\n",
            "Epoch 1120: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2951 - accuracy: 0.9337 - val_loss: 0.3860 - val_accuracy: 0.9099\n",
            "Epoch 1121/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3762 - accuracy: 0.9188\n",
            "Epoch 1121: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3747 - accuracy: 0.9193 - val_loss: 0.3584 - val_accuracy: 0.9213\n",
            "Epoch 1122/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3193 - accuracy: 0.9272\n",
            "Epoch 1122: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3192 - accuracy: 0.9271 - val_loss: 0.4365 - val_accuracy: 0.9299\n",
            "Epoch 1123/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4393 - accuracy: 0.9219\n",
            "Epoch 1123: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4369 - accuracy: 0.9213 - val_loss: 0.3830 - val_accuracy: 0.9185\n",
            "Epoch 1124/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3343 - accuracy: 0.9174\n",
            "Epoch 1124: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3336 - accuracy: 0.9175 - val_loss: 0.3777 - val_accuracy: 0.9270\n",
            "Epoch 1125/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3231 - accuracy: 0.9235\n",
            "Epoch 1125: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3201 - accuracy: 0.9243 - val_loss: 0.3698 - val_accuracy: 0.9185\n",
            "Epoch 1126/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.9163\n",
            "Epoch 1126: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3851 - accuracy: 0.9167 - val_loss: 0.4120 - val_accuracy: 0.9041\n",
            "Epoch 1127/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3743 - accuracy: 0.9160\n",
            "Epoch 1127: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3741 - accuracy: 0.9158 - val_loss: 0.4278 - val_accuracy: 0.9142\n",
            "Epoch 1128/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3681 - accuracy: 0.9238\n",
            "Epoch 1128: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3681 - accuracy: 0.9238 - val_loss: 0.3888 - val_accuracy: 0.9199\n",
            "Epoch 1129/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3601 - accuracy: 0.9251\n",
            "Epoch 1129: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3635 - accuracy: 0.9250 - val_loss: 0.4387 - val_accuracy: 0.9256\n",
            "Epoch 1130/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3653 - accuracy: 0.9153\n",
            "Epoch 1130: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3631 - accuracy: 0.9157 - val_loss: 0.3969 - val_accuracy: 0.9185\n",
            "Epoch 1131/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3149 - accuracy: 0.9236\n",
            "Epoch 1131: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3149 - accuracy: 0.9236 - val_loss: 0.3974 - val_accuracy: 0.9213\n",
            "Epoch 1132/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3248 - accuracy: 0.9185\n",
            "Epoch 1132: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3322 - accuracy: 0.9194 - val_loss: 0.3768 - val_accuracy: 0.9199\n",
            "Epoch 1133/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3079 - accuracy: 0.9196\n",
            "Epoch 1133: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3078 - accuracy: 0.9194 - val_loss: 0.4079 - val_accuracy: 0.9127\n",
            "Epoch 1134/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.2889 - accuracy: 0.9296\n",
            "Epoch 1134: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2907 - accuracy: 0.9296 - val_loss: 0.3708 - val_accuracy: 0.9256\n",
            "Epoch 1135/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3033 - accuracy: 0.9282\n",
            "Epoch 1135: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3020 - accuracy: 0.9286 - val_loss: 0.4152 - val_accuracy: 0.9142\n",
            "Epoch 1136/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2941 - accuracy: 0.9240\n",
            "Epoch 1136: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2935 - accuracy: 0.9243 - val_loss: 0.4360 - val_accuracy: 0.9185\n",
            "Epoch 1137/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3996 - accuracy: 0.9223\n",
            "Epoch 1137: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3996 - accuracy: 0.9223 - val_loss: 0.5297 - val_accuracy: 0.9156\n",
            "Epoch 1138/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3149 - accuracy: 0.9266\n",
            "Epoch 1138: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3162 - accuracy: 0.9271 - val_loss: 0.4694 - val_accuracy: 0.9170\n",
            "Epoch 1139/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3763 - accuracy: 0.9220\n",
            "Epoch 1139: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3732 - accuracy: 0.9224 - val_loss: 0.4472 - val_accuracy: 0.9127\n",
            "Epoch 1140/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3347 - accuracy: 0.9151\n",
            "Epoch 1140: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3474 - accuracy: 0.9157 - val_loss: 0.4426 - val_accuracy: 0.9170\n",
            "Epoch 1141/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3705 - accuracy: 0.9122\n",
            "Epoch 1141: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3694 - accuracy: 0.9124 - val_loss: 0.3813 - val_accuracy: 0.9127\n",
            "Epoch 1142/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3494 - accuracy: 0.9144\n",
            "Epoch 1142: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3807 - accuracy: 0.9140 - val_loss: 0.4676 - val_accuracy: 0.9027\n",
            "Epoch 1143/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4158 - accuracy: 0.9118\n",
            "Epoch 1143: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4132 - accuracy: 0.9121 - val_loss: 0.4246 - val_accuracy: 0.9285\n",
            "Epoch 1144/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3541 - accuracy: 0.9232\n",
            "Epoch 1144: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3573 - accuracy: 0.9230 - val_loss: 0.4226 - val_accuracy: 0.9142\n",
            "Epoch 1145/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3595 - accuracy: 0.9212\n",
            "Epoch 1145: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3596 - accuracy: 0.9210 - val_loss: 0.4607 - val_accuracy: 0.9041\n",
            "Epoch 1146/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3335 - accuracy: 0.9166\n",
            "Epoch 1146: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3357 - accuracy: 0.9171 - val_loss: 0.4724 - val_accuracy: 0.9156\n",
            "Epoch 1147/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3094 - accuracy: 0.9278\n",
            "Epoch 1147: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3089 - accuracy: 0.9278 - val_loss: 0.4404 - val_accuracy: 0.9127\n",
            "Epoch 1148/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3183 - accuracy: 0.9252\n",
            "Epoch 1148: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3278 - accuracy: 0.9241 - val_loss: 0.4447 - val_accuracy: 0.9227\n",
            "Epoch 1149/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4045 - accuracy: 0.9197\n",
            "Epoch 1149: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4096 - accuracy: 0.9191 - val_loss: 0.4272 - val_accuracy: 0.9084\n",
            "Epoch 1150/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3024 - accuracy: 0.9193\n",
            "Epoch 1150: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3012 - accuracy: 0.9195 - val_loss: 0.4120 - val_accuracy: 0.9199\n",
            "Epoch 1151/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3377 - accuracy: 0.9252\n",
            "Epoch 1151: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3376 - accuracy: 0.9251 - val_loss: 0.4317 - val_accuracy: 0.9227\n",
            "Epoch 1152/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3706 - accuracy: 0.9180\n",
            "Epoch 1152: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3712 - accuracy: 0.9180 - val_loss: 0.4211 - val_accuracy: 0.9156\n",
            "Epoch 1153/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3397 - accuracy: 0.9178\n",
            "Epoch 1153: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3385 - accuracy: 0.9178 - val_loss: 0.3551 - val_accuracy: 0.9113\n",
            "Epoch 1154/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3370 - accuracy: 0.9204\n",
            "Epoch 1154: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3370 - accuracy: 0.9204 - val_loss: 0.3961 - val_accuracy: 0.9242\n",
            "Epoch 1155/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3400 - accuracy: 0.9307\n",
            "Epoch 1155: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3367 - accuracy: 0.9311 - val_loss: 0.4306 - val_accuracy: 0.9270\n",
            "Epoch 1156/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3700 - accuracy: 0.9280\n",
            "Epoch 1156: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3692 - accuracy: 0.9277 - val_loss: 0.4262 - val_accuracy: 0.9185\n",
            "Epoch 1157/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3084 - accuracy: 0.9297\n",
            "Epoch 1157: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3101 - accuracy: 0.9293 - val_loss: 0.4604 - val_accuracy: 0.9156\n",
            "Epoch 1158/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.9177\n",
            "Epoch 1158: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3814 - accuracy: 0.9180 - val_loss: 0.4287 - val_accuracy: 0.9099\n",
            "Epoch 1159/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4733 - accuracy: 0.9052\n",
            "Epoch 1159: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4678 - accuracy: 0.9058 - val_loss: 0.4251 - val_accuracy: 0.9113\n",
            "Epoch 1160/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3845 - accuracy: 0.9190\n",
            "Epoch 1160: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3812 - accuracy: 0.9191 - val_loss: 0.4078 - val_accuracy: 0.9199\n",
            "Epoch 1161/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3188 - accuracy: 0.9203\n",
            "Epoch 1161: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3178 - accuracy: 0.9205 - val_loss: 0.4163 - val_accuracy: 0.9084\n",
            "Epoch 1162/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.9252\n",
            "Epoch 1162: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3036 - accuracy: 0.9257 - val_loss: 0.3999 - val_accuracy: 0.9156\n",
            "Epoch 1163/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3285 - accuracy: 0.9216\n",
            "Epoch 1163: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3301 - accuracy: 0.9214 - val_loss: 0.3782 - val_accuracy: 0.9213\n",
            "Epoch 1164/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.9162\n",
            "Epoch 1164: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3812 - accuracy: 0.9164 - val_loss: 0.3871 - val_accuracy: 0.9256\n",
            "Epoch 1165/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3426 - accuracy: 0.9247\n",
            "Epoch 1165: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3467 - accuracy: 0.9254 - val_loss: 0.3502 - val_accuracy: 0.9213\n",
            "Epoch 1166/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3094 - accuracy: 0.9216\n",
            "Epoch 1166: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3066 - accuracy: 0.9224 - val_loss: 0.3645 - val_accuracy: 0.9156\n",
            "Epoch 1167/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3416 - accuracy: 0.9302\n",
            "Epoch 1167: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3449 - accuracy: 0.9296 - val_loss: 0.3964 - val_accuracy: 0.9270\n",
            "Epoch 1168/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2993 - accuracy: 0.9288\n",
            "Epoch 1168: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3018 - accuracy: 0.9278 - val_loss: 0.3983 - val_accuracy: 0.9227\n",
            "Epoch 1169/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.2797 - accuracy: 0.9364\n",
            "Epoch 1169: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2791 - accuracy: 0.9361 - val_loss: 0.3961 - val_accuracy: 0.9285\n",
            "Epoch 1170/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2455 - accuracy: 0.9393\n",
            "Epoch 1170: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2456 - accuracy: 0.9392 - val_loss: 0.4190 - val_accuracy: 0.9313\n",
            "Epoch 1171/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.9319\n",
            "Epoch 1171: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2870 - accuracy: 0.9319 - val_loss: 0.4298 - val_accuracy: 0.9156\n",
            "Epoch 1172/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3014 - accuracy: 0.9320\n",
            "Epoch 1172: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3073 - accuracy: 0.9319 - val_loss: 0.4557 - val_accuracy: 0.9270\n",
            "Epoch 1173/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3036 - accuracy: 0.9283\n",
            "Epoch 1173: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3029 - accuracy: 0.9284 - val_loss: 0.4060 - val_accuracy: 0.9242\n",
            "Epoch 1174/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.9326\n",
            "Epoch 1174: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2883 - accuracy: 0.9324 - val_loss: 0.4606 - val_accuracy: 0.9285\n",
            "Epoch 1175/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3328 - accuracy: 0.9328\n",
            "Epoch 1175: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3311 - accuracy: 0.9329 - val_loss: 0.4543 - val_accuracy: 0.9142\n",
            "Epoch 1176/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3390 - accuracy: 0.9281\n",
            "Epoch 1176: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3387 - accuracy: 0.9280 - val_loss: 0.4098 - val_accuracy: 0.9299\n",
            "Epoch 1177/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2928 - accuracy: 0.9292\n",
            "Epoch 1177: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2940 - accuracy: 0.9286 - val_loss: 0.4246 - val_accuracy: 0.9227\n",
            "Epoch 1178/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3078 - accuracy: 0.9310\n",
            "Epoch 1178: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3140 - accuracy: 0.9300 - val_loss: 0.4453 - val_accuracy: 0.9199\n",
            "Epoch 1179/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3317 - accuracy: 0.9229\n",
            "Epoch 1179: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3325 - accuracy: 0.9225 - val_loss: 0.4323 - val_accuracy: 0.9256\n",
            "Epoch 1180/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3322 - accuracy: 0.9242\n",
            "Epoch 1180: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3393 - accuracy: 0.9243 - val_loss: 0.3947 - val_accuracy: 0.9199\n",
            "Epoch 1181/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3221 - accuracy: 0.9281\n",
            "Epoch 1181: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3216 - accuracy: 0.9281 - val_loss: 0.3680 - val_accuracy: 0.9270\n",
            "Epoch 1182/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.9225\n",
            "Epoch 1182: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3777 - accuracy: 0.9225 - val_loss: 0.4500 - val_accuracy: 0.9099\n",
            "Epoch 1183/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.9298\n",
            "Epoch 1183: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2889 - accuracy: 0.9296 - val_loss: 0.5001 - val_accuracy: 0.9242\n",
            "Epoch 1184/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3127 - accuracy: 0.9281\n",
            "Epoch 1184: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3133 - accuracy: 0.9280 - val_loss: 0.4202 - val_accuracy: 0.9199\n",
            "Epoch 1185/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.2748 - accuracy: 0.9380\n",
            "Epoch 1185: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2787 - accuracy: 0.9376 - val_loss: 0.3933 - val_accuracy: 0.9170\n",
            "Epoch 1186/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4380 - accuracy: 0.9177\n",
            "Epoch 1186: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4387 - accuracy: 0.9171 - val_loss: 0.4133 - val_accuracy: 0.9199\n",
            "Epoch 1187/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4737 - accuracy: 0.9132\n",
            "Epoch 1187: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4725 - accuracy: 0.9131 - val_loss: 0.4972 - val_accuracy: 0.9099\n",
            "Epoch 1188/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3599 - accuracy: 0.9183\n",
            "Epoch 1188: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3599 - accuracy: 0.9183 - val_loss: 0.4567 - val_accuracy: 0.9227\n",
            "Epoch 1189/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3670 - accuracy: 0.9190\n",
            "Epoch 1189: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3665 - accuracy: 0.9187 - val_loss: 0.5052 - val_accuracy: 0.9213\n",
            "Epoch 1190/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3899 - accuracy: 0.9163\n",
            "Epoch 1190: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3869 - accuracy: 0.9157 - val_loss: 0.4807 - val_accuracy: 0.9113\n",
            "Epoch 1191/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.8938\n",
            "Epoch 1191: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4674 - accuracy: 0.8938 - val_loss: 0.4519 - val_accuracy: 0.9099\n",
            "Epoch 1192/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3656 - accuracy: 0.9074\n",
            "Epoch 1192: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3620 - accuracy: 0.9081 - val_loss: 0.4775 - val_accuracy: 0.9170\n",
            "Epoch 1193/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3438 - accuracy: 0.9184\n",
            "Epoch 1193: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3490 - accuracy: 0.9180 - val_loss: 0.4253 - val_accuracy: 0.9213\n",
            "Epoch 1194/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3923 - accuracy: 0.9201\n",
            "Epoch 1194: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3849 - accuracy: 0.9205 - val_loss: 0.4266 - val_accuracy: 0.9285\n",
            "Epoch 1195/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3237 - accuracy: 0.9197\n",
            "Epoch 1195: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3237 - accuracy: 0.9197 - val_loss: 0.4248 - val_accuracy: 0.9299\n",
            "Epoch 1196/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3389 - accuracy: 0.9210\n",
            "Epoch 1196: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3382 - accuracy: 0.9208 - val_loss: 0.4167 - val_accuracy: 0.9256\n",
            "Epoch 1197/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3939 - accuracy: 0.9206\n",
            "Epoch 1197: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3979 - accuracy: 0.9200 - val_loss: 0.3944 - val_accuracy: 0.9156\n",
            "Epoch 1198/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3688 - accuracy: 0.9188\n",
            "Epoch 1198: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3693 - accuracy: 0.9187 - val_loss: 0.3607 - val_accuracy: 0.9199\n",
            "Epoch 1199/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3309 - accuracy: 0.9253\n",
            "Epoch 1199: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3310 - accuracy: 0.9250 - val_loss: 0.3680 - val_accuracy: 0.9185\n",
            "Epoch 1200/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3676 - accuracy: 0.9168\n",
            "Epoch 1200: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3650 - accuracy: 0.9165 - val_loss: 0.3875 - val_accuracy: 0.9156\n",
            "Epoch 1201/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3155 - accuracy: 0.9216\n",
            "Epoch 1201: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3154 - accuracy: 0.9217 - val_loss: 0.3634 - val_accuracy: 0.9156\n",
            "Epoch 1202/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 1.5904 - accuracy: 0.9280\n",
            "Epoch 1202: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 1.5904 - accuracy: 0.9280 - val_loss: 0.3666 - val_accuracy: 0.9199\n",
            "Epoch 1203/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3390 - accuracy: 0.9203\n",
            "Epoch 1203: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3377 - accuracy: 0.9208 - val_loss: 0.4165 - val_accuracy: 0.9242\n",
            "Epoch 1204/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4487 - accuracy: 0.9087\n",
            "Epoch 1204: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4444 - accuracy: 0.9097 - val_loss: 0.3950 - val_accuracy: 0.9199\n",
            "Epoch 1205/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4293 - accuracy: 0.9147\n",
            "Epoch 1205: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4268 - accuracy: 0.9145 - val_loss: 0.3552 - val_accuracy: 0.9099\n",
            "Epoch 1206/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3276 - accuracy: 0.9221\n",
            "Epoch 1206: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3276 - accuracy: 0.9221 - val_loss: 0.3362 - val_accuracy: 0.9199\n",
            "Epoch 1207/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3450 - accuracy: 0.9228\n",
            "Epoch 1207: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3430 - accuracy: 0.9228 - val_loss: 0.3802 - val_accuracy: 0.9027\n",
            "Epoch 1208/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3499 - accuracy: 0.9247\n",
            "Epoch 1208: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3446 - accuracy: 0.9254 - val_loss: 0.4538 - val_accuracy: 0.9113\n",
            "Epoch 1209/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3756 - accuracy: 0.9232\n",
            "Epoch 1209: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3794 - accuracy: 0.9236 - val_loss: 0.3900 - val_accuracy: 0.9027\n",
            "Epoch 1210/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.9147\n",
            "Epoch 1210: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3597 - accuracy: 0.9147 - val_loss: 0.3560 - val_accuracy: 0.9113\n",
            "Epoch 1211/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3264 - accuracy: 0.9225\n",
            "Epoch 1211: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3247 - accuracy: 0.9230 - val_loss: 0.3949 - val_accuracy: 0.9070\n",
            "Epoch 1212/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3801 - accuracy: 0.9203\n",
            "Epoch 1212: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3761 - accuracy: 0.9203 - val_loss: 0.4158 - val_accuracy: 0.9084\n",
            "Epoch 1213/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3757 - accuracy: 0.9250\n",
            "Epoch 1213: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3758 - accuracy: 0.9243 - val_loss: 0.4297 - val_accuracy: 0.9099\n",
            "Epoch 1214/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3491 - accuracy: 0.9218\n",
            "Epoch 1214: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3414 - accuracy: 0.9230 - val_loss: 0.4355 - val_accuracy: 0.9084\n",
            "Epoch 1215/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3701 - accuracy: 0.9274\n",
            "Epoch 1215: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3701 - accuracy: 0.9274 - val_loss: 0.3453 - val_accuracy: 0.9185\n",
            "Epoch 1216/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2888 - accuracy: 0.9234\n",
            "Epoch 1216: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2888 - accuracy: 0.9234 - val_loss: 0.3469 - val_accuracy: 0.9199\n",
            "Epoch 1217/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2483 - accuracy: 0.9353\n",
            "Epoch 1217: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2474 - accuracy: 0.9354 - val_loss: 0.3880 - val_accuracy: 0.9227\n",
            "Epoch 1218/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2882 - accuracy: 0.9282\n",
            "Epoch 1218: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2875 - accuracy: 0.9284 - val_loss: 0.4194 - val_accuracy: 0.9127\n",
            "Epoch 1219/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3304 - accuracy: 0.9277\n",
            "Epoch 1219: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3302 - accuracy: 0.9276 - val_loss: 0.3755 - val_accuracy: 0.9185\n",
            "Epoch 1220/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3271 - accuracy: 0.9265\n",
            "Epoch 1220: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3272 - accuracy: 0.9266 - val_loss: 0.3808 - val_accuracy: 0.9185\n",
            "Epoch 1221/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3686 - accuracy: 0.9251\n",
            "Epoch 1221: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3696 - accuracy: 0.9248 - val_loss: 0.3504 - val_accuracy: 0.9227\n",
            "Epoch 1222/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.9308\n",
            "Epoch 1222: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2968 - accuracy: 0.9307 - val_loss: 0.3597 - val_accuracy: 0.9199\n",
            "Epoch 1223/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3178 - accuracy: 0.9299\n",
            "Epoch 1223: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3172 - accuracy: 0.9296 - val_loss: 0.3881 - val_accuracy: 0.9142\n",
            "Epoch 1224/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3411 - accuracy: 0.9341\n",
            "Epoch 1224: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3410 - accuracy: 0.9337 - val_loss: 0.4954 - val_accuracy: 0.9113\n",
            "Epoch 1225/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3067 - accuracy: 0.9290\n",
            "Epoch 1225: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3097 - accuracy: 0.9290 - val_loss: 0.4467 - val_accuracy: 0.9142\n",
            "Epoch 1226/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2878 - accuracy: 0.9311\n",
            "Epoch 1226: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2883 - accuracy: 0.9309 - val_loss: 0.4116 - val_accuracy: 0.9242\n",
            "Epoch 1227/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3107 - accuracy: 0.9314\n",
            "Epoch 1227: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3124 - accuracy: 0.9313 - val_loss: 0.4742 - val_accuracy: 0.9270\n",
            "Epoch 1228/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3481 - accuracy: 0.9255\n",
            "Epoch 1228: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3555 - accuracy: 0.9251 - val_loss: 0.3867 - val_accuracy: 0.9227\n",
            "Epoch 1229/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2956 - accuracy: 0.9227\n",
            "Epoch 1229: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2956 - accuracy: 0.9227 - val_loss: 0.3968 - val_accuracy: 0.9285\n",
            "Epoch 1230/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2773 - accuracy: 0.9305\n",
            "Epoch 1230: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2761 - accuracy: 0.9307 - val_loss: 0.3734 - val_accuracy: 0.9142\n",
            "Epoch 1231/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3488 - accuracy: 0.9165\n",
            "Epoch 1231: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3488 - accuracy: 0.9165 - val_loss: 0.3789 - val_accuracy: 0.9041\n",
            "Epoch 1232/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3236 - accuracy: 0.9277\n",
            "Epoch 1232: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3236 - accuracy: 0.9277 - val_loss: 0.3667 - val_accuracy: 0.9185\n",
            "Epoch 1233/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2815 - accuracy: 0.9316\n",
            "Epoch 1233: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2815 - accuracy: 0.9316 - val_loss: 0.3707 - val_accuracy: 0.9170\n",
            "Epoch 1234/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3297 - accuracy: 0.9292\n",
            "Epoch 1234: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3288 - accuracy: 0.9293 - val_loss: 0.3819 - val_accuracy: 0.9113\n",
            "Epoch 1235/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3157 - accuracy: 0.9270\n",
            "Epoch 1235: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3151 - accuracy: 0.9270 - val_loss: 0.3652 - val_accuracy: 0.9185\n",
            "Epoch 1236/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2889 - accuracy: 0.9300\n",
            "Epoch 1236: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2889 - accuracy: 0.9300 - val_loss: 0.3682 - val_accuracy: 0.9185\n",
            "Epoch 1237/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3670 - accuracy: 0.9201\n",
            "Epoch 1237: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3665 - accuracy: 0.9201 - val_loss: 0.3833 - val_accuracy: 0.9185\n",
            "Epoch 1238/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3418 - accuracy: 0.9268\n",
            "Epoch 1238: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3416 - accuracy: 0.9264 - val_loss: 0.3824 - val_accuracy: 0.9185\n",
            "Epoch 1239/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3420 - accuracy: 0.9242\n",
            "Epoch 1239: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3391 - accuracy: 0.9243 - val_loss: 0.4557 - val_accuracy: 0.9170\n",
            "Epoch 1240/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3378 - accuracy: 0.9268\n",
            "Epoch 1240: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3394 - accuracy: 0.9267 - val_loss: 0.4435 - val_accuracy: 0.9242\n",
            "Epoch 1241/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3677 - accuracy: 0.9234\n",
            "Epoch 1241: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3641 - accuracy: 0.9238 - val_loss: 0.4275 - val_accuracy: 0.9256\n",
            "Epoch 1242/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3432 - accuracy: 0.9207\n",
            "Epoch 1242: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3413 - accuracy: 0.9210 - val_loss: 0.4615 - val_accuracy: 0.9142\n",
            "Epoch 1243/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3388 - accuracy: 0.9257\n",
            "Epoch 1243: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3378 - accuracy: 0.9251 - val_loss: 0.4404 - val_accuracy: 0.9185\n",
            "Epoch 1244/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3180 - accuracy: 0.9282\n",
            "Epoch 1244: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3168 - accuracy: 0.9284 - val_loss: 0.4311 - val_accuracy: 0.9270\n",
            "Epoch 1245/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2881 - accuracy: 0.9292\n",
            "Epoch 1245: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2890 - accuracy: 0.9287 - val_loss: 0.3870 - val_accuracy: 0.9213\n",
            "Epoch 1246/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.9177\n",
            "Epoch 1246: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3869 - accuracy: 0.9178 - val_loss: 0.4760 - val_accuracy: 0.9170\n",
            "Epoch 1247/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3658 - accuracy: 0.9187\n",
            "Epoch 1247: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3650 - accuracy: 0.9187 - val_loss: 0.4264 - val_accuracy: 0.9185\n",
            "Epoch 1248/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3367 - accuracy: 0.9199\n",
            "Epoch 1248: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3350 - accuracy: 0.9200 - val_loss: 0.4272 - val_accuracy: 0.9256\n",
            "Epoch 1249/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.9184\n",
            "Epoch 1249: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3802 - accuracy: 0.9187 - val_loss: 0.3675 - val_accuracy: 0.9170\n",
            "Epoch 1250/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3470 - accuracy: 0.9229\n",
            "Epoch 1250: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3567 - accuracy: 0.9218 - val_loss: 0.3878 - val_accuracy: 0.9156\n",
            "Epoch 1251/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3796 - accuracy: 0.9136\n",
            "Epoch 1251: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3745 - accuracy: 0.9138 - val_loss: 0.3773 - val_accuracy: 0.9156\n",
            "Epoch 1252/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.9248\n",
            "Epoch 1252: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3290 - accuracy: 0.9248 - val_loss: 0.3730 - val_accuracy: 0.9170\n",
            "Epoch 1253/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.9165\n",
            "Epoch 1253: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3903 - accuracy: 0.9165 - val_loss: 0.3525 - val_accuracy: 0.9170\n",
            "Epoch 1254/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3023 - accuracy: 0.9240\n",
            "Epoch 1254: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3051 - accuracy: 0.9237 - val_loss: 0.3493 - val_accuracy: 0.9113\n",
            "Epoch 1255/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3229 - accuracy: 0.9255\n",
            "Epoch 1255: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3192 - accuracy: 0.9260 - val_loss: 0.3377 - val_accuracy: 0.9256\n",
            "Epoch 1256/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2643 - accuracy: 0.9348\n",
            "Epoch 1256: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2607 - accuracy: 0.9356 - val_loss: 0.3322 - val_accuracy: 0.9313\n",
            "Epoch 1257/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2900 - accuracy: 0.9315\n",
            "Epoch 1257: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2905 - accuracy: 0.9314 - val_loss: 0.3768 - val_accuracy: 0.9371\n",
            "Epoch 1258/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3367 - accuracy: 0.9273\n",
            "Epoch 1258: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3364 - accuracy: 0.9274 - val_loss: 0.3771 - val_accuracy: 0.9170\n",
            "Epoch 1259/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3209 - accuracy: 0.9279\n",
            "Epoch 1259: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3200 - accuracy: 0.9277 - val_loss: 0.3964 - val_accuracy: 0.9242\n",
            "Epoch 1260/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.9150\n",
            "Epoch 1260: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3890 - accuracy: 0.9150 - val_loss: 0.4763 - val_accuracy: 0.9041\n",
            "Epoch 1261/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.9065\n",
            "Epoch 1261: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3811 - accuracy: 0.9067 - val_loss: 0.4388 - val_accuracy: 0.9070\n",
            "Epoch 1262/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3373 - accuracy: 0.9271\n",
            "Epoch 1262: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3373 - accuracy: 0.9271 - val_loss: 0.4103 - val_accuracy: 0.9227\n",
            "Epoch 1263/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2949 - accuracy: 0.9284\n",
            "Epoch 1263: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2949 - accuracy: 0.9284 - val_loss: 0.4466 - val_accuracy: 0.9227\n",
            "Epoch 1264/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3213 - accuracy: 0.9253\n",
            "Epoch 1264: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3213 - accuracy: 0.9253 - val_loss: 0.4290 - val_accuracy: 0.9142\n",
            "Epoch 1265/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3327 - accuracy: 0.9237\n",
            "Epoch 1265: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3293 - accuracy: 0.9233 - val_loss: 0.4586 - val_accuracy: 0.9185\n",
            "Epoch 1266/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3313 - accuracy: 0.9241\n",
            "Epoch 1266: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3326 - accuracy: 0.9234 - val_loss: 0.4679 - val_accuracy: 0.9270\n",
            "Epoch 1267/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3603 - accuracy: 0.9228\n",
            "Epoch 1267: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3579 - accuracy: 0.9223 - val_loss: 0.5151 - val_accuracy: 0.9199\n",
            "Epoch 1268/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3822 - accuracy: 0.9247\n",
            "Epoch 1268: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3816 - accuracy: 0.9251 - val_loss: 0.4230 - val_accuracy: 0.9270\n",
            "Epoch 1269/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3078 - accuracy: 0.9289\n",
            "Epoch 1269: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3048 - accuracy: 0.9293 - val_loss: 0.4253 - val_accuracy: 0.9213\n",
            "Epoch 1270/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3240 - accuracy: 0.9259\n",
            "Epoch 1270: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3224 - accuracy: 0.9260 - val_loss: 0.4078 - val_accuracy: 0.9213\n",
            "Epoch 1271/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4136 - accuracy: 0.9221\n",
            "Epoch 1271: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4128 - accuracy: 0.9221 - val_loss: 0.3535 - val_accuracy: 0.9270\n",
            "Epoch 1272/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3784 - accuracy: 0.9264\n",
            "Epoch 1272: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3784 - accuracy: 0.9264 - val_loss: 0.4725 - val_accuracy: 0.9170\n",
            "Epoch 1273/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3561 - accuracy: 0.9259\n",
            "Epoch 1273: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3553 - accuracy: 0.9260 - val_loss: 0.4200 - val_accuracy: 0.9185\n",
            "Epoch 1274/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3335 - accuracy: 0.9182\n",
            "Epoch 1274: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3317 - accuracy: 0.9178 - val_loss: 0.4404 - val_accuracy: 0.9142\n",
            "Epoch 1275/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3687 - accuracy: 0.9249\n",
            "Epoch 1275: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3656 - accuracy: 0.9251 - val_loss: 0.4842 - val_accuracy: 0.9170\n",
            "Epoch 1276/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4025 - accuracy: 0.9181\n",
            "Epoch 1276: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4072 - accuracy: 0.9181 - val_loss: 0.3962 - val_accuracy: 0.9270\n",
            "Epoch 1277/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4106 - accuracy: 0.9166\n",
            "Epoch 1277: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4036 - accuracy: 0.9177 - val_loss: 0.4237 - val_accuracy: 0.9170\n",
            "Epoch 1278/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3658 - accuracy: 0.9246\n",
            "Epoch 1278: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3646 - accuracy: 0.9247 - val_loss: 0.4732 - val_accuracy: 0.9099\n",
            "Epoch 1279/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2822 - accuracy: 0.9267\n",
            "Epoch 1279: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2822 - accuracy: 0.9267 - val_loss: 0.4277 - val_accuracy: 0.9099\n",
            "Epoch 1280/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3679 - accuracy: 0.9257\n",
            "Epoch 1280: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3648 - accuracy: 0.9261 - val_loss: 0.4340 - val_accuracy: 0.9027\n",
            "Epoch 1281/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3255 - accuracy: 0.9259\n",
            "Epoch 1281: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3256 - accuracy: 0.9247 - val_loss: 0.4046 - val_accuracy: 0.9213\n",
            "Epoch 1282/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3522 - accuracy: 0.9184\n",
            "Epoch 1282: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3508 - accuracy: 0.9183 - val_loss: 0.4265 - val_accuracy: 0.9199\n",
            "Epoch 1283/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3349 - accuracy: 0.9297\n",
            "Epoch 1283: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3329 - accuracy: 0.9291 - val_loss: 0.4754 - val_accuracy: 0.9127\n",
            "Epoch 1284/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3264 - accuracy: 0.9240\n",
            "Epoch 1284: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3408 - accuracy: 0.9238 - val_loss: 0.4360 - val_accuracy: 0.9127\n",
            "Epoch 1285/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3406 - accuracy: 0.9194\n",
            "Epoch 1285: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3396 - accuracy: 0.9197 - val_loss: 0.4071 - val_accuracy: 0.9227\n",
            "Epoch 1286/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3157 - accuracy: 0.9255\n",
            "Epoch 1286: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3248 - accuracy: 0.9251 - val_loss: 0.4027 - val_accuracy: 0.9227\n",
            "Epoch 1287/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3729 - accuracy: 0.9205\n",
            "Epoch 1287: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3729 - accuracy: 0.9205 - val_loss: 0.4346 - val_accuracy: 0.9070\n",
            "Epoch 1288/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4349 - accuracy: 0.9104\n",
            "Epoch 1288: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4336 - accuracy: 0.9107 - val_loss: 0.3765 - val_accuracy: 0.9142\n",
            "Epoch 1289/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3356 - accuracy: 0.9225\n",
            "Epoch 1289: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3361 - accuracy: 0.9224 - val_loss: 0.3876 - val_accuracy: 0.9242\n",
            "Epoch 1290/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3290 - accuracy: 0.9269\n",
            "Epoch 1290: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3304 - accuracy: 0.9267 - val_loss: 0.4471 - val_accuracy: 0.9084\n",
            "Epoch 1291/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3355 - accuracy: 0.9171\n",
            "Epoch 1291: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3310 - accuracy: 0.9181 - val_loss: 0.4105 - val_accuracy: 0.9170\n",
            "Epoch 1292/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.9300\n",
            "Epoch 1292: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2738 - accuracy: 0.9300 - val_loss: 0.4791 - val_accuracy: 0.9142\n",
            "Epoch 1293/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.2761 - accuracy: 0.9300\n",
            "Epoch 1293: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2755 - accuracy: 0.9298 - val_loss: 0.4244 - val_accuracy: 0.9213\n",
            "Epoch 1294/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2708 - accuracy: 0.9327\n",
            "Epoch 1294: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2797 - accuracy: 0.9321 - val_loss: 0.5215 - val_accuracy: 0.9313\n",
            "Epoch 1295/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3194 - accuracy: 0.9258\n",
            "Epoch 1295: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3246 - accuracy: 0.9256 - val_loss: 0.4384 - val_accuracy: 0.9342\n",
            "Epoch 1296/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3241 - accuracy: 0.9253\n",
            "Epoch 1296: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3228 - accuracy: 0.9250 - val_loss: 0.4869 - val_accuracy: 0.9170\n",
            "Epoch 1297/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3432 - accuracy: 0.9216\n",
            "Epoch 1297: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3431 - accuracy: 0.9214 - val_loss: 0.4027 - val_accuracy: 0.9256\n",
            "Epoch 1298/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3001 - accuracy: 0.9248\n",
            "Epoch 1298: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2986 - accuracy: 0.9250 - val_loss: 0.3822 - val_accuracy: 0.9399\n",
            "Epoch 1299/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3160 - accuracy: 0.9308\n",
            "Epoch 1299: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3161 - accuracy: 0.9306 - val_loss: 0.3961 - val_accuracy: 0.9213\n",
            "Epoch 1300/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4067 - accuracy: 0.9184\n",
            "Epoch 1300: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4047 - accuracy: 0.9184 - val_loss: 0.4501 - val_accuracy: 0.9041\n",
            "Epoch 1301/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4114 - accuracy: 0.9081\n",
            "Epoch 1301: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4098 - accuracy: 0.9082 - val_loss: 0.4211 - val_accuracy: 0.9242\n",
            "Epoch 1302/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.9225\n",
            "Epoch 1302: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3839 - accuracy: 0.9227 - val_loss: 0.4070 - val_accuracy: 0.9185\n",
            "Epoch 1303/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4367 - accuracy: 0.9187\n",
            "Epoch 1303: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4387 - accuracy: 0.9183 - val_loss: 0.4006 - val_accuracy: 0.9156\n",
            "Epoch 1304/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.9147\n",
            "Epoch 1304: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3763 - accuracy: 0.9147 - val_loss: 0.3916 - val_accuracy: 0.9156\n",
            "Epoch 1305/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3256 - accuracy: 0.9213\n",
            "Epoch 1305: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3251 - accuracy: 0.9215 - val_loss: 0.3758 - val_accuracy: 0.9170\n",
            "Epoch 1306/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3507 - accuracy: 0.9257\n",
            "Epoch 1306: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3491 - accuracy: 0.9261 - val_loss: 0.4091 - val_accuracy: 0.9156\n",
            "Epoch 1307/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3632 - accuracy: 0.9203\n",
            "Epoch 1307: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3648 - accuracy: 0.9201 - val_loss: 0.4083 - val_accuracy: 0.9227\n",
            "Epoch 1308/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.8968\n",
            "Epoch 1308: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4573 - accuracy: 0.8968 - val_loss: 0.4665 - val_accuracy: 0.8970\n",
            "Epoch 1309/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4281 - accuracy: 0.9041\n",
            "Epoch 1309: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4242 - accuracy: 0.9041 - val_loss: 0.3822 - val_accuracy: 0.9084\n",
            "Epoch 1310/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4430 - accuracy: 0.9024\n",
            "Epoch 1310: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4419 - accuracy: 0.9025 - val_loss: 0.3801 - val_accuracy: 0.9027\n",
            "Epoch 1311/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3524 - accuracy: 0.9176\n",
            "Epoch 1311: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3508 - accuracy: 0.9178 - val_loss: 0.3866 - val_accuracy: 0.9142\n",
            "Epoch 1312/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.2991 - accuracy: 0.9261\n",
            "Epoch 1312: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2964 - accuracy: 0.9264 - val_loss: 0.3956 - val_accuracy: 0.9256\n",
            "Epoch 1313/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.9225\n",
            "Epoch 1313: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3839 - accuracy: 0.9225 - val_loss: 0.3660 - val_accuracy: 0.9185\n",
            "Epoch 1314/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.9193\n",
            "Epoch 1314: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3230 - accuracy: 0.9193 - val_loss: 0.3666 - val_accuracy: 0.9185\n",
            "Epoch 1315/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3079 - accuracy: 0.9250\n",
            "Epoch 1315: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3079 - accuracy: 0.9248 - val_loss: 0.3879 - val_accuracy: 0.9299\n",
            "Epoch 1316/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3268 - accuracy: 0.9150\n",
            "Epoch 1316: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3250 - accuracy: 0.9155 - val_loss: 0.3835 - val_accuracy: 0.9256\n",
            "Epoch 1317/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2822 - accuracy: 0.9290\n",
            "Epoch 1317: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2785 - accuracy: 0.9297 - val_loss: 0.3653 - val_accuracy: 0.9170\n",
            "Epoch 1318/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3015 - accuracy: 0.9324\n",
            "Epoch 1318: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3049 - accuracy: 0.9319 - val_loss: 0.3552 - val_accuracy: 0.9227\n",
            "Epoch 1319/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2545 - accuracy: 0.9351\n",
            "Epoch 1319: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2545 - accuracy: 0.9351 - val_loss: 0.3867 - val_accuracy: 0.9213\n",
            "Epoch 1320/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3024 - accuracy: 0.9332\n",
            "Epoch 1320: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3092 - accuracy: 0.9336 - val_loss: 0.3662 - val_accuracy: 0.9256\n",
            "Epoch 1321/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3249 - accuracy: 0.9242\n",
            "Epoch 1321: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3181 - accuracy: 0.9253 - val_loss: 0.3993 - val_accuracy: 0.9199\n",
            "Epoch 1322/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.9273\n",
            "Epoch 1322: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3298 - accuracy: 0.9273 - val_loss: 0.3570 - val_accuracy: 0.9270\n",
            "Epoch 1323/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3183 - accuracy: 0.9254\n",
            "Epoch 1323: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3186 - accuracy: 0.9256 - val_loss: 0.3667 - val_accuracy: 0.9113\n",
            "Epoch 1324/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3070 - accuracy: 0.9329\n",
            "Epoch 1324: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3033 - accuracy: 0.9327 - val_loss: 0.3761 - val_accuracy: 0.9242\n",
            "Epoch 1325/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3163 - accuracy: 0.9253\n",
            "Epoch 1325: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3163 - accuracy: 0.9253 - val_loss: 0.4075 - val_accuracy: 0.9199\n",
            "Epoch 1326/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2808 - accuracy: 0.9323\n",
            "Epoch 1326: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2808 - accuracy: 0.9323 - val_loss: 0.4234 - val_accuracy: 0.9313\n",
            "Epoch 1327/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.9326\n",
            "Epoch 1327: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3263 - accuracy: 0.9326 - val_loss: 0.3980 - val_accuracy: 0.9313\n",
            "Epoch 1328/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3024 - accuracy: 0.9351\n",
            "Epoch 1328: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2976 - accuracy: 0.9351 - val_loss: 0.4151 - val_accuracy: 0.9227\n",
            "Epoch 1329/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3467 - accuracy: 0.9300\n",
            "Epoch 1329: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3467 - accuracy: 0.9300 - val_loss: 0.4220 - val_accuracy: 0.9070\n",
            "Epoch 1330/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4138 - accuracy: 0.9157\n",
            "Epoch 1330: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4118 - accuracy: 0.9161 - val_loss: 0.4167 - val_accuracy: 0.9213\n",
            "Epoch 1331/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2883 - accuracy: 0.9283\n",
            "Epoch 1331: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2883 - accuracy: 0.9283 - val_loss: 0.4037 - val_accuracy: 0.9227\n",
            "Epoch 1332/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3145 - accuracy: 0.9246\n",
            "Epoch 1332: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3140 - accuracy: 0.9247 - val_loss: 0.4100 - val_accuracy: 0.9142\n",
            "Epoch 1333/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.9154\n",
            "Epoch 1333: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3953 - accuracy: 0.9152 - val_loss: 0.4477 - val_accuracy: 0.9113\n",
            "Epoch 1334/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3580 - accuracy: 0.9176\n",
            "Epoch 1334: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3569 - accuracy: 0.9175 - val_loss: 0.4178 - val_accuracy: 0.9199\n",
            "Epoch 1335/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3191 - accuracy: 0.9250\n",
            "Epoch 1335: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3181 - accuracy: 0.9253 - val_loss: 0.4025 - val_accuracy: 0.9285\n",
            "Epoch 1336/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2712 - accuracy: 0.9328\n",
            "Epoch 1336: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2724 - accuracy: 0.9327 - val_loss: 0.4214 - val_accuracy: 0.9328\n",
            "Epoch 1337/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.9290\n",
            "Epoch 1337: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3154 - accuracy: 0.9290 - val_loss: 0.4751 - val_accuracy: 0.9270\n",
            "Epoch 1338/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.9265\n",
            "Epoch 1338: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3220 - accuracy: 0.9266 - val_loss: 0.4374 - val_accuracy: 0.9084\n",
            "Epoch 1339/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3333 - accuracy: 0.9177\n",
            "Epoch 1339: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3339 - accuracy: 0.9175 - val_loss: 0.4176 - val_accuracy: 0.9242\n",
            "Epoch 1340/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.9215\n",
            "Epoch 1340: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3388 - accuracy: 0.9215 - val_loss: 0.4209 - val_accuracy: 0.9199\n",
            "Epoch 1341/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2758 - accuracy: 0.9262\n",
            "Epoch 1341: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2751 - accuracy: 0.9263 - val_loss: 0.3925 - val_accuracy: 0.9285\n",
            "Epoch 1342/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2668 - accuracy: 0.9308\n",
            "Epoch 1342: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2673 - accuracy: 0.9306 - val_loss: 0.4693 - val_accuracy: 0.9142\n",
            "Epoch 1343/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2776 - accuracy: 0.9313\n",
            "Epoch 1343: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2747 - accuracy: 0.9317 - val_loss: 0.4056 - val_accuracy: 0.9213\n",
            "Epoch 1344/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.9257\n",
            "Epoch 1344: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3399 - accuracy: 0.9257 - val_loss: 0.3906 - val_accuracy: 0.9270\n",
            "Epoch 1345/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4100 - accuracy: 0.9151\n",
            "Epoch 1345: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4119 - accuracy: 0.9152 - val_loss: 0.3969 - val_accuracy: 0.9256\n",
            "Epoch 1346/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3586 - accuracy: 0.9194\n",
            "Epoch 1346: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3605 - accuracy: 0.9188 - val_loss: 0.4376 - val_accuracy: 0.9256\n",
            "Epoch 1347/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3500 - accuracy: 0.9185\n",
            "Epoch 1347: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3499 - accuracy: 0.9178 - val_loss: 0.4044 - val_accuracy: 0.9299\n",
            "Epoch 1348/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.9231\n",
            "Epoch 1348: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3130 - accuracy: 0.9231 - val_loss: 0.4310 - val_accuracy: 0.9170\n",
            "Epoch 1349/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3665 - accuracy: 0.9271\n",
            "Epoch 1349: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3656 - accuracy: 0.9271 - val_loss: 0.3675 - val_accuracy: 0.9270\n",
            "Epoch 1350/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3688 - accuracy: 0.9227\n",
            "Epoch 1350: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3672 - accuracy: 0.9230 - val_loss: 0.4057 - val_accuracy: 0.9299\n",
            "Epoch 1351/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3039 - accuracy: 0.9242\n",
            "Epoch 1351: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3019 - accuracy: 0.9247 - val_loss: 0.4383 - val_accuracy: 0.9285\n",
            "Epoch 1352/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3508 - accuracy: 0.9221\n",
            "Epoch 1352: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3508 - accuracy: 0.9221 - val_loss: 0.4189 - val_accuracy: 0.9213\n",
            "Epoch 1353/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3330 - accuracy: 0.9261\n",
            "Epoch 1353: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3375 - accuracy: 0.9258 - val_loss: 0.4012 - val_accuracy: 0.9227\n",
            "Epoch 1354/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3080 - accuracy: 0.9247\n",
            "Epoch 1354: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3079 - accuracy: 0.9246 - val_loss: 0.3657 - val_accuracy: 0.9285\n",
            "Epoch 1355/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4590 - accuracy: 0.9099\n",
            "Epoch 1355: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4576 - accuracy: 0.9102 - val_loss: 0.3826 - val_accuracy: 0.9170\n",
            "Epoch 1356/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.9158\n",
            "Epoch 1356: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4432 - accuracy: 0.9158 - val_loss: 0.3615 - val_accuracy: 0.9170\n",
            "Epoch 1357/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4460 - accuracy: 0.9161\n",
            "Epoch 1357: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4428 - accuracy: 0.9162 - val_loss: 0.3421 - val_accuracy: 0.9170\n",
            "Epoch 1358/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3264 - accuracy: 0.9217\n",
            "Epoch 1358: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3258 - accuracy: 0.9217 - val_loss: 0.3351 - val_accuracy: 0.9213\n",
            "Epoch 1359/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2675 - accuracy: 0.9279\n",
            "Epoch 1359: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2632 - accuracy: 0.9293 - val_loss: 0.2951 - val_accuracy: 0.9299\n",
            "Epoch 1360/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.9307\n",
            "Epoch 1360: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3056 - accuracy: 0.9307 - val_loss: 0.3531 - val_accuracy: 0.9285\n",
            "Epoch 1361/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.9334\n",
            "Epoch 1361: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2607 - accuracy: 0.9334 - val_loss: 0.3432 - val_accuracy: 0.9313\n",
            "Epoch 1362/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3698 - accuracy: 0.9302\n",
            "Epoch 1362: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3664 - accuracy: 0.9307 - val_loss: 0.3570 - val_accuracy: 0.9242\n",
            "Epoch 1363/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2473 - accuracy: 0.9376\n",
            "Epoch 1363: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2468 - accuracy: 0.9377 - val_loss: 0.4321 - val_accuracy: 0.9285\n",
            "Epoch 1364/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3234 - accuracy: 0.9327\n",
            "Epoch 1364: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3223 - accuracy: 0.9329 - val_loss: 0.4482 - val_accuracy: 0.9142\n",
            "Epoch 1365/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2868 - accuracy: 0.9333\n",
            "Epoch 1365: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2875 - accuracy: 0.9331 - val_loss: 0.4404 - val_accuracy: 0.9285\n",
            "Epoch 1366/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2463 - accuracy: 0.9374\n",
            "Epoch 1366: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2463 - accuracy: 0.9374 - val_loss: 0.4340 - val_accuracy: 0.9356\n",
            "Epoch 1367/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2713 - accuracy: 0.9348\n",
            "Epoch 1367: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2746 - accuracy: 0.9349 - val_loss: 0.3859 - val_accuracy: 0.9285\n",
            "Epoch 1368/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3231 - accuracy: 0.9306\n",
            "Epoch 1368: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3221 - accuracy: 0.9309 - val_loss: 0.4086 - val_accuracy: 0.9213\n",
            "Epoch 1369/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3750 - accuracy: 0.9283\n",
            "Epoch 1369: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3723 - accuracy: 0.9287 - val_loss: 0.4156 - val_accuracy: 0.9242\n",
            "Epoch 1370/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3052 - accuracy: 0.9307\n",
            "Epoch 1370: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3187 - accuracy: 0.9294 - val_loss: 0.3960 - val_accuracy: 0.9270\n",
            "Epoch 1371/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.9160\n",
            "Epoch 1371: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3852 - accuracy: 0.9157 - val_loss: 0.4714 - val_accuracy: 0.8999\n",
            "Epoch 1372/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3778 - accuracy: 0.9115\n",
            "Epoch 1372: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3799 - accuracy: 0.9115 - val_loss: 0.4041 - val_accuracy: 0.9170\n",
            "Epoch 1373/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4378 - accuracy: 0.9156\n",
            "Epoch 1373: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4340 - accuracy: 0.9157 - val_loss: 0.3712 - val_accuracy: 0.9213\n",
            "Epoch 1374/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4465 - accuracy: 0.9174\n",
            "Epoch 1374: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4448 - accuracy: 0.9165 - val_loss: 0.3924 - val_accuracy: 0.9142\n",
            "Epoch 1375/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3529 - accuracy: 0.9217\n",
            "Epoch 1375: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3531 - accuracy: 0.9215 - val_loss: 0.5118 - val_accuracy: 0.9156\n",
            "Epoch 1376/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3958 - accuracy: 0.9110\n",
            "Epoch 1376: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3958 - accuracy: 0.9110 - val_loss: 0.3765 - val_accuracy: 0.9242\n",
            "Epoch 1377/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3508 - accuracy: 0.9147\n",
            "Epoch 1377: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3495 - accuracy: 0.9144 - val_loss: 0.3919 - val_accuracy: 0.9299\n",
            "Epoch 1378/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3166 - accuracy: 0.9243\n",
            "Epoch 1378: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3140 - accuracy: 0.9243 - val_loss: 0.3675 - val_accuracy: 0.9313\n",
            "Epoch 1379/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3163 - accuracy: 0.9279\n",
            "Epoch 1379: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3255 - accuracy: 0.9274 - val_loss: 0.3619 - val_accuracy: 0.9313\n",
            "Epoch 1380/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3539 - accuracy: 0.9181\n",
            "Epoch 1380: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3539 - accuracy: 0.9181 - val_loss: 0.3994 - val_accuracy: 0.9270\n",
            "Epoch 1381/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2951 - accuracy: 0.9287\n",
            "Epoch 1381: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2951 - accuracy: 0.9287 - val_loss: 0.3988 - val_accuracy: 0.9385\n",
            "Epoch 1382/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3471 - accuracy: 0.9236\n",
            "Epoch 1382: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3494 - accuracy: 0.9237 - val_loss: 0.4006 - val_accuracy: 0.9270\n",
            "Epoch 1383/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3331 - accuracy: 0.9193\n",
            "Epoch 1383: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3365 - accuracy: 0.9201 - val_loss: 0.3725 - val_accuracy: 0.9270\n",
            "Epoch 1384/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3081 - accuracy: 0.9304\n",
            "Epoch 1384: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3095 - accuracy: 0.9291 - val_loss: 0.4374 - val_accuracy: 0.9299\n",
            "Epoch 1385/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.9270\n",
            "Epoch 1385: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2976 - accuracy: 0.9270 - val_loss: 0.3983 - val_accuracy: 0.9385\n",
            "Epoch 1386/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2944 - accuracy: 0.9310\n",
            "Epoch 1386: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2944 - accuracy: 0.9310 - val_loss: 0.3869 - val_accuracy: 0.9371\n",
            "Epoch 1387/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3188 - accuracy: 0.9273\n",
            "Epoch 1387: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3190 - accuracy: 0.9271 - val_loss: 0.3561 - val_accuracy: 0.9213\n",
            "Epoch 1388/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3960 - accuracy: 0.9184\n",
            "Epoch 1388: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3953 - accuracy: 0.9183 - val_loss: 0.3775 - val_accuracy: 0.9170\n",
            "Epoch 1389/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3761 - accuracy: 0.9180\n",
            "Epoch 1389: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3761 - accuracy: 0.9180 - val_loss: 0.3680 - val_accuracy: 0.9313\n",
            "Epoch 1390/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4303 - accuracy: 0.9206\n",
            "Epoch 1390: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4288 - accuracy: 0.9208 - val_loss: 0.3453 - val_accuracy: 0.9256\n",
            "Epoch 1391/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4845 - accuracy: 0.9147\n",
            "Epoch 1391: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4835 - accuracy: 0.9145 - val_loss: 0.3525 - val_accuracy: 0.9213\n",
            "Epoch 1392/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3367 - accuracy: 0.9204\n",
            "Epoch 1392: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3367 - accuracy: 0.9204 - val_loss: 0.3640 - val_accuracy: 0.9285\n",
            "Epoch 1393/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3359 - accuracy: 0.9294\n",
            "Epoch 1393: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3369 - accuracy: 0.9291 - val_loss: 0.3833 - val_accuracy: 0.9356\n",
            "Epoch 1394/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3601 - accuracy: 0.9274\n",
            "Epoch 1394: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3610 - accuracy: 0.9263 - val_loss: 0.3613 - val_accuracy: 0.9299\n",
            "Epoch 1395/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3375 - accuracy: 0.9228\n",
            "Epoch 1395: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3375 - accuracy: 0.9228 - val_loss: 0.4085 - val_accuracy: 0.9256\n",
            "Epoch 1396/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3333 - accuracy: 0.9224\n",
            "Epoch 1396: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3317 - accuracy: 0.9220 - val_loss: 0.4164 - val_accuracy: 0.9227\n",
            "Epoch 1397/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3751 - accuracy: 0.9162\n",
            "Epoch 1397: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3751 - accuracy: 0.9162 - val_loss: 0.4160 - val_accuracy: 0.9299\n",
            "Epoch 1398/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3480 - accuracy: 0.9225\n",
            "Epoch 1398: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3485 - accuracy: 0.9227 - val_loss: 0.3864 - val_accuracy: 0.9256\n",
            "Epoch 1399/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3965 - accuracy: 0.9171\n",
            "Epoch 1399: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3954 - accuracy: 0.9173 - val_loss: 0.3931 - val_accuracy: 0.9199\n",
            "Epoch 1400/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.9207\n",
            "Epoch 1400: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3545 - accuracy: 0.9207 - val_loss: 0.4276 - val_accuracy: 0.9113\n",
            "Epoch 1401/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3412 - accuracy: 0.9268\n",
            "Epoch 1401: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3412 - accuracy: 0.9268 - val_loss: 0.3870 - val_accuracy: 0.9227\n",
            "Epoch 1402/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2951 - accuracy: 0.9312\n",
            "Epoch 1402: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2944 - accuracy: 0.9314 - val_loss: 0.4480 - val_accuracy: 0.9142\n",
            "Epoch 1403/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3231 - accuracy: 0.9288\n",
            "Epoch 1403: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3231 - accuracy: 0.9287 - val_loss: 0.4060 - val_accuracy: 0.9156\n",
            "Epoch 1404/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3272 - accuracy: 0.9227\n",
            "Epoch 1404: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3285 - accuracy: 0.9225 - val_loss: 0.4417 - val_accuracy: 0.9213\n",
            "Epoch 1405/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4261 - accuracy: 0.9134\n",
            "Epoch 1405: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4253 - accuracy: 0.9134 - val_loss: 0.4140 - val_accuracy: 0.9142\n",
            "Epoch 1406/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2841 - accuracy: 0.9283\n",
            "Epoch 1406: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2838 - accuracy: 0.9286 - val_loss: 0.3942 - val_accuracy: 0.9299\n",
            "Epoch 1407/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3666 - accuracy: 0.9238\n",
            "Epoch 1407: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3666 - accuracy: 0.9238 - val_loss: 0.4149 - val_accuracy: 0.9070\n",
            "Epoch 1408/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3540 - accuracy: 0.9222\n",
            "Epoch 1408: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3531 - accuracy: 0.9227 - val_loss: 0.4408 - val_accuracy: 0.9270\n",
            "Epoch 1409/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4127 - accuracy: 0.9216\n",
            "Epoch 1409: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4074 - accuracy: 0.9220 - val_loss: 0.5544 - val_accuracy: 0.9199\n",
            "Epoch 1410/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3405 - accuracy: 0.9238\n",
            "Epoch 1410: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3394 - accuracy: 0.9243 - val_loss: 0.4480 - val_accuracy: 0.9227\n",
            "Epoch 1411/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3091 - accuracy: 0.9326\n",
            "Epoch 1411: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3104 - accuracy: 0.9324 - val_loss: 0.4676 - val_accuracy: 0.9185\n",
            "Epoch 1412/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3358 - accuracy: 0.9263\n",
            "Epoch 1412: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3520 - accuracy: 0.9264 - val_loss: 0.4364 - val_accuracy: 0.9227\n",
            "Epoch 1413/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4320 - accuracy: 0.9221\n",
            "Epoch 1413: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4320 - accuracy: 0.9221 - val_loss: 0.3753 - val_accuracy: 0.9027\n",
            "Epoch 1414/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3649 - accuracy: 0.9132\n",
            "Epoch 1414: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3651 - accuracy: 0.9134 - val_loss: 0.4117 - val_accuracy: 0.9127\n",
            "Epoch 1415/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3757 - accuracy: 0.9163\n",
            "Epoch 1415: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3764 - accuracy: 0.9162 - val_loss: 0.4027 - val_accuracy: 0.9113\n",
            "Epoch 1416/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3171 - accuracy: 0.9217\n",
            "Epoch 1416: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3166 - accuracy: 0.9218 - val_loss: 0.4109 - val_accuracy: 0.9270\n",
            "Epoch 1417/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3261 - accuracy: 0.9256\n",
            "Epoch 1417: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3241 - accuracy: 0.9256 - val_loss: 0.4288 - val_accuracy: 0.9213\n",
            "Epoch 1418/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3583 - accuracy: 0.9230\n",
            "Epoch 1418: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3582 - accuracy: 0.9231 - val_loss: 0.4144 - val_accuracy: 0.9170\n",
            "Epoch 1419/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3121 - accuracy: 0.9258\n",
            "Epoch 1419: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3114 - accuracy: 0.9260 - val_loss: 0.4023 - val_accuracy: 0.9113\n",
            "Epoch 1420/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4020 - accuracy: 0.9157\n",
            "Epoch 1420: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4004 - accuracy: 0.9152 - val_loss: 0.4101 - val_accuracy: 0.9127\n",
            "Epoch 1421/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4234 - accuracy: 0.9203\n",
            "Epoch 1421: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4234 - accuracy: 0.9204 - val_loss: 0.4066 - val_accuracy: 0.9199\n",
            "Epoch 1422/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3803 - accuracy: 0.9185\n",
            "Epoch 1422: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3905 - accuracy: 0.9173 - val_loss: 0.4418 - val_accuracy: 0.9099\n",
            "Epoch 1423/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3674 - accuracy: 0.9181\n",
            "Epoch 1423: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3671 - accuracy: 0.9174 - val_loss: 0.4460 - val_accuracy: 0.9113\n",
            "Epoch 1424/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3141 - accuracy: 0.9269\n",
            "Epoch 1424: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3136 - accuracy: 0.9268 - val_loss: 0.4284 - val_accuracy: 0.9156\n",
            "Epoch 1425/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3783 - accuracy: 0.9161\n",
            "Epoch 1425: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3746 - accuracy: 0.9160 - val_loss: 0.4109 - val_accuracy: 0.9056\n",
            "Epoch 1426/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3573 - accuracy: 0.9199\n",
            "Epoch 1426: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3574 - accuracy: 0.9190 - val_loss: 0.4549 - val_accuracy: 0.9041\n",
            "Epoch 1427/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3357 - accuracy: 0.9250\n",
            "Epoch 1427: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3333 - accuracy: 0.9253 - val_loss: 0.4039 - val_accuracy: 0.9242\n",
            "Epoch 1428/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 0.9310\n",
            "Epoch 1428: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2708 - accuracy: 0.9311 - val_loss: 0.3628 - val_accuracy: 0.9256\n",
            "Epoch 1429/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.2275 - accuracy: 0.9426\n",
            "Epoch 1429: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2265 - accuracy: 0.9424 - val_loss: 0.3772 - val_accuracy: 0.9242\n",
            "Epoch 1430/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3328 - accuracy: 0.9378\n",
            "Epoch 1430: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3329 - accuracy: 0.9379 - val_loss: 0.3975 - val_accuracy: 0.9170\n",
            "Epoch 1431/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2721 - accuracy: 0.9390\n",
            "Epoch 1431: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2715 - accuracy: 0.9386 - val_loss: 0.4000 - val_accuracy: 0.9113\n",
            "Epoch 1432/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3545 - accuracy: 0.9273\n",
            "Epoch 1432: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3549 - accuracy: 0.9273 - val_loss: 0.3666 - val_accuracy: 0.9127\n",
            "Epoch 1433/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3322 - accuracy: 0.9276\n",
            "Epoch 1433: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3284 - accuracy: 0.9287 - val_loss: 0.3808 - val_accuracy: 0.9113\n",
            "Epoch 1434/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2945 - accuracy: 0.9296\n",
            "Epoch 1434: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2936 - accuracy: 0.9296 - val_loss: 0.3730 - val_accuracy: 0.9285\n",
            "Epoch 1435/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3406 - accuracy: 0.9280\n",
            "Epoch 1435: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3392 - accuracy: 0.9274 - val_loss: 0.3480 - val_accuracy: 0.9242\n",
            "Epoch 1436/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2757 - accuracy: 0.9325\n",
            "Epoch 1436: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2762 - accuracy: 0.9321 - val_loss: 0.3858 - val_accuracy: 0.9156\n",
            "Epoch 1437/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3180 - accuracy: 0.9283\n",
            "Epoch 1437: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3165 - accuracy: 0.9287 - val_loss: 0.4307 - val_accuracy: 0.9156\n",
            "Epoch 1438/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3638 - accuracy: 0.9219\n",
            "Epoch 1438: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3648 - accuracy: 0.9214 - val_loss: 0.4668 - val_accuracy: 0.9156\n",
            "Epoch 1439/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3056 - accuracy: 0.9271\n",
            "Epoch 1439: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3044 - accuracy: 0.9273 - val_loss: 0.3782 - val_accuracy: 0.9199\n",
            "Epoch 1440/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3054 - accuracy: 0.9281\n",
            "Epoch 1440: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3052 - accuracy: 0.9281 - val_loss: 0.3414 - val_accuracy: 0.9256\n",
            "Epoch 1441/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3111 - accuracy: 0.9226\n",
            "Epoch 1441: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3126 - accuracy: 0.9225 - val_loss: 0.3902 - val_accuracy: 0.9142\n",
            "Epoch 1442/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.9244\n",
            "Epoch 1442: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3263 - accuracy: 0.9244 - val_loss: 0.3771 - val_accuracy: 0.9227\n",
            "Epoch 1443/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3495 - accuracy: 0.9268\n",
            "Epoch 1443: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3492 - accuracy: 0.9266 - val_loss: 0.3330 - val_accuracy: 0.9270\n",
            "Epoch 1444/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3370 - accuracy: 0.9278\n",
            "Epoch 1444: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3362 - accuracy: 0.9277 - val_loss: 0.3674 - val_accuracy: 0.9227\n",
            "Epoch 1445/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.9248\n",
            "Epoch 1445: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3518 - accuracy: 0.9248 - val_loss: 0.3665 - val_accuracy: 0.9142\n",
            "Epoch 1446/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2544 - accuracy: 0.9348\n",
            "Epoch 1446: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2569 - accuracy: 0.9346 - val_loss: 0.3429 - val_accuracy: 0.9242\n",
            "Epoch 1447/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3000 - accuracy: 0.9306\n",
            "Epoch 1447: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3000 - accuracy: 0.9306 - val_loss: 0.3502 - val_accuracy: 0.9242\n",
            "Epoch 1448/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.9314\n",
            "Epoch 1448: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3178 - accuracy: 0.9314 - val_loss: 0.3671 - val_accuracy: 0.9156\n",
            "Epoch 1449/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4475 - accuracy: 0.9248\n",
            "Epoch 1449: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4475 - accuracy: 0.9248 - val_loss: 0.3993 - val_accuracy: 0.9142\n",
            "Epoch 1450/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3572 - accuracy: 0.9247\n",
            "Epoch 1450: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3565 - accuracy: 0.9248 - val_loss: 0.3674 - val_accuracy: 0.9227\n",
            "Epoch 1451/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.9306\n",
            "Epoch 1451: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3345 - accuracy: 0.9306 - val_loss: 0.3989 - val_accuracy: 0.9299\n",
            "Epoch 1452/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3090 - accuracy: 0.9246\n",
            "Epoch 1452: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3092 - accuracy: 0.9238 - val_loss: 0.3883 - val_accuracy: 0.9285\n",
            "Epoch 1453/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4162 - accuracy: 0.9158\n",
            "Epoch 1453: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4147 - accuracy: 0.9161 - val_loss: 0.3583 - val_accuracy: 0.9056\n",
            "Epoch 1454/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3922 - accuracy: 0.9164\n",
            "Epoch 1454: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3922 - accuracy: 0.9164 - val_loss: 0.3591 - val_accuracy: 0.9142\n",
            "Epoch 1455/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5019 - accuracy: 0.8956\n",
            "Epoch 1455: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5014 - accuracy: 0.8955 - val_loss: 0.4053 - val_accuracy: 0.8870\n",
            "Epoch 1456/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3886 - accuracy: 0.9041\n",
            "Epoch 1456: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3886 - accuracy: 0.9041 - val_loss: 0.3598 - val_accuracy: 0.9013\n",
            "Epoch 1457/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.9120\n",
            "Epoch 1457: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3902 - accuracy: 0.9120 - val_loss: 0.3610 - val_accuracy: 0.9156\n",
            "Epoch 1458/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4025 - accuracy: 0.9104\n",
            "Epoch 1458: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4025 - accuracy: 0.9104 - val_loss: 0.3709 - val_accuracy: 0.9142\n",
            "Epoch 1459/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3845 - accuracy: 0.9105\n",
            "Epoch 1459: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3822 - accuracy: 0.9115 - val_loss: 0.3914 - val_accuracy: 0.9156\n",
            "Epoch 1460/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2949 - accuracy: 0.9311\n",
            "Epoch 1460: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2941 - accuracy: 0.9313 - val_loss: 0.4299 - val_accuracy: 0.9142\n",
            "Epoch 1461/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3763 - accuracy: 0.9188\n",
            "Epoch 1461: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3755 - accuracy: 0.9188 - val_loss: 0.4050 - val_accuracy: 0.9156\n",
            "Epoch 1462/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2928 - accuracy: 0.9250\n",
            "Epoch 1462: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2928 - accuracy: 0.9250 - val_loss: 0.3802 - val_accuracy: 0.9213\n",
            "Epoch 1463/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2925 - accuracy: 0.9310\n",
            "Epoch 1463: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2971 - accuracy: 0.9293 - val_loss: 0.4183 - val_accuracy: 0.9242\n",
            "Epoch 1464/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3061 - accuracy: 0.9289\n",
            "Epoch 1464: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3030 - accuracy: 0.9287 - val_loss: 0.4583 - val_accuracy: 0.9213\n",
            "Epoch 1465/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.9294\n",
            "Epoch 1465: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3364 - accuracy: 0.9294 - val_loss: 0.4100 - val_accuracy: 0.9199\n",
            "Epoch 1466/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3085 - accuracy: 0.9258\n",
            "Epoch 1466: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3082 - accuracy: 0.9258 - val_loss: 0.4525 - val_accuracy: 0.9199\n",
            "Epoch 1467/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2470 - accuracy: 0.9354\n",
            "Epoch 1467: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2472 - accuracy: 0.9351 - val_loss: 0.4448 - val_accuracy: 0.9227\n",
            "Epoch 1468/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3306 - accuracy: 0.9260\n",
            "Epoch 1468: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3393 - accuracy: 0.9260 - val_loss: 0.3895 - val_accuracy: 0.9156\n",
            "Epoch 1469/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3533 - accuracy: 0.9227\n",
            "Epoch 1469: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3533 - accuracy: 0.9227 - val_loss: 0.4280 - val_accuracy: 0.9213\n",
            "Epoch 1470/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3400 - accuracy: 0.9194\n",
            "Epoch 1470: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3400 - accuracy: 0.9194 - val_loss: 0.3741 - val_accuracy: 0.9185\n",
            "Epoch 1471/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2897 - accuracy: 0.9286\n",
            "Epoch 1471: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2897 - accuracy: 0.9286 - val_loss: 0.3935 - val_accuracy: 0.9213\n",
            "Epoch 1472/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3225 - accuracy: 0.9294\n",
            "Epoch 1472: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3217 - accuracy: 0.9294 - val_loss: 0.3950 - val_accuracy: 0.9242\n",
            "Epoch 1473/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3318 - accuracy: 0.9289\n",
            "Epoch 1473: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3394 - accuracy: 0.9290 - val_loss: 0.3894 - val_accuracy: 0.9213\n",
            "Epoch 1474/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.9346\n",
            "Epoch 1474: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2926 - accuracy: 0.9346 - val_loss: 0.4029 - val_accuracy: 0.9199\n",
            "Epoch 1475/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.9259\n",
            "Epoch 1475: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3047 - accuracy: 0.9258 - val_loss: 0.4283 - val_accuracy: 0.9285\n",
            "Epoch 1476/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3532 - accuracy: 0.9263\n",
            "Epoch 1476: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3518 - accuracy: 0.9260 - val_loss: 0.4132 - val_accuracy: 0.9199\n",
            "Epoch 1477/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3692 - accuracy: 0.9258\n",
            "Epoch 1477: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3693 - accuracy: 0.9250 - val_loss: 0.3621 - val_accuracy: 0.9256\n",
            "Epoch 1478/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4243 - accuracy: 0.9242\n",
            "Epoch 1478: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4214 - accuracy: 0.9238 - val_loss: 0.4445 - val_accuracy: 0.9213\n",
            "Epoch 1479/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3024 - accuracy: 0.9290\n",
            "Epoch 1479: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3024 - accuracy: 0.9290 - val_loss: 0.4050 - val_accuracy: 0.9213\n",
            "Epoch 1480/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3403 - accuracy: 0.9233\n",
            "Epoch 1480: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3392 - accuracy: 0.9236 - val_loss: 0.4029 - val_accuracy: 0.9185\n",
            "Epoch 1481/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3128 - accuracy: 0.9301\n",
            "Epoch 1481: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3097 - accuracy: 0.9304 - val_loss: 0.4043 - val_accuracy: 0.9285\n",
            "Epoch 1482/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3622 - accuracy: 0.9279\n",
            "Epoch 1482: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3619 - accuracy: 0.9278 - val_loss: 0.4015 - val_accuracy: 0.9156\n",
            "Epoch 1483/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3359 - accuracy: 0.9260\n",
            "Epoch 1483: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3359 - accuracy: 0.9260 - val_loss: 0.4584 - val_accuracy: 0.9270\n",
            "Epoch 1484/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3685 - accuracy: 0.9207\n",
            "Epoch 1484: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3685 - accuracy: 0.9207 - val_loss: 0.3869 - val_accuracy: 0.9270\n",
            "Epoch 1485/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3433 - accuracy: 0.9234\n",
            "Epoch 1485: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3433 - accuracy: 0.9234 - val_loss: 0.4554 - val_accuracy: 0.9227\n",
            "Epoch 1486/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2901 - accuracy: 0.9246\n",
            "Epoch 1486: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2884 - accuracy: 0.9251 - val_loss: 0.3708 - val_accuracy: 0.9385\n",
            "Epoch 1487/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2974 - accuracy: 0.9314\n",
            "Epoch 1487: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2961 - accuracy: 0.9313 - val_loss: 0.3711 - val_accuracy: 0.9256\n",
            "Epoch 1488/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3382 - accuracy: 0.9272\n",
            "Epoch 1488: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3355 - accuracy: 0.9274 - val_loss: 0.4606 - val_accuracy: 0.9156\n",
            "Epoch 1489/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3310 - accuracy: 0.9222\n",
            "Epoch 1489: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3313 - accuracy: 0.9221 - val_loss: 0.5016 - val_accuracy: 0.9142\n",
            "Epoch 1490/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3057 - accuracy: 0.9242\n",
            "Epoch 1490: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3111 - accuracy: 0.9240 - val_loss: 0.4837 - val_accuracy: 0.9213\n",
            "Epoch 1491/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3609 - accuracy: 0.9269\n",
            "Epoch 1491: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3595 - accuracy: 0.9270 - val_loss: 0.4272 - val_accuracy: 0.9099\n",
            "Epoch 1492/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3620 - accuracy: 0.9222\n",
            "Epoch 1492: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3603 - accuracy: 0.9217 - val_loss: 0.4970 - val_accuracy: 0.9099\n",
            "Epoch 1493/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.6444 - accuracy: 0.9142\n",
            "Epoch 1493: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6444 - accuracy: 0.9142 - val_loss: 0.4849 - val_accuracy: 0.9213\n",
            "Epoch 1494/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3463 - accuracy: 0.9204\n",
            "Epoch 1494: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3417 - accuracy: 0.9213 - val_loss: 0.4722 - val_accuracy: 0.9256\n",
            "Epoch 1495/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3509 - accuracy: 0.9262\n",
            "Epoch 1495: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3499 - accuracy: 0.9261 - val_loss: 0.4153 - val_accuracy: 0.9270\n",
            "Epoch 1496/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3578 - accuracy: 0.9242\n",
            "Epoch 1496: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3587 - accuracy: 0.9236 - val_loss: 0.4354 - val_accuracy: 0.9227\n",
            "Epoch 1497/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.9174\n",
            "Epoch 1497: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3516 - accuracy: 0.9175 - val_loss: 0.4192 - val_accuracy: 0.9213\n",
            "Epoch 1498/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3693 - accuracy: 0.9193\n",
            "Epoch 1498: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3693 - accuracy: 0.9193 - val_loss: 0.4124 - val_accuracy: 0.9142\n",
            "Epoch 1499/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.9193\n",
            "Epoch 1499: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3827 - accuracy: 0.9194 - val_loss: 0.3672 - val_accuracy: 0.9299\n",
            "Epoch 1500/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.9310\n",
            "Epoch 1500: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3518 - accuracy: 0.9310 - val_loss: 0.4591 - val_accuracy: 0.9270\n",
            "Epoch 1501/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.9290\n",
            "Epoch 1501: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3228 - accuracy: 0.9290 - val_loss: 0.3926 - val_accuracy: 0.9213\n",
            "Epoch 1502/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.9326\n",
            "Epoch 1502: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2533 - accuracy: 0.9331 - val_loss: 0.3999 - val_accuracy: 0.9270\n",
            "Epoch 1503/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3511 - accuracy: 0.9220\n",
            "Epoch 1503: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3514 - accuracy: 0.9223 - val_loss: 0.4823 - val_accuracy: 0.9185\n",
            "Epoch 1504/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3352 - accuracy: 0.9262\n",
            "Epoch 1504: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3297 - accuracy: 0.9268 - val_loss: 0.4107 - val_accuracy: 0.9185\n",
            "Epoch 1505/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3557 - accuracy: 0.9279\n",
            "Epoch 1505: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3564 - accuracy: 0.9278 - val_loss: 0.3746 - val_accuracy: 0.9170\n",
            "Epoch 1506/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.9231\n",
            "Epoch 1506: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4076 - accuracy: 0.9231 - val_loss: 0.4661 - val_accuracy: 0.9156\n",
            "Epoch 1507/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3675 - accuracy: 0.9203\n",
            "Epoch 1507: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3675 - accuracy: 0.9203 - val_loss: 0.3987 - val_accuracy: 0.9213\n",
            "Epoch 1508/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3565 - accuracy: 0.9215\n",
            "Epoch 1508: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3543 - accuracy: 0.9213 - val_loss: 0.4015 - val_accuracy: 0.9113\n",
            "Epoch 1509/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3574 - accuracy: 0.9206\n",
            "Epoch 1509: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3567 - accuracy: 0.9208 - val_loss: 0.4012 - val_accuracy: 0.9099\n",
            "Epoch 1510/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3087 - accuracy: 0.9244\n",
            "Epoch 1510: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3087 - accuracy: 0.9244 - val_loss: 0.3605 - val_accuracy: 0.9213\n",
            "Epoch 1511/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2841 - accuracy: 0.9247\n",
            "Epoch 1511: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2837 - accuracy: 0.9247 - val_loss: 0.3797 - val_accuracy: 0.9199\n",
            "Epoch 1512/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.9312\n",
            "Epoch 1512: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3254 - accuracy: 0.9310 - val_loss: 0.4006 - val_accuracy: 0.9227\n",
            "Epoch 1513/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2930 - accuracy: 0.9325\n",
            "Epoch 1513: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2930 - accuracy: 0.9324 - val_loss: 0.4277 - val_accuracy: 0.9242\n",
            "Epoch 1514/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2920 - accuracy: 0.9289\n",
            "Epoch 1514: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3000 - accuracy: 0.9284 - val_loss: 0.3940 - val_accuracy: 0.9199\n",
            "Epoch 1515/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3376 - accuracy: 0.9255\n",
            "Epoch 1515: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3371 - accuracy: 0.9254 - val_loss: 0.4049 - val_accuracy: 0.9213\n",
            "Epoch 1516/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.9264\n",
            "Epoch 1516: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3077 - accuracy: 0.9264 - val_loss: 0.4379 - val_accuracy: 0.9156\n",
            "Epoch 1517/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2562 - accuracy: 0.9355\n",
            "Epoch 1517: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2587 - accuracy: 0.9353 - val_loss: 0.4389 - val_accuracy: 0.9185\n",
            "Epoch 1518/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3239 - accuracy: 0.9323\n",
            "Epoch 1518: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3237 - accuracy: 0.9320 - val_loss: 0.3923 - val_accuracy: 0.9199\n",
            "Epoch 1519/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.9180\n",
            "Epoch 1519: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3849 - accuracy: 0.9175 - val_loss: 0.4687 - val_accuracy: 0.8999\n",
            "Epoch 1520/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.9118\n",
            "Epoch 1520: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3882 - accuracy: 0.9120 - val_loss: 0.4004 - val_accuracy: 0.9170\n",
            "Epoch 1521/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3543 - accuracy: 0.9278\n",
            "Epoch 1521: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3543 - accuracy: 0.9278 - val_loss: 0.4100 - val_accuracy: 0.9227\n",
            "Epoch 1522/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3058 - accuracy: 0.9239\n",
            "Epoch 1522: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3031 - accuracy: 0.9238 - val_loss: 0.4379 - val_accuracy: 0.9156\n",
            "Epoch 1523/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3070 - accuracy: 0.9250\n",
            "Epoch 1523: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3071 - accuracy: 0.9251 - val_loss: 0.4137 - val_accuracy: 0.9170\n",
            "Epoch 1524/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4166 - accuracy: 0.9197\n",
            "Epoch 1524: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4151 - accuracy: 0.9200 - val_loss: 0.4736 - val_accuracy: 0.9027\n",
            "Epoch 1525/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3982 - accuracy: 0.9201\n",
            "Epoch 1525: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3968 - accuracy: 0.9204 - val_loss: 0.4497 - val_accuracy: 0.9113\n",
            "Epoch 1526/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2994 - accuracy: 0.9243\n",
            "Epoch 1526: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2994 - accuracy: 0.9243 - val_loss: 0.4251 - val_accuracy: 0.9142\n",
            "Epoch 1527/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3050 - accuracy: 0.9238\n",
            "Epoch 1527: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3050 - accuracy: 0.9238 - val_loss: 0.4536 - val_accuracy: 0.8999\n",
            "Epoch 1528/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3166 - accuracy: 0.9263\n",
            "Epoch 1528: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3163 - accuracy: 0.9263 - val_loss: 0.3689 - val_accuracy: 0.9056\n",
            "Epoch 1529/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.9236\n",
            "Epoch 1529: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3901 - accuracy: 0.9238 - val_loss: 0.3472 - val_accuracy: 0.9142\n",
            "Epoch 1530/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3706 - accuracy: 0.9271\n",
            "Epoch 1530: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3706 - accuracy: 0.9271 - val_loss: 0.4148 - val_accuracy: 0.9185\n",
            "Epoch 1531/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3567 - accuracy: 0.9200\n",
            "Epoch 1531: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3564 - accuracy: 0.9201 - val_loss: 0.4164 - val_accuracy: 0.9227\n",
            "Epoch 1532/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3089 - accuracy: 0.9294\n",
            "Epoch 1532: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3162 - accuracy: 0.9291 - val_loss: 0.4415 - val_accuracy: 0.9213\n",
            "Epoch 1533/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3650 - accuracy: 0.9231\n",
            "Epoch 1533: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3650 - accuracy: 0.9231 - val_loss: 0.3802 - val_accuracy: 0.9285\n",
            "Epoch 1534/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3164 - accuracy: 0.9244\n",
            "Epoch 1534: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3164 - accuracy: 0.9244 - val_loss: 0.3842 - val_accuracy: 0.9227\n",
            "Epoch 1535/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3958 - accuracy: 0.9230\n",
            "Epoch 1535: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3958 - accuracy: 0.9230 - val_loss: 0.4308 - val_accuracy: 0.9084\n",
            "Epoch 1536/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3292 - accuracy: 0.9160\n",
            "Epoch 1536: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3292 - accuracy: 0.9160 - val_loss: 0.4347 - val_accuracy: 0.9113\n",
            "Epoch 1537/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3286 - accuracy: 0.9259\n",
            "Epoch 1537: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3273 - accuracy: 0.9261 - val_loss: 0.4834 - val_accuracy: 0.9199\n",
            "Epoch 1538/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2900 - accuracy: 0.9342\n",
            "Epoch 1538: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2906 - accuracy: 0.9334 - val_loss: 0.4610 - val_accuracy: 0.9227\n",
            "Epoch 1539/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4020 - accuracy: 0.9161\n",
            "Epoch 1539: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4005 - accuracy: 0.9148 - val_loss: 0.5375 - val_accuracy: 0.8941\n",
            "Epoch 1540/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.9075\n",
            "Epoch 1540: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3818 - accuracy: 0.9075 - val_loss: 0.4805 - val_accuracy: 0.9142\n",
            "Epoch 1541/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4929 - accuracy: 0.9010\n",
            "Epoch 1541: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4881 - accuracy: 0.9012 - val_loss: 0.4471 - val_accuracy: 0.9127\n",
            "Epoch 1542/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4103 - accuracy: 0.9046\n",
            "Epoch 1542: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4093 - accuracy: 0.9048 - val_loss: 0.4404 - val_accuracy: 0.9156\n",
            "Epoch 1543/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.9049\n",
            "Epoch 1543: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4350 - accuracy: 0.9049 - val_loss: 0.4001 - val_accuracy: 0.9285\n",
            "Epoch 1544/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3613 - accuracy: 0.9193\n",
            "Epoch 1544: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3613 - accuracy: 0.9193 - val_loss: 0.4035 - val_accuracy: 0.9199\n",
            "Epoch 1545/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3182 - accuracy: 0.9236\n",
            "Epoch 1545: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3202 - accuracy: 0.9234 - val_loss: 0.3689 - val_accuracy: 0.9242\n",
            "Epoch 1546/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3130 - accuracy: 0.9246\n",
            "Epoch 1546: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3087 - accuracy: 0.9256 - val_loss: 0.4148 - val_accuracy: 0.9199\n",
            "Epoch 1547/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.9174\n",
            "Epoch 1547: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3837 - accuracy: 0.9177 - val_loss: 0.4002 - val_accuracy: 0.9185\n",
            "Epoch 1548/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.9215\n",
            "Epoch 1548: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3550 - accuracy: 0.9215 - val_loss: 0.3589 - val_accuracy: 0.9156\n",
            "Epoch 1549/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3217 - accuracy: 0.9228\n",
            "Epoch 1549: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3212 - accuracy: 0.9224 - val_loss: 0.3967 - val_accuracy: 0.9170\n",
            "Epoch 1550/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.2723 - accuracy: 0.9268\n",
            "Epoch 1550: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2716 - accuracy: 0.9271 - val_loss: 0.4226 - val_accuracy: 0.9084\n",
            "Epoch 1551/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3373 - accuracy: 0.9289\n",
            "Epoch 1551: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3379 - accuracy: 0.9290 - val_loss: 0.4134 - val_accuracy: 0.9199\n",
            "Epoch 1552/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2933 - accuracy: 0.9351\n",
            "Epoch 1552: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2923 - accuracy: 0.9353 - val_loss: 0.4164 - val_accuracy: 0.9270\n",
            "Epoch 1553/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3680 - accuracy: 0.9221\n",
            "Epoch 1553: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3945 - accuracy: 0.9218 - val_loss: 0.4349 - val_accuracy: 0.9142\n",
            "Epoch 1554/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3200 - accuracy: 0.9252\n",
            "Epoch 1554: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3192 - accuracy: 0.9253 - val_loss: 0.4085 - val_accuracy: 0.9156\n",
            "Epoch 1555/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4792 - accuracy: 0.9098\n",
            "Epoch 1555: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4782 - accuracy: 0.9099 - val_loss: 0.4498 - val_accuracy: 0.8999\n",
            "Epoch 1556/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3925 - accuracy: 0.9061\n",
            "Epoch 1556: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3890 - accuracy: 0.9065 - val_loss: 0.4622 - val_accuracy: 0.9142\n",
            "Epoch 1557/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3683 - accuracy: 0.9141\n",
            "Epoch 1557: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3683 - accuracy: 0.9141 - val_loss: 0.4193 - val_accuracy: 0.9056\n",
            "Epoch 1558/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.9173\n",
            "Epoch 1558: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3785 - accuracy: 0.9173 - val_loss: 0.5096 - val_accuracy: 0.9056\n",
            "Epoch 1559/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3608 - accuracy: 0.9193\n",
            "Epoch 1559: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3599 - accuracy: 0.9195 - val_loss: 0.3866 - val_accuracy: 0.9199\n",
            "Epoch 1560/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4086 - accuracy: 0.9179\n",
            "Epoch 1560: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4082 - accuracy: 0.9178 - val_loss: 0.4653 - val_accuracy: 0.8984\n",
            "Epoch 1561/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3311 - accuracy: 0.9196\n",
            "Epoch 1561: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3293 - accuracy: 0.9198 - val_loss: 0.5549 - val_accuracy: 0.9170\n",
            "Epoch 1562/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.2958 - accuracy: 0.9290\n",
            "Epoch 1562: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2938 - accuracy: 0.9291 - val_loss: 0.4664 - val_accuracy: 0.9199\n",
            "Epoch 1563/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3167 - accuracy: 0.9300\n",
            "Epoch 1563: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3127 - accuracy: 0.9304 - val_loss: 0.5101 - val_accuracy: 0.9170\n",
            "Epoch 1564/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2986 - accuracy: 0.9319\n",
            "Epoch 1564: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2951 - accuracy: 0.9316 - val_loss: 0.4500 - val_accuracy: 0.9227\n",
            "Epoch 1565/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3502 - accuracy: 0.9284\n",
            "Epoch 1565: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3502 - accuracy: 0.9284 - val_loss: 0.4690 - val_accuracy: 0.9070\n",
            "Epoch 1566/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3356 - accuracy: 0.9209\n",
            "Epoch 1566: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3325 - accuracy: 0.9213 - val_loss: 0.4028 - val_accuracy: 0.9113\n",
            "Epoch 1567/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2950 - accuracy: 0.9310\n",
            "Epoch 1567: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2948 - accuracy: 0.9310 - val_loss: 0.4127 - val_accuracy: 0.9227\n",
            "Epoch 1568/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2904 - accuracy: 0.9334\n",
            "Epoch 1568: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2901 - accuracy: 0.9333 - val_loss: 0.4666 - val_accuracy: 0.9299\n",
            "Epoch 1569/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2658 - accuracy: 0.9363\n",
            "Epoch 1569: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2658 - accuracy: 0.9363 - val_loss: 0.4676 - val_accuracy: 0.9299\n",
            "Epoch 1570/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3232 - accuracy: 0.9275\n",
            "Epoch 1570: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3228 - accuracy: 0.9276 - val_loss: 0.4578 - val_accuracy: 0.9270\n",
            "Epoch 1571/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3515 - accuracy: 0.9274\n",
            "Epoch 1571: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3517 - accuracy: 0.9266 - val_loss: 0.4392 - val_accuracy: 0.9156\n",
            "Epoch 1572/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3507 - accuracy: 0.9238\n",
            "Epoch 1572: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3524 - accuracy: 0.9238 - val_loss: 0.4585 - val_accuracy: 0.9099\n",
            "Epoch 1573/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3192 - accuracy: 0.9204\n",
            "Epoch 1573: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3179 - accuracy: 0.9200 - val_loss: 0.4024 - val_accuracy: 0.9242\n",
            "Epoch 1574/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3704 - accuracy: 0.9306\n",
            "Epoch 1574: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3704 - accuracy: 0.9306 - val_loss: 0.4039 - val_accuracy: 0.9285\n",
            "Epoch 1575/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.9200\n",
            "Epoch 1575: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3804 - accuracy: 0.9203 - val_loss: 0.3849 - val_accuracy: 0.9199\n",
            "Epoch 1576/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3682 - accuracy: 0.9216\n",
            "Epoch 1576: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3692 - accuracy: 0.9217 - val_loss: 0.3962 - val_accuracy: 0.9185\n",
            "Epoch 1577/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4095 - accuracy: 0.9223\n",
            "Epoch 1577: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4059 - accuracy: 0.9228 - val_loss: 0.4379 - val_accuracy: 0.9256\n",
            "Epoch 1578/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2920 - accuracy: 0.9302\n",
            "Epoch 1578: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2934 - accuracy: 0.9298 - val_loss: 0.4990 - val_accuracy: 0.9227\n",
            "Epoch 1579/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3340 - accuracy: 0.9253\n",
            "Epoch 1579: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3370 - accuracy: 0.9244 - val_loss: 0.3991 - val_accuracy: 0.9199\n",
            "Epoch 1580/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3015 - accuracy: 0.9238\n",
            "Epoch 1580: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3017 - accuracy: 0.9240 - val_loss: 0.3903 - val_accuracy: 0.9013\n",
            "Epoch 1581/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3494 - accuracy: 0.9216\n",
            "Epoch 1581: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3467 - accuracy: 0.9223 - val_loss: 0.4184 - val_accuracy: 0.9142\n",
            "Epoch 1582/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4277 - accuracy: 0.9196\n",
            "Epoch 1582: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4343 - accuracy: 0.9190 - val_loss: 0.4162 - val_accuracy: 0.9213\n",
            "Epoch 1583/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4126 - accuracy: 0.9138\n",
            "Epoch 1583: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4086 - accuracy: 0.9147 - val_loss: 0.3777 - val_accuracy: 0.9227\n",
            "Epoch 1584/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.9197\n",
            "Epoch 1584: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3855 - accuracy: 0.9200 - val_loss: 0.4013 - val_accuracy: 0.9256\n",
            "Epoch 1585/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4195 - accuracy: 0.9135\n",
            "Epoch 1585: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4196 - accuracy: 0.9132 - val_loss: 0.4422 - val_accuracy: 0.9084\n",
            "Epoch 1586/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4352 - accuracy: 0.9022\n",
            "Epoch 1586: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4345 - accuracy: 0.9022 - val_loss: 0.4988 - val_accuracy: 0.9013\n",
            "Epoch 1587/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4426 - accuracy: 0.9072\n",
            "Epoch 1587: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4500 - accuracy: 0.9075 - val_loss: 0.5173 - val_accuracy: 0.9013\n",
            "Epoch 1588/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.9069\n",
            "Epoch 1588: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3896 - accuracy: 0.9072 - val_loss: 0.4488 - val_accuracy: 0.9242\n",
            "Epoch 1589/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.9175\n",
            "Epoch 1589: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3513 - accuracy: 0.9181 - val_loss: 0.3865 - val_accuracy: 0.9227\n",
            "Epoch 1590/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3257 - accuracy: 0.9213\n",
            "Epoch 1590: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3250 - accuracy: 0.9215 - val_loss: 0.4150 - val_accuracy: 0.9199\n",
            "Epoch 1591/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3557 - accuracy: 0.9188\n",
            "Epoch 1591: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3608 - accuracy: 0.9184 - val_loss: 0.4631 - val_accuracy: 0.9185\n",
            "Epoch 1592/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2999 - accuracy: 0.9201\n",
            "Epoch 1592: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2987 - accuracy: 0.9205 - val_loss: 0.4809 - val_accuracy: 0.9185\n",
            "Epoch 1593/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3017 - accuracy: 0.9288\n",
            "Epoch 1593: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2999 - accuracy: 0.9287 - val_loss: 0.5308 - val_accuracy: 0.9213\n",
            "Epoch 1594/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3644 - accuracy: 0.9289\n",
            "Epoch 1594: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3583 - accuracy: 0.9293 - val_loss: 0.5235 - val_accuracy: 0.9199\n",
            "Epoch 1595/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3164 - accuracy: 0.9319\n",
            "Epoch 1595: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3161 - accuracy: 0.9319 - val_loss: 0.5502 - val_accuracy: 0.9227\n",
            "Epoch 1596/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3043 - accuracy: 0.9295\n",
            "Epoch 1596: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3023 - accuracy: 0.9294 - val_loss: 0.4899 - val_accuracy: 0.9242\n",
            "Epoch 1597/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2975 - accuracy: 0.9350\n",
            "Epoch 1597: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2971 - accuracy: 0.9350 - val_loss: 0.4505 - val_accuracy: 0.9199\n",
            "Epoch 1598/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2646 - accuracy: 0.9387\n",
            "Epoch 1598: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2684 - accuracy: 0.9379 - val_loss: 0.4603 - val_accuracy: 0.9270\n",
            "Epoch 1599/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3150 - accuracy: 0.9333\n",
            "Epoch 1599: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3168 - accuracy: 0.9329 - val_loss: 0.4853 - val_accuracy: 0.9285\n",
            "Epoch 1600/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.9317\n",
            "Epoch 1600: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3142 - accuracy: 0.9317 - val_loss: 0.4759 - val_accuracy: 0.9227\n",
            "Epoch 1601/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2571 - accuracy: 0.9365\n",
            "Epoch 1601: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2591 - accuracy: 0.9356 - val_loss: 0.5025 - val_accuracy: 0.9213\n",
            "Epoch 1602/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2834 - accuracy: 0.9335\n",
            "Epoch 1602: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2837 - accuracy: 0.9334 - val_loss: 0.4404 - val_accuracy: 0.9156\n",
            "Epoch 1603/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2498 - accuracy: 0.9426\n",
            "Epoch 1603: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2498 - accuracy: 0.9426 - val_loss: 0.4994 - val_accuracy: 0.9113\n",
            "Epoch 1604/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3226 - accuracy: 0.9286\n",
            "Epoch 1604: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3219 - accuracy: 0.9286 - val_loss: 0.4550 - val_accuracy: 0.9142\n",
            "Epoch 1605/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3684 - accuracy: 0.9214\n",
            "Epoch 1605: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3718 - accuracy: 0.9211 - val_loss: 0.5176 - val_accuracy: 0.9127\n",
            "Epoch 1606/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3783 - accuracy: 0.9176\n",
            "Epoch 1606: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3793 - accuracy: 0.9171 - val_loss: 0.4517 - val_accuracy: 0.9056\n",
            "Epoch 1607/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3450 - accuracy: 0.9247\n",
            "Epoch 1607: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3525 - accuracy: 0.9248 - val_loss: 0.4248 - val_accuracy: 0.9156\n",
            "Epoch 1608/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3227 - accuracy: 0.9281\n",
            "Epoch 1608: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3235 - accuracy: 0.9278 - val_loss: 0.4214 - val_accuracy: 0.9227\n",
            "Epoch 1609/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4188 - accuracy: 0.9173\n",
            "Epoch 1609: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4188 - accuracy: 0.9173 - val_loss: 0.4305 - val_accuracy: 0.9070\n",
            "Epoch 1610/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3482 - accuracy: 0.9190\n",
            "Epoch 1610: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3510 - accuracy: 0.9184 - val_loss: 0.3995 - val_accuracy: 0.9213\n",
            "Epoch 1611/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3936 - accuracy: 0.9065\n",
            "Epoch 1611: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3925 - accuracy: 0.9068 - val_loss: 0.3899 - val_accuracy: 0.9070\n",
            "Epoch 1612/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3659 - accuracy: 0.9173\n",
            "Epoch 1612: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3658 - accuracy: 0.9170 - val_loss: 0.3645 - val_accuracy: 0.9156\n",
            "Epoch 1613/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3236 - accuracy: 0.9236\n",
            "Epoch 1613: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3225 - accuracy: 0.9240 - val_loss: 0.3849 - val_accuracy: 0.9127\n",
            "Epoch 1614/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4496 - accuracy: 0.9140\n",
            "Epoch 1614: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4477 - accuracy: 0.9142 - val_loss: 0.3963 - val_accuracy: 0.9113\n",
            "Epoch 1615/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3223 - accuracy: 0.9196\n",
            "Epoch 1615: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3297 - accuracy: 0.9193 - val_loss: 0.4431 - val_accuracy: 0.9185\n",
            "Epoch 1616/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3992 - accuracy: 0.9167\n",
            "Epoch 1616: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3967 - accuracy: 0.9170 - val_loss: 0.4388 - val_accuracy: 0.9185\n",
            "Epoch 1617/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3585 - accuracy: 0.9255\n",
            "Epoch 1617: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3572 - accuracy: 0.9256 - val_loss: 0.3688 - val_accuracy: 0.9142\n",
            "Epoch 1618/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3151 - accuracy: 0.9264\n",
            "Epoch 1618: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3181 - accuracy: 0.9258 - val_loss: 0.3848 - val_accuracy: 0.9185\n",
            "Epoch 1619/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4166 - accuracy: 0.9262\n",
            "Epoch 1619: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4302 - accuracy: 0.9261 - val_loss: 0.3923 - val_accuracy: 0.9185\n",
            "Epoch 1620/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3350 - accuracy: 0.9221\n",
            "Epoch 1620: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3355 - accuracy: 0.9221 - val_loss: 0.3925 - val_accuracy: 0.9170\n",
            "Epoch 1621/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.9178\n",
            "Epoch 1621: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3849 - accuracy: 0.9177 - val_loss: 0.4286 - val_accuracy: 0.9199\n",
            "Epoch 1622/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.9078\n",
            "Epoch 1622: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3867 - accuracy: 0.9078 - val_loss: 0.3960 - val_accuracy: 0.9113\n",
            "Epoch 1623/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.9123\n",
            "Epoch 1623: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3842 - accuracy: 0.9128 - val_loss: 0.4024 - val_accuracy: 0.9084\n",
            "Epoch 1624/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4177 - accuracy: 0.9142\n",
            "Epoch 1624: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4177 - accuracy: 0.9142 - val_loss: 0.3671 - val_accuracy: 0.9099\n",
            "Epoch 1625/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3508 - accuracy: 0.9188\n",
            "Epoch 1625: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3467 - accuracy: 0.9200 - val_loss: 0.3485 - val_accuracy: 0.9170\n",
            "Epoch 1626/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3391 - accuracy: 0.9307\n",
            "Epoch 1626: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3394 - accuracy: 0.9300 - val_loss: 0.3254 - val_accuracy: 0.9242\n",
            "Epoch 1627/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2929 - accuracy: 0.9294\n",
            "Epoch 1627: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2921 - accuracy: 0.9296 - val_loss: 0.3756 - val_accuracy: 0.9213\n",
            "Epoch 1628/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3892 - accuracy: 0.9230\n",
            "Epoch 1628: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3853 - accuracy: 0.9228 - val_loss: 0.4386 - val_accuracy: 0.9170\n",
            "Epoch 1629/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3464 - accuracy: 0.9234\n",
            "Epoch 1629: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3454 - accuracy: 0.9233 - val_loss: 0.4510 - val_accuracy: 0.9170\n",
            "Epoch 1630/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3556 - accuracy: 0.9268\n",
            "Epoch 1630: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3556 - accuracy: 0.9268 - val_loss: 0.4759 - val_accuracy: 0.9056\n",
            "Epoch 1631/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3591 - accuracy: 0.9231\n",
            "Epoch 1631: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3591 - accuracy: 0.9231 - val_loss: 0.4817 - val_accuracy: 0.9056\n",
            "Epoch 1632/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3969 - accuracy: 0.9138\n",
            "Epoch 1632: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3969 - accuracy: 0.9138 - val_loss: 0.4611 - val_accuracy: 0.9056\n",
            "Epoch 1633/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3581 - accuracy: 0.9134\n",
            "Epoch 1633: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3581 - accuracy: 0.9134 - val_loss: 0.4277 - val_accuracy: 0.9156\n",
            "Epoch 1634/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4143 - accuracy: 0.9222\n",
            "Epoch 1634: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4132 - accuracy: 0.9221 - val_loss: 0.5491 - val_accuracy: 0.9041\n",
            "Epoch 1635/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3315 - accuracy: 0.9231\n",
            "Epoch 1635: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3305 - accuracy: 0.9227 - val_loss: 0.4259 - val_accuracy: 0.9127\n",
            "Epoch 1636/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3928 - accuracy: 0.9199\n",
            "Epoch 1636: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3928 - accuracy: 0.9195 - val_loss: 0.4727 - val_accuracy: 0.9056\n",
            "Epoch 1637/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3648 - accuracy: 0.9181\n",
            "Epoch 1637: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3924 - accuracy: 0.9184 - val_loss: 0.3814 - val_accuracy: 0.9156\n",
            "Epoch 1638/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.9183\n",
            "Epoch 1638: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3364 - accuracy: 0.9183 - val_loss: 0.3948 - val_accuracy: 0.9084\n",
            "Epoch 1639/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2611 - accuracy: 0.9307\n",
            "Epoch 1639: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2664 - accuracy: 0.9307 - val_loss: 0.3972 - val_accuracy: 0.9185\n",
            "Epoch 1640/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3366 - accuracy: 0.9271\n",
            "Epoch 1640: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3365 - accuracy: 0.9268 - val_loss: 0.4643 - val_accuracy: 0.9185\n",
            "Epoch 1641/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4104 - accuracy: 0.9252\n",
            "Epoch 1641: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.4072 - accuracy: 0.9256 - val_loss: 0.4271 - val_accuracy: 0.9142\n",
            "Epoch 1642/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.9191\n",
            "Epoch 1642: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3658 - accuracy: 0.9191 - val_loss: 0.4218 - val_accuracy: 0.9113\n",
            "Epoch 1643/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.9218\n",
            "Epoch 1643: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3349 - accuracy: 0.9218 - val_loss: 0.4354 - val_accuracy: 0.9056\n",
            "Epoch 1644/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3900 - accuracy: 0.9197\n",
            "Epoch 1644: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3834 - accuracy: 0.9205 - val_loss: 0.4646 - val_accuracy: 0.9213\n",
            "Epoch 1645/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3960 - accuracy: 0.9255\n",
            "Epoch 1645: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3933 - accuracy: 0.9257 - val_loss: 0.4788 - val_accuracy: 0.9099\n",
            "Epoch 1646/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3206 - accuracy: 0.9278\n",
            "Epoch 1646: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3191 - accuracy: 0.9281 - val_loss: 0.4033 - val_accuracy: 0.9242\n",
            "Epoch 1647/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.9289\n",
            "Epoch 1647: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3801 - accuracy: 0.9287 - val_loss: 0.4125 - val_accuracy: 0.9285\n",
            "Epoch 1648/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4195 - accuracy: 0.9173\n",
            "Epoch 1648: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4183 - accuracy: 0.9174 - val_loss: 0.3654 - val_accuracy: 0.9127\n",
            "Epoch 1649/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4295 - accuracy: 0.9122\n",
            "Epoch 1649: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4315 - accuracy: 0.9115 - val_loss: 0.3564 - val_accuracy: 0.9285\n",
            "Epoch 1650/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4395 - accuracy: 0.9227\n",
            "Epoch 1650: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4391 - accuracy: 0.9225 - val_loss: 0.3658 - val_accuracy: 0.9185\n",
            "Epoch 1651/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3775 - accuracy: 0.9128\n",
            "Epoch 1651: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3768 - accuracy: 0.9135 - val_loss: 0.3901 - val_accuracy: 0.9113\n",
            "Epoch 1652/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3492 - accuracy: 0.9158\n",
            "Epoch 1652: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3492 - accuracy: 0.9158 - val_loss: 0.4002 - val_accuracy: 0.9170\n",
            "Epoch 1653/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.9194\n",
            "Epoch 1653: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3320 - accuracy: 0.9193 - val_loss: 0.3773 - val_accuracy: 0.9285\n",
            "Epoch 1654/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.9200\n",
            "Epoch 1654: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3823 - accuracy: 0.9200 - val_loss: 0.4039 - val_accuracy: 0.9285\n",
            "Epoch 1655/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.9187\n",
            "Epoch 1655: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3842 - accuracy: 0.9187 - val_loss: 0.3823 - val_accuracy: 0.9270\n",
            "Epoch 1656/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3348 - accuracy: 0.9228\n",
            "Epoch 1656: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3362 - accuracy: 0.9238 - val_loss: 0.4885 - val_accuracy: 0.9299\n",
            "Epoch 1657/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3302 - accuracy: 0.9252\n",
            "Epoch 1657: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.9179 - accuracy: 0.9251 - val_loss: 0.3863 - val_accuracy: 0.9256\n",
            "Epoch 1658/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.9112\n",
            "Epoch 1658: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3900 - accuracy: 0.9105 - val_loss: 0.4722 - val_accuracy: 0.9056\n",
            "Epoch 1659/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.9136\n",
            "Epoch 1659: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3876 - accuracy: 0.9135 - val_loss: 0.4098 - val_accuracy: 0.9185\n",
            "Epoch 1660/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3665 - accuracy: 0.9228\n",
            "Epoch 1660: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3666 - accuracy: 0.9231 - val_loss: 0.3995 - val_accuracy: 0.9299\n",
            "Epoch 1661/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3693 - accuracy: 0.9147\n",
            "Epoch 1661: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3693 - accuracy: 0.9147 - val_loss: 0.4323 - val_accuracy: 0.9142\n",
            "Epoch 1662/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3750 - accuracy: 0.9154\n",
            "Epoch 1662: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3790 - accuracy: 0.9138 - val_loss: 0.4214 - val_accuracy: 0.9270\n",
            "Epoch 1663/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3688 - accuracy: 0.9249\n",
            "Epoch 1663: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3659 - accuracy: 0.9254 - val_loss: 0.4394 - val_accuracy: 0.9156\n",
            "Epoch 1664/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.9244\n",
            "Epoch 1664: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3659 - accuracy: 0.9244 - val_loss: 0.4469 - val_accuracy: 0.9156\n",
            "Epoch 1665/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5000 - accuracy: 0.9201\n",
            "Epoch 1665: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5004 - accuracy: 0.9198 - val_loss: 0.4831 - val_accuracy: 0.8984\n",
            "Epoch 1666/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4206 - accuracy: 0.9066\n",
            "Epoch 1666: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4196 - accuracy: 0.9068 - val_loss: 0.3803 - val_accuracy: 0.9142\n",
            "Epoch 1667/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3148 - accuracy: 0.9261\n",
            "Epoch 1667: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3207 - accuracy: 0.9251 - val_loss: 0.4066 - val_accuracy: 0.9142\n",
            "Epoch 1668/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3195 - accuracy: 0.9254\n",
            "Epoch 1668: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3207 - accuracy: 0.9248 - val_loss: 0.4107 - val_accuracy: 0.9199\n",
            "Epoch 1669/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3636 - accuracy: 0.9200\n",
            "Epoch 1669: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3625 - accuracy: 0.9201 - val_loss: 0.4676 - val_accuracy: 0.9270\n",
            "Epoch 1670/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3091 - accuracy: 0.9307\n",
            "Epoch 1670: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3069 - accuracy: 0.9313 - val_loss: 0.4813 - val_accuracy: 0.9270\n",
            "Epoch 1671/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2939 - accuracy: 0.9263\n",
            "Epoch 1671: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2939 - accuracy: 0.9264 - val_loss: 0.4625 - val_accuracy: 0.9299\n",
            "Epoch 1672/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3553 - accuracy: 0.9250\n",
            "Epoch 1672: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3538 - accuracy: 0.9253 - val_loss: 0.4012 - val_accuracy: 0.9270\n",
            "Epoch 1673/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3572 - accuracy: 0.9303\n",
            "Epoch 1673: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3710 - accuracy: 0.9303 - val_loss: 0.5651 - val_accuracy: 0.9256\n",
            "Epoch 1674/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2924 - accuracy: 0.9261\n",
            "Epoch 1674: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2924 - accuracy: 0.9261 - val_loss: 0.4280 - val_accuracy: 0.9285\n",
            "Epoch 1675/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.9344\n",
            "Epoch 1675: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3006 - accuracy: 0.9344 - val_loss: 0.4350 - val_accuracy: 0.9313\n",
            "Epoch 1676/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.9333\n",
            "Epoch 1676: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2857 - accuracy: 0.9333 - val_loss: 0.3964 - val_accuracy: 0.9299\n",
            "Epoch 1677/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.2726 - accuracy: 0.9378\n",
            "Epoch 1677: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2722 - accuracy: 0.9376 - val_loss: 0.4425 - val_accuracy: 0.9242\n",
            "Epoch 1678/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3287 - accuracy: 0.9289\n",
            "Epoch 1678: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3275 - accuracy: 0.9293 - val_loss: 0.3717 - val_accuracy: 0.9285\n",
            "Epoch 1679/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3172 - accuracy: 0.9335\n",
            "Epoch 1679: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3244 - accuracy: 0.9343 - val_loss: 0.4033 - val_accuracy: 0.9242\n",
            "Epoch 1680/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2983 - accuracy: 0.9322\n",
            "Epoch 1680: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2975 - accuracy: 0.9323 - val_loss: 0.3763 - val_accuracy: 0.9313\n",
            "Epoch 1681/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.9294\n",
            "Epoch 1681: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3106 - accuracy: 0.9294 - val_loss: 0.4081 - val_accuracy: 0.9299\n",
            "Epoch 1682/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5676 - accuracy: 0.9138\n",
            "Epoch 1682: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5671 - accuracy: 0.9135 - val_loss: 0.3846 - val_accuracy: 0.9156\n",
            "Epoch 1683/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3222 - accuracy: 0.9149\n",
            "Epoch 1683: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3231 - accuracy: 0.9148 - val_loss: 0.3598 - val_accuracy: 0.9185\n",
            "Epoch 1684/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3277 - accuracy: 0.9244\n",
            "Epoch 1684: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3277 - accuracy: 0.9244 - val_loss: 0.3479 - val_accuracy: 0.9227\n",
            "Epoch 1685/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2651 - accuracy: 0.9316\n",
            "Epoch 1685: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2651 - accuracy: 0.9316 - val_loss: 0.3830 - val_accuracy: 0.9199\n",
            "Epoch 1686/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3486 - accuracy: 0.9251\n",
            "Epoch 1686: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3520 - accuracy: 0.9240 - val_loss: 0.4058 - val_accuracy: 0.9227\n",
            "Epoch 1687/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3031 - accuracy: 0.9258\n",
            "Epoch 1687: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3021 - accuracy: 0.9258 - val_loss: 0.3736 - val_accuracy: 0.9142\n",
            "Epoch 1688/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2760 - accuracy: 0.9332\n",
            "Epoch 1688: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2765 - accuracy: 0.9330 - val_loss: 0.3417 - val_accuracy: 0.9356\n",
            "Epoch 1689/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2638 - accuracy: 0.9323\n",
            "Epoch 1689: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2637 - accuracy: 0.9326 - val_loss: 0.3407 - val_accuracy: 0.9328\n",
            "Epoch 1690/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3684 - accuracy: 0.9274\n",
            "Epoch 1690: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3703 - accuracy: 0.9268 - val_loss: 0.4242 - val_accuracy: 0.9185\n",
            "Epoch 1691/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3318 - accuracy: 0.9196\n",
            "Epoch 1691: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3309 - accuracy: 0.9197 - val_loss: 0.3309 - val_accuracy: 0.9213\n",
            "Epoch 1692/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3694 - accuracy: 0.9236\n",
            "Epoch 1692: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3679 - accuracy: 0.9238 - val_loss: 0.3815 - val_accuracy: 0.9113\n",
            "Epoch 1693/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4100 - accuracy: 0.9230\n",
            "Epoch 1693: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4438 - accuracy: 0.9234 - val_loss: 0.4797 - val_accuracy: 0.9127\n",
            "Epoch 1694/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4714 - accuracy: 0.9118\n",
            "Epoch 1694: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4714 - accuracy: 0.9118 - val_loss: 0.4694 - val_accuracy: 0.9185\n",
            "Epoch 1695/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3733 - accuracy: 0.9134\n",
            "Epoch 1695: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3731 - accuracy: 0.9131 - val_loss: 0.4545 - val_accuracy: 0.9156\n",
            "Epoch 1696/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.9177\n",
            "Epoch 1696: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4468 - accuracy: 0.9177 - val_loss: 0.5364 - val_accuracy: 0.9156\n",
            "Epoch 1697/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3575 - accuracy: 0.9173\n",
            "Epoch 1697: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3584 - accuracy: 0.9171 - val_loss: 0.4237 - val_accuracy: 0.9156\n",
            "Epoch 1698/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4264 - accuracy: 0.9199\n",
            "Epoch 1698: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4256 - accuracy: 0.9198 - val_loss: 0.3824 - val_accuracy: 0.9027\n",
            "Epoch 1699/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3976 - accuracy: 0.9101\n",
            "Epoch 1699: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3976 - accuracy: 0.9101 - val_loss: 0.4518 - val_accuracy: 0.8999\n",
            "Epoch 1700/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4590 - accuracy: 0.9075\n",
            "Epoch 1700: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4568 - accuracy: 0.9079 - val_loss: 0.3706 - val_accuracy: 0.9156\n",
            "Epoch 1701/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3112 - accuracy: 0.9168\n",
            "Epoch 1701: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3106 - accuracy: 0.9168 - val_loss: 0.3581 - val_accuracy: 0.9270\n",
            "Epoch 1702/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3308 - accuracy: 0.9281\n",
            "Epoch 1702: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3299 - accuracy: 0.9283 - val_loss: 0.4048 - val_accuracy: 0.9070\n",
            "Epoch 1703/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5407 - accuracy: 0.9103\n",
            "Epoch 1703: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5364 - accuracy: 0.9105 - val_loss: 0.4499 - val_accuracy: 0.9056\n",
            "Epoch 1704/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4349 - accuracy: 0.9068\n",
            "Epoch 1704: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4348 - accuracy: 0.9065 - val_loss: 0.4423 - val_accuracy: 0.9127\n",
            "Epoch 1705/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4910 - accuracy: 0.9078\n",
            "Epoch 1705: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4895 - accuracy: 0.9079 - val_loss: 0.4249 - val_accuracy: 0.9199\n",
            "Epoch 1706/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.6581 - accuracy: 0.8962\n",
            "Epoch 1706: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6545 - accuracy: 0.8961 - val_loss: 0.4209 - val_accuracy: 0.8970\n",
            "Epoch 1707/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4001 - accuracy: 0.8999\n",
            "Epoch 1707: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3996 - accuracy: 0.8998 - val_loss: 0.4008 - val_accuracy: 0.9041\n",
            "Epoch 1708/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3517 - accuracy: 0.9132\n",
            "Epoch 1708: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3506 - accuracy: 0.9135 - val_loss: 0.4457 - val_accuracy: 0.9213\n",
            "Epoch 1709/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3447 - accuracy: 0.9224\n",
            "Epoch 1709: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3389 - accuracy: 0.9230 - val_loss: 0.4333 - val_accuracy: 0.9199\n",
            "Epoch 1710/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4465 - accuracy: 0.9193\n",
            "Epoch 1710: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4445 - accuracy: 0.9193 - val_loss: 0.4119 - val_accuracy: 0.9227\n",
            "Epoch 1711/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3152 - accuracy: 0.9225\n",
            "Epoch 1711: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3178 - accuracy: 0.9221 - val_loss: 0.4319 - val_accuracy: 0.9270\n",
            "Epoch 1712/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3164 - accuracy: 0.9299\n",
            "Epoch 1712: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3166 - accuracy: 0.9298 - val_loss: 0.4012 - val_accuracy: 0.9199\n",
            "Epoch 1713/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.9309\n",
            "Epoch 1713: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3144 - accuracy: 0.9309 - val_loss: 0.4425 - val_accuracy: 0.9227\n",
            "Epoch 1714/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3389 - accuracy: 0.9311\n",
            "Epoch 1714: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3374 - accuracy: 0.9314 - val_loss: 0.4386 - val_accuracy: 0.9227\n",
            "Epoch 1715/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3335 - accuracy: 0.9231\n",
            "Epoch 1715: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3863 - accuracy: 0.9230 - val_loss: 0.4638 - val_accuracy: 0.9099\n",
            "Epoch 1716/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3475 - accuracy: 0.9107\n",
            "Epoch 1716: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3447 - accuracy: 0.9112 - val_loss: 0.4528 - val_accuracy: 0.9199\n",
            "Epoch 1717/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3591 - accuracy: 0.9140\n",
            "Epoch 1717: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3589 - accuracy: 0.9140 - val_loss: 0.3957 - val_accuracy: 0.9242\n",
            "Epoch 1718/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.9159\n",
            "Epoch 1718: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3852 - accuracy: 0.9161 - val_loss: 0.4535 - val_accuracy: 0.9070\n",
            "Epoch 1719/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4426 - accuracy: 0.9132\n",
            "Epoch 1719: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4448 - accuracy: 0.9135 - val_loss: 0.4157 - val_accuracy: 0.9070\n",
            "Epoch 1720/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3003 - accuracy: 0.9212\n",
            "Epoch 1720: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3000 - accuracy: 0.9213 - val_loss: 0.4530 - val_accuracy: 0.9227\n",
            "Epoch 1721/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4536 - accuracy: 0.9207\n",
            "Epoch 1721: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4477 - accuracy: 0.9214 - val_loss: 0.4597 - val_accuracy: 0.9256\n",
            "Epoch 1722/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3137 - accuracy: 0.9282\n",
            "Epoch 1722: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3150 - accuracy: 0.9280 - val_loss: 0.4046 - val_accuracy: 0.9313\n",
            "Epoch 1723/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.9301\n",
            "Epoch 1723: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3382 - accuracy: 0.9301 - val_loss: 0.4068 - val_accuracy: 0.9313\n",
            "Epoch 1724/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2980 - accuracy: 0.9371\n",
            "Epoch 1724: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2979 - accuracy: 0.9369 - val_loss: 0.5382 - val_accuracy: 0.9270\n",
            "Epoch 1725/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4284 - accuracy: 0.9219\n",
            "Epoch 1725: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4271 - accuracy: 0.9221 - val_loss: 0.4632 - val_accuracy: 0.9242\n",
            "Epoch 1726/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3152 - accuracy: 0.9246\n",
            "Epoch 1726: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3151 - accuracy: 0.9244 - val_loss: 0.4552 - val_accuracy: 0.9256\n",
            "Epoch 1727/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2959 - accuracy: 0.9258\n",
            "Epoch 1727: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2947 - accuracy: 0.9261 - val_loss: 0.5165 - val_accuracy: 0.9213\n",
            "Epoch 1728/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3162 - accuracy: 0.9267\n",
            "Epoch 1728: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3155 - accuracy: 0.9267 - val_loss: 0.3971 - val_accuracy: 0.9213\n",
            "Epoch 1729/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3387 - accuracy: 0.9232\n",
            "Epoch 1729: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3368 - accuracy: 0.9236 - val_loss: 0.4366 - val_accuracy: 0.9285\n",
            "Epoch 1730/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.9237\n",
            "Epoch 1730: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3903 - accuracy: 0.9237 - val_loss: 0.4837 - val_accuracy: 0.9270\n",
            "Epoch 1731/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3004 - accuracy: 0.9314\n",
            "Epoch 1731: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3006 - accuracy: 0.9311 - val_loss: 0.4575 - val_accuracy: 0.9227\n",
            "Epoch 1732/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3122 - accuracy: 0.9350\n",
            "Epoch 1732: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3122 - accuracy: 0.9350 - val_loss: 0.4284 - val_accuracy: 0.9242\n",
            "Epoch 1733/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3323 - accuracy: 0.9342\n",
            "Epoch 1733: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3294 - accuracy: 0.9349 - val_loss: 0.3410 - val_accuracy: 0.9299\n",
            "Epoch 1734/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3498 - accuracy: 0.9243\n",
            "Epoch 1734: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3482 - accuracy: 0.9247 - val_loss: 0.3894 - val_accuracy: 0.9285\n",
            "Epoch 1735/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3996 - accuracy: 0.9292\n",
            "Epoch 1735: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3933 - accuracy: 0.9296 - val_loss: 0.4065 - val_accuracy: 0.9213\n",
            "Epoch 1736/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3234 - accuracy: 0.9331\n",
            "Epoch 1736: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3242 - accuracy: 0.9329 - val_loss: 0.3978 - val_accuracy: 0.9227\n",
            "Epoch 1737/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.2976 - accuracy: 0.9301\n",
            "Epoch 1737: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3003 - accuracy: 0.9301 - val_loss: 0.3983 - val_accuracy: 0.9299\n",
            "Epoch 1738/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3619 - accuracy: 0.9300\n",
            "Epoch 1738: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3619 - accuracy: 0.9300 - val_loss: 0.4310 - val_accuracy: 0.9213\n",
            "Epoch 1739/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3709 - accuracy: 0.9235\n",
            "Epoch 1739: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3711 - accuracy: 0.9234 - val_loss: 0.4139 - val_accuracy: 0.9099\n",
            "Epoch 1740/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.7086 - accuracy: 0.9150\n",
            "Epoch 1740: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6933 - accuracy: 0.9157 - val_loss: 0.4256 - val_accuracy: 0.9127\n",
            "Epoch 1741/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3746 - accuracy: 0.9204\n",
            "Epoch 1741: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3687 - accuracy: 0.9214 - val_loss: 0.4347 - val_accuracy: 0.9127\n",
            "Epoch 1742/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3938 - accuracy: 0.9142\n",
            "Epoch 1742: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3919 - accuracy: 0.9140 - val_loss: 0.4250 - val_accuracy: 0.9113\n",
            "Epoch 1743/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3257 - accuracy: 0.9188\n",
            "Epoch 1743: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3231 - accuracy: 0.9193 - val_loss: 0.3804 - val_accuracy: 0.9099\n",
            "Epoch 1744/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.9292\n",
            "Epoch 1744: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2797 - accuracy: 0.9286 - val_loss: 0.3622 - val_accuracy: 0.9185\n",
            "Epoch 1745/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3414 - accuracy: 0.9278\n",
            "Epoch 1745: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3414 - accuracy: 0.9278 - val_loss: 0.3702 - val_accuracy: 0.9041\n",
            "Epoch 1746/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4211 - accuracy: 0.9165\n",
            "Epoch 1746: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4221 - accuracy: 0.9164 - val_loss: 0.3761 - val_accuracy: 0.9242\n",
            "Epoch 1747/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3269 - accuracy: 0.9201\n",
            "Epoch 1747: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3329 - accuracy: 0.9191 - val_loss: 0.3536 - val_accuracy: 0.9227\n",
            "Epoch 1748/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3717 - accuracy: 0.9247\n",
            "Epoch 1748: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3679 - accuracy: 0.9250 - val_loss: 0.3728 - val_accuracy: 0.9227\n",
            "Epoch 1749/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3847 - accuracy: 0.9257\n",
            "Epoch 1749: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3770 - accuracy: 0.9266 - val_loss: 0.4189 - val_accuracy: 0.9142\n",
            "Epoch 1750/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3495 - accuracy: 0.9181\n",
            "Epoch 1750: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3495 - accuracy: 0.9181 - val_loss: 0.4272 - val_accuracy: 0.9213\n",
            "Epoch 1751/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4182 - accuracy: 0.9137\n",
            "Epoch 1751: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4182 - accuracy: 0.9137 - val_loss: 0.4048 - val_accuracy: 0.9070\n",
            "Epoch 1752/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3181 - accuracy: 0.9178\n",
            "Epoch 1752: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3176 - accuracy: 0.9178 - val_loss: 0.4193 - val_accuracy: 0.9227\n",
            "Epoch 1753/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3162 - accuracy: 0.9227\n",
            "Epoch 1753: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3162 - accuracy: 0.9227 - val_loss: 0.3758 - val_accuracy: 0.9270\n",
            "Epoch 1754/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3709 - accuracy: 0.9212\n",
            "Epoch 1754: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3707 - accuracy: 0.9207 - val_loss: 0.3883 - val_accuracy: 0.9170\n",
            "Epoch 1755/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3187 - accuracy: 0.9255\n",
            "Epoch 1755: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3153 - accuracy: 0.9260 - val_loss: 0.4037 - val_accuracy: 0.9270\n",
            "Epoch 1756/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3066 - accuracy: 0.9224\n",
            "Epoch 1756: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3163 - accuracy: 0.9224 - val_loss: 0.4560 - val_accuracy: 0.9227\n",
            "Epoch 1757/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3539 - accuracy: 0.9272\n",
            "Epoch 1757: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3528 - accuracy: 0.9274 - val_loss: 0.3892 - val_accuracy: 0.9256\n",
            "Epoch 1758/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3613 - accuracy: 0.9262\n",
            "Epoch 1758: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3618 - accuracy: 0.9261 - val_loss: 0.4022 - val_accuracy: 0.9070\n",
            "Epoch 1759/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.9217\n",
            "Epoch 1759: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3298 - accuracy: 0.9217 - val_loss: 0.4004 - val_accuracy: 0.9142\n",
            "Epoch 1760/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3966 - accuracy: 0.9281\n",
            "Epoch 1760: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3922 - accuracy: 0.9280 - val_loss: 0.4147 - val_accuracy: 0.9185\n",
            "Epoch 1761/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3458 - accuracy: 0.9298\n",
            "Epoch 1761: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3458 - accuracy: 0.9298 - val_loss: 0.3912 - val_accuracy: 0.9185\n",
            "Epoch 1762/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.9291\n",
            "Epoch 1762: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2659 - accuracy: 0.9291 - val_loss: 0.4376 - val_accuracy: 0.9170\n",
            "Epoch 1763/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.9306\n",
            "Epoch 1763: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3196 - accuracy: 0.9306 - val_loss: 0.4630 - val_accuracy: 0.9127\n",
            "Epoch 1764/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2826 - accuracy: 0.9344\n",
            "Epoch 1764: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2821 - accuracy: 0.9344 - val_loss: 0.4859 - val_accuracy: 0.9270\n",
            "Epoch 1765/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3984 - accuracy: 0.9214\n",
            "Epoch 1765: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3967 - accuracy: 0.9217 - val_loss: 0.4364 - val_accuracy: 0.9185\n",
            "Epoch 1766/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4086 - accuracy: 0.9154\n",
            "Epoch 1766: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4070 - accuracy: 0.9157 - val_loss: 0.4483 - val_accuracy: 0.9099\n",
            "Epoch 1767/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3058 - accuracy: 0.9255\n",
            "Epoch 1767: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3062 - accuracy: 0.9254 - val_loss: 0.5276 - val_accuracy: 0.9070\n",
            "Epoch 1768/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3136 - accuracy: 0.9276\n",
            "Epoch 1768: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3170 - accuracy: 0.9276 - val_loss: 0.4862 - val_accuracy: 0.9156\n",
            "Epoch 1769/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.9279\n",
            "Epoch 1769: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3023 - accuracy: 0.9277 - val_loss: 0.5584 - val_accuracy: 0.9142\n",
            "Epoch 1770/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4685 - accuracy: 0.9258\n",
            "Epoch 1770: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4633 - accuracy: 0.9258 - val_loss: 0.4438 - val_accuracy: 0.9113\n",
            "Epoch 1771/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3115 - accuracy: 0.9278\n",
            "Epoch 1771: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3081 - accuracy: 0.9278 - val_loss: 0.4216 - val_accuracy: 0.9270\n",
            "Epoch 1772/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3720 - accuracy: 0.9209\n",
            "Epoch 1772: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3677 - accuracy: 0.9211 - val_loss: 0.3835 - val_accuracy: 0.9213\n",
            "Epoch 1773/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.9212\n",
            "Epoch 1773: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4521 - accuracy: 0.9210 - val_loss: 0.4300 - val_accuracy: 0.9213\n",
            "Epoch 1774/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3286 - accuracy: 0.9281\n",
            "Epoch 1774: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3267 - accuracy: 0.9281 - val_loss: 0.4454 - val_accuracy: 0.9285\n",
            "Epoch 1775/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2760 - accuracy: 0.9290\n",
            "Epoch 1775: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.2760 - accuracy: 0.9286 - val_loss: 0.4688 - val_accuracy: 0.9227\n",
            "Epoch 1776/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3427 - accuracy: 0.9264\n",
            "Epoch 1776: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3419 - accuracy: 0.9264 - val_loss: 0.3383 - val_accuracy: 0.9170\n",
            "Epoch 1777/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.9308\n",
            "Epoch 1777: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3000 - accuracy: 0.9307 - val_loss: 0.3592 - val_accuracy: 0.9170\n",
            "Epoch 1778/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3697 - accuracy: 0.9273\n",
            "Epoch 1778: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3683 - accuracy: 0.9276 - val_loss: 0.3631 - val_accuracy: 0.9099\n",
            "Epoch 1779/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3299 - accuracy: 0.9236\n",
            "Epoch 1779: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3299 - accuracy: 0.9236 - val_loss: 0.3702 - val_accuracy: 0.9199\n",
            "Epoch 1780/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3576 - accuracy: 0.9250\n",
            "Epoch 1780: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3561 - accuracy: 0.9253 - val_loss: 0.3986 - val_accuracy: 0.9170\n",
            "Epoch 1781/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3726 - accuracy: 0.9216\n",
            "Epoch 1781: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3704 - accuracy: 0.9210 - val_loss: 0.3782 - val_accuracy: 0.8970\n",
            "Epoch 1782/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3359 - accuracy: 0.9187\n",
            "Epoch 1782: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3359 - accuracy: 0.9187 - val_loss: 0.4154 - val_accuracy: 0.9170\n",
            "Epoch 1783/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3214 - accuracy: 0.9250\n",
            "Epoch 1783: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3236 - accuracy: 0.9243 - val_loss: 0.4237 - val_accuracy: 0.9113\n",
            "Epoch 1784/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3399 - accuracy: 0.9294\n",
            "Epoch 1784: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3387 - accuracy: 0.9288 - val_loss: 0.3764 - val_accuracy: 0.9113\n",
            "Epoch 1785/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4113 - accuracy: 0.9071\n",
            "Epoch 1785: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4048 - accuracy: 0.9075 - val_loss: 0.3516 - val_accuracy: 0.9041\n",
            "Epoch 1786/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3635 - accuracy: 0.9153\n",
            "Epoch 1786: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3599 - accuracy: 0.9154 - val_loss: 0.3676 - val_accuracy: 0.9070\n",
            "Epoch 1787/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4399 - accuracy: 0.9120\n",
            "Epoch 1787: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4400 - accuracy: 0.9114 - val_loss: 0.4214 - val_accuracy: 0.8999\n",
            "Epoch 1788/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3500 - accuracy: 0.9112\n",
            "Epoch 1788: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3488 - accuracy: 0.9112 - val_loss: 0.4886 - val_accuracy: 0.9185\n",
            "Epoch 1789/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3150 - accuracy: 0.9213\n",
            "Epoch 1789: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3141 - accuracy: 0.9220 - val_loss: 0.4811 - val_accuracy: 0.9156\n",
            "Epoch 1790/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2964 - accuracy: 0.9276\n",
            "Epoch 1790: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2963 - accuracy: 0.9276 - val_loss: 0.4762 - val_accuracy: 0.9142\n",
            "Epoch 1791/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.9217\n",
            "Epoch 1791: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3762 - accuracy: 0.9217 - val_loss: 0.4166 - val_accuracy: 0.9170\n",
            "Epoch 1792/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3261 - accuracy: 0.9222\n",
            "Epoch 1792: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3267 - accuracy: 0.9218 - val_loss: 0.4403 - val_accuracy: 0.9113\n",
            "Epoch 1793/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3601 - accuracy: 0.9271\n",
            "Epoch 1793: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3601 - accuracy: 0.9271 - val_loss: 0.4604 - val_accuracy: 0.9156\n",
            "Epoch 1794/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3713 - accuracy: 0.9237\n",
            "Epoch 1794: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3750 - accuracy: 0.9240 - val_loss: 0.3973 - val_accuracy: 0.9185\n",
            "Epoch 1795/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.9168\n",
            "Epoch 1795: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3364 - accuracy: 0.9168 - val_loss: 0.5158 - val_accuracy: 0.9142\n",
            "Epoch 1796/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.9243\n",
            "Epoch 1796: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3835 - accuracy: 0.9244 - val_loss: 0.4179 - val_accuracy: 0.9199\n",
            "Epoch 1797/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3222 - accuracy: 0.9287\n",
            "Epoch 1797: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3226 - accuracy: 0.9281 - val_loss: 0.3953 - val_accuracy: 0.9199\n",
            "Epoch 1798/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3979 - accuracy: 0.9243\n",
            "Epoch 1798: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4004 - accuracy: 0.9237 - val_loss: 0.4047 - val_accuracy: 0.9113\n",
            "Epoch 1799/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3372 - accuracy: 0.9204\n",
            "Epoch 1799: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3372 - accuracy: 0.9201 - val_loss: 0.3617 - val_accuracy: 0.9213\n",
            "Epoch 1800/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3073 - accuracy: 0.9253\n",
            "Epoch 1800: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3023 - accuracy: 0.9258 - val_loss: 0.3913 - val_accuracy: 0.9127\n",
            "Epoch 1801/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3358 - accuracy: 0.9281\n",
            "Epoch 1801: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3358 - accuracy: 0.9281 - val_loss: 0.4363 - val_accuracy: 0.9227\n",
            "Epoch 1802/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2930 - accuracy: 0.9291\n",
            "Epoch 1802: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2930 - accuracy: 0.9291 - val_loss: 0.3805 - val_accuracy: 0.9285\n",
            "Epoch 1803/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2774 - accuracy: 0.9370\n",
            "Epoch 1803: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2968 - accuracy: 0.9369 - val_loss: 0.4346 - val_accuracy: 0.9185\n",
            "Epoch 1804/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2670 - accuracy: 0.9360\n",
            "Epoch 1804: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2664 - accuracy: 0.9360 - val_loss: 0.4136 - val_accuracy: 0.9227\n",
            "Epoch 1805/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3427 - accuracy: 0.9286\n",
            "Epoch 1805: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3441 - accuracy: 0.9286 - val_loss: 0.4069 - val_accuracy: 0.9242\n",
            "Epoch 1806/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4611 - accuracy: 0.9298\n",
            "Epoch 1806: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4605 - accuracy: 0.9296 - val_loss: 0.3932 - val_accuracy: 0.9227\n",
            "Epoch 1807/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5702 - accuracy: 0.9154\n",
            "Epoch 1807: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5702 - accuracy: 0.9154 - val_loss: 0.3815 - val_accuracy: 0.9227\n",
            "Epoch 1808/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3409 - accuracy: 0.9151\n",
            "Epoch 1808: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3404 - accuracy: 0.9151 - val_loss: 0.3763 - val_accuracy: 0.9199\n",
            "Epoch 1809/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3493 - accuracy: 0.9219\n",
            "Epoch 1809: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3514 - accuracy: 0.9214 - val_loss: 0.3990 - val_accuracy: 0.9199\n",
            "Epoch 1810/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3630 - accuracy: 0.9181\n",
            "Epoch 1810: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3630 - accuracy: 0.9178 - val_loss: 0.3893 - val_accuracy: 0.9170\n",
            "Epoch 1811/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.9236\n",
            "Epoch 1811: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3505 - accuracy: 0.9236 - val_loss: 0.3688 - val_accuracy: 0.9242\n",
            "Epoch 1812/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.9311\n",
            "Epoch 1812: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2929 - accuracy: 0.9311 - val_loss: 0.4368 - val_accuracy: 0.9256\n",
            "Epoch 1813/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.9296\n",
            "Epoch 1813: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3447 - accuracy: 0.9296 - val_loss: 0.4618 - val_accuracy: 0.9127\n",
            "Epoch 1814/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3162 - accuracy: 0.9246\n",
            "Epoch 1814: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3162 - accuracy: 0.9246 - val_loss: 0.4009 - val_accuracy: 0.9213\n",
            "Epoch 1815/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3089 - accuracy: 0.9295\n",
            "Epoch 1815: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3083 - accuracy: 0.9288 - val_loss: 0.4031 - val_accuracy: 0.9213\n",
            "Epoch 1816/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3945 - accuracy: 0.9258\n",
            "Epoch 1816: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3932 - accuracy: 0.9260 - val_loss: 0.3940 - val_accuracy: 0.9185\n",
            "Epoch 1817/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3133 - accuracy: 0.9233\n",
            "Epoch 1817: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3140 - accuracy: 0.9228 - val_loss: 0.4086 - val_accuracy: 0.9142\n",
            "Epoch 1818/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3470 - accuracy: 0.9302\n",
            "Epoch 1818: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3509 - accuracy: 0.9300 - val_loss: 0.4163 - val_accuracy: 0.9213\n",
            "Epoch 1819/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4066 - accuracy: 0.9073\n",
            "Epoch 1819: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4061 - accuracy: 0.9079 - val_loss: 0.4143 - val_accuracy: 0.9084\n",
            "Epoch 1820/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4451 - accuracy: 0.9093\n",
            "Epoch 1820: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4418 - accuracy: 0.9089 - val_loss: 0.4393 - val_accuracy: 0.9199\n",
            "Epoch 1821/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3324 - accuracy: 0.9212\n",
            "Epoch 1821: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3266 - accuracy: 0.9224 - val_loss: 0.3847 - val_accuracy: 0.9170\n",
            "Epoch 1822/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4353 - accuracy: 0.9158\n",
            "Epoch 1822: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4353 - accuracy: 0.9158 - val_loss: 0.3576 - val_accuracy: 0.9185\n",
            "Epoch 1823/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3502 - accuracy: 0.9191\n",
            "Epoch 1823: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3472 - accuracy: 0.9191 - val_loss: 0.4386 - val_accuracy: 0.9170\n",
            "Epoch 1824/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3400 - accuracy: 0.9196\n",
            "Epoch 1824: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3386 - accuracy: 0.9195 - val_loss: 0.4327 - val_accuracy: 0.9156\n",
            "Epoch 1825/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3157 - accuracy: 0.9306\n",
            "Epoch 1825: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3157 - accuracy: 0.9306 - val_loss: 0.4375 - val_accuracy: 0.9213\n",
            "Epoch 1826/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4346 - accuracy: 0.9212\n",
            "Epoch 1826: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4342 - accuracy: 0.9211 - val_loss: 0.4464 - val_accuracy: 0.9227\n",
            "Epoch 1827/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4905 - accuracy: 0.9181\n",
            "Epoch 1827: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4874 - accuracy: 0.9190 - val_loss: 0.4263 - val_accuracy: 0.9185\n",
            "Epoch 1828/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4007 - accuracy: 0.9119\n",
            "Epoch 1828: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3915 - accuracy: 0.9135 - val_loss: 0.4508 - val_accuracy: 0.9227\n",
            "Epoch 1829/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3139 - accuracy: 0.9233\n",
            "Epoch 1829: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3116 - accuracy: 0.9230 - val_loss: 0.4286 - val_accuracy: 0.9142\n",
            "Epoch 1830/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4226 - accuracy: 0.9152\n",
            "Epoch 1830: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4238 - accuracy: 0.9142 - val_loss: 0.4215 - val_accuracy: 0.9213\n",
            "Epoch 1831/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4145 - accuracy: 0.9143\n",
            "Epoch 1831: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4144 - accuracy: 0.9141 - val_loss: 0.3740 - val_accuracy: 0.9213\n",
            "Epoch 1832/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3257 - accuracy: 0.9243\n",
            "Epoch 1832: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3252 - accuracy: 0.9241 - val_loss: 0.3840 - val_accuracy: 0.9170\n",
            "Epoch 1833/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3412 - accuracy: 0.9199\n",
            "Epoch 1833: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3413 - accuracy: 0.9197 - val_loss: 0.3947 - val_accuracy: 0.9170\n",
            "Epoch 1834/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.9283\n",
            "Epoch 1834: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2674 - accuracy: 0.9283 - val_loss: 0.4558 - val_accuracy: 0.9213\n",
            "Epoch 1835/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.9261\n",
            "Epoch 1835: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3326 - accuracy: 0.9261 - val_loss: 0.3819 - val_accuracy: 0.9113\n",
            "Epoch 1836/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.2807 - accuracy: 0.9279\n",
            "Epoch 1836: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2829 - accuracy: 0.9277 - val_loss: 0.4098 - val_accuracy: 0.9170\n",
            "Epoch 1837/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3083 - accuracy: 0.9243\n",
            "Epoch 1837: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3068 - accuracy: 0.9244 - val_loss: 0.3924 - val_accuracy: 0.9213\n",
            "Epoch 1838/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3766 - accuracy: 0.9252\n",
            "Epoch 1838: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3766 - accuracy: 0.9250 - val_loss: 0.3937 - val_accuracy: 0.9056\n",
            "Epoch 1839/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3327 - accuracy: 0.9190\n",
            "Epoch 1839: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3284 - accuracy: 0.9198 - val_loss: 0.3782 - val_accuracy: 0.9199\n",
            "Epoch 1840/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.2814 - accuracy: 0.9303\n",
            "Epoch 1840: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2892 - accuracy: 0.9304 - val_loss: 0.5009 - val_accuracy: 0.9142\n",
            "Epoch 1841/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3307 - accuracy: 0.9236\n",
            "Epoch 1841: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3298 - accuracy: 0.9230 - val_loss: 0.4227 - val_accuracy: 0.9199\n",
            "Epoch 1842/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4230 - accuracy: 0.9127\n",
            "Epoch 1842: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4205 - accuracy: 0.9138 - val_loss: 0.4175 - val_accuracy: 0.9156\n",
            "Epoch 1843/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2997 - accuracy: 0.9246\n",
            "Epoch 1843: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2986 - accuracy: 0.9248 - val_loss: 0.4219 - val_accuracy: 0.9170\n",
            "Epoch 1844/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3478 - accuracy: 0.9326\n",
            "Epoch 1844: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3462 - accuracy: 0.9321 - val_loss: 0.4258 - val_accuracy: 0.9142\n",
            "Epoch 1845/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3325 - accuracy: 0.9257\n",
            "Epoch 1845: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3382 - accuracy: 0.9253 - val_loss: 0.4518 - val_accuracy: 0.9156\n",
            "Epoch 1846/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3705 - accuracy: 0.9068\n",
            "Epoch 1846: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3705 - accuracy: 0.9068 - val_loss: 0.4161 - val_accuracy: 0.9185\n",
            "Epoch 1847/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4375 - accuracy: 0.9209\n",
            "Epoch 1847: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4349 - accuracy: 0.9203 - val_loss: 0.4404 - val_accuracy: 0.9213\n",
            "Epoch 1848/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3021 - accuracy: 0.9270\n",
            "Epoch 1848: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3017 - accuracy: 0.9268 - val_loss: 0.3773 - val_accuracy: 0.9227\n",
            "Epoch 1849/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2975 - accuracy: 0.9353\n",
            "Epoch 1849: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2997 - accuracy: 0.9357 - val_loss: 0.4511 - val_accuracy: 0.9185\n",
            "Epoch 1850/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3715 - accuracy: 0.9301\n",
            "Epoch 1850: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3669 - accuracy: 0.9311 - val_loss: 0.3740 - val_accuracy: 0.9270\n",
            "Epoch 1851/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3931 - accuracy: 0.9163\n",
            "Epoch 1851: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3961 - accuracy: 0.9155 - val_loss: 0.4601 - val_accuracy: 0.9113\n",
            "Epoch 1852/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3429 - accuracy: 0.9225\n",
            "Epoch 1852: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3474 - accuracy: 0.9224 - val_loss: 0.4083 - val_accuracy: 0.9242\n",
            "Epoch 1853/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4147 - accuracy: 0.9264\n",
            "Epoch 1853: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4131 - accuracy: 0.9258 - val_loss: 0.4007 - val_accuracy: 0.9185\n",
            "Epoch 1854/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4725 - accuracy: 0.9119\n",
            "Epoch 1854: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4723 - accuracy: 0.9122 - val_loss: 0.5004 - val_accuracy: 0.9070\n",
            "Epoch 1855/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3422 - accuracy: 0.9113\n",
            "Epoch 1855: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3444 - accuracy: 0.9115 - val_loss: 0.4847 - val_accuracy: 0.9084\n",
            "Epoch 1856/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4069 - accuracy: 0.9073\n",
            "Epoch 1856: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4037 - accuracy: 0.9079 - val_loss: 0.5126 - val_accuracy: 0.9142\n",
            "Epoch 1857/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4006 - accuracy: 0.9163\n",
            "Epoch 1857: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3992 - accuracy: 0.9165 - val_loss: 0.4633 - val_accuracy: 0.9142\n",
            "Epoch 1858/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.9210\n",
            "Epoch 1858: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3964 - accuracy: 0.9210 - val_loss: 0.4948 - val_accuracy: 0.9113\n",
            "Epoch 1859/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3217 - accuracy: 0.9231\n",
            "Epoch 1859: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3335 - accuracy: 0.9228 - val_loss: 0.4554 - val_accuracy: 0.9213\n",
            "Epoch 1860/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3932 - accuracy: 0.9233\n",
            "Epoch 1860: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3927 - accuracy: 0.9228 - val_loss: 0.4202 - val_accuracy: 0.9084\n",
            "Epoch 1861/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.2976 - accuracy: 0.9227\n",
            "Epoch 1861: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2949 - accuracy: 0.9231 - val_loss: 0.4450 - val_accuracy: 0.9142\n",
            "Epoch 1862/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3274 - accuracy: 0.9257\n",
            "Epoch 1862: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3249 - accuracy: 0.9266 - val_loss: 0.4389 - val_accuracy: 0.9213\n",
            "Epoch 1863/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3455 - accuracy: 0.9225\n",
            "Epoch 1863: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3480 - accuracy: 0.9225 - val_loss: 0.4099 - val_accuracy: 0.9256\n",
            "Epoch 1864/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3673 - accuracy: 0.9246\n",
            "Epoch 1864: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3667 - accuracy: 0.9244 - val_loss: 0.4549 - val_accuracy: 0.9185\n",
            "Epoch 1865/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3926 - accuracy: 0.9260\n",
            "Epoch 1865: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3897 - accuracy: 0.9258 - val_loss: 0.4518 - val_accuracy: 0.9142\n",
            "Epoch 1866/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3153 - accuracy: 0.9281\n",
            "Epoch 1866: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3162 - accuracy: 0.9278 - val_loss: 0.4002 - val_accuracy: 0.9199\n",
            "Epoch 1867/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3669 - accuracy: 0.9304\n",
            "Epoch 1867: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3679 - accuracy: 0.9303 - val_loss: 0.3858 - val_accuracy: 0.9270\n",
            "Epoch 1868/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4167 - accuracy: 0.9133\n",
            "Epoch 1868: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4153 - accuracy: 0.9137 - val_loss: 0.4527 - val_accuracy: 0.9099\n",
            "Epoch 1869/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.9287\n",
            "Epoch 1869: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2882 - accuracy: 0.9288 - val_loss: 0.4088 - val_accuracy: 0.9170\n",
            "Epoch 1870/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2787 - accuracy: 0.9322\n",
            "Epoch 1870: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2764 - accuracy: 0.9327 - val_loss: 0.4266 - val_accuracy: 0.9270\n",
            "Epoch 1871/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3336 - accuracy: 0.9271\n",
            "Epoch 1871: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3336 - accuracy: 0.9271 - val_loss: 0.4001 - val_accuracy: 0.9328\n",
            "Epoch 1872/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3575 - accuracy: 0.9356\n",
            "Epoch 1872: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3506 - accuracy: 0.9361 - val_loss: 0.4351 - val_accuracy: 0.9199\n",
            "Epoch 1873/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.9278\n",
            "Epoch 1873: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3759 - accuracy: 0.9281 - val_loss: 0.3756 - val_accuracy: 0.9213\n",
            "Epoch 1874/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3784 - accuracy: 0.9209\n",
            "Epoch 1874: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3763 - accuracy: 0.9211 - val_loss: 0.3587 - val_accuracy: 0.9185\n",
            "Epoch 1875/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5557 - accuracy: 0.9204\n",
            "Epoch 1875: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5561 - accuracy: 0.9203 - val_loss: 0.3803 - val_accuracy: 0.9156\n",
            "Epoch 1876/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4715 - accuracy: 0.9127\n",
            "Epoch 1876: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4704 - accuracy: 0.9128 - val_loss: 0.3647 - val_accuracy: 0.9156\n",
            "Epoch 1877/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4247 - accuracy: 0.9175\n",
            "Epoch 1877: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4228 - accuracy: 0.9174 - val_loss: 0.3550 - val_accuracy: 0.9213\n",
            "Epoch 1878/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3645 - accuracy: 0.9180\n",
            "Epoch 1878: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3616 - accuracy: 0.9184 - val_loss: 0.3708 - val_accuracy: 0.9156\n",
            "Epoch 1879/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.9228\n",
            "Epoch 1879: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3328 - accuracy: 0.9228 - val_loss: 0.3511 - val_accuracy: 0.9185\n",
            "Epoch 1880/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2947 - accuracy: 0.9304\n",
            "Epoch 1880: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2964 - accuracy: 0.9301 - val_loss: 0.3776 - val_accuracy: 0.9227\n",
            "Epoch 1881/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3559 - accuracy: 0.9287\n",
            "Epoch 1881: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3508 - accuracy: 0.9293 - val_loss: 0.3897 - val_accuracy: 0.9185\n",
            "Epoch 1882/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3440 - accuracy: 0.9232\n",
            "Epoch 1882: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3489 - accuracy: 0.9231 - val_loss: 0.3738 - val_accuracy: 0.9227\n",
            "Epoch 1883/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3686 - accuracy: 0.9183\n",
            "Epoch 1883: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3681 - accuracy: 0.9185 - val_loss: 0.4957 - val_accuracy: 0.9227\n",
            "Epoch 1884/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3110 - accuracy: 0.9291\n",
            "Epoch 1884: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3110 - accuracy: 0.9291 - val_loss: 0.4503 - val_accuracy: 0.9227\n",
            "Epoch 1885/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3206 - accuracy: 0.9270\n",
            "Epoch 1885: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3193 - accuracy: 0.9270 - val_loss: 0.3892 - val_accuracy: 0.9127\n",
            "Epoch 1886/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3330 - accuracy: 0.9223\n",
            "Epoch 1886: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3330 - accuracy: 0.9223 - val_loss: 0.4378 - val_accuracy: 0.9170\n",
            "Epoch 1887/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4018 - accuracy: 0.9233\n",
            "Epoch 1887: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4011 - accuracy: 0.9233 - val_loss: 0.4460 - val_accuracy: 0.9170\n",
            "Epoch 1888/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3082 - accuracy: 0.9303\n",
            "Epoch 1888: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3092 - accuracy: 0.9296 - val_loss: 0.5322 - val_accuracy: 0.9156\n",
            "Epoch 1889/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.2822 - accuracy: 0.9311\n",
            "Epoch 1889: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2821 - accuracy: 0.9307 - val_loss: 0.4391 - val_accuracy: 0.9142\n",
            "Epoch 1890/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4837 - accuracy: 0.9247\n",
            "Epoch 1890: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4806 - accuracy: 0.9241 - val_loss: 0.4399 - val_accuracy: 0.9070\n",
            "Epoch 1891/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3624 - accuracy: 0.9128\n",
            "Epoch 1891: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3629 - accuracy: 0.9131 - val_loss: 0.4576 - val_accuracy: 0.9070\n",
            "Epoch 1892/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.9124\n",
            "Epoch 1892: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3893 - accuracy: 0.9120 - val_loss: 0.4410 - val_accuracy: 0.9113\n",
            "Epoch 1893/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4299 - accuracy: 0.9089\n",
            "Epoch 1893: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4289 - accuracy: 0.9082 - val_loss: 0.4654 - val_accuracy: 0.9070\n",
            "Epoch 1894/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4912 - accuracy: 0.9107\n",
            "Epoch 1894: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4876 - accuracy: 0.9114 - val_loss: 0.4739 - val_accuracy: 0.9170\n",
            "Epoch 1895/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4162 - accuracy: 0.9111\n",
            "Epoch 1895: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4162 - accuracy: 0.9111 - val_loss: 0.4860 - val_accuracy: 0.9185\n",
            "Epoch 1896/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4364 - accuracy: 0.9081\n",
            "Epoch 1896: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4347 - accuracy: 0.9082 - val_loss: 0.4449 - val_accuracy: 0.9156\n",
            "Epoch 1897/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3786 - accuracy: 0.9176\n",
            "Epoch 1897: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3789 - accuracy: 0.9171 - val_loss: 0.4743 - val_accuracy: 0.9027\n",
            "Epoch 1898/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3217 - accuracy: 0.9221\n",
            "Epoch 1898: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3191 - accuracy: 0.9220 - val_loss: 0.4301 - val_accuracy: 0.9084\n",
            "Epoch 1899/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3264 - accuracy: 0.9256\n",
            "Epoch 1899: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3270 - accuracy: 0.9247 - val_loss: 0.4396 - val_accuracy: 0.9041\n",
            "Epoch 1900/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5076 - accuracy: 0.9204\n",
            "Epoch 1900: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4988 - accuracy: 0.9210 - val_loss: 0.4151 - val_accuracy: 0.9113\n",
            "Epoch 1901/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4931 - accuracy: 0.9136\n",
            "Epoch 1901: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4913 - accuracy: 0.9130 - val_loss: 0.3830 - val_accuracy: 0.9084\n",
            "Epoch 1902/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4826 - accuracy: 0.9068\n",
            "Epoch 1902: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4818 - accuracy: 0.9065 - val_loss: 0.4328 - val_accuracy: 0.9013\n",
            "Epoch 1903/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4174 - accuracy: 0.9035\n",
            "Epoch 1903: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4148 - accuracy: 0.9041 - val_loss: 0.4280 - val_accuracy: 0.9156\n",
            "Epoch 1904/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3517 - accuracy: 0.9185\n",
            "Epoch 1904: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3554 - accuracy: 0.9185 - val_loss: 0.4109 - val_accuracy: 0.9185\n",
            "Epoch 1905/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.9168\n",
            "Epoch 1905: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3513 - accuracy: 0.9168 - val_loss: 0.4357 - val_accuracy: 0.9127\n",
            "Epoch 1906/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3702 - accuracy: 0.9163\n",
            "Epoch 1906: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3690 - accuracy: 0.9164 - val_loss: 0.4126 - val_accuracy: 0.9156\n",
            "Epoch 1907/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3544 - accuracy: 0.9286\n",
            "Epoch 1907: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3635 - accuracy: 0.9287 - val_loss: 0.4222 - val_accuracy: 0.9156\n",
            "Epoch 1908/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3203 - accuracy: 0.9276\n",
            "Epoch 1908: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3203 - accuracy: 0.9276 - val_loss: 0.4159 - val_accuracy: 0.9099\n",
            "Epoch 1909/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2752 - accuracy: 0.9310\n",
            "Epoch 1909: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2752 - accuracy: 0.9310 - val_loss: 0.4491 - val_accuracy: 0.9170\n",
            "Epoch 1910/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3481 - accuracy: 0.9312\n",
            "Epoch 1910: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3456 - accuracy: 0.9311 - val_loss: 0.3856 - val_accuracy: 0.9227\n",
            "Epoch 1911/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4053 - accuracy: 0.9219\n",
            "Epoch 1911: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4053 - accuracy: 0.9210 - val_loss: 0.4273 - val_accuracy: 0.9084\n",
            "Epoch 1912/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3340 - accuracy: 0.9233\n",
            "Epoch 1912: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3340 - accuracy: 0.9233 - val_loss: 0.3689 - val_accuracy: 0.9199\n",
            "Epoch 1913/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4121 - accuracy: 0.9149\n",
            "Epoch 1913: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4109 - accuracy: 0.9151 - val_loss: 0.4918 - val_accuracy: 0.9084\n",
            "Epoch 1914/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5032 - accuracy: 0.9037\n",
            "Epoch 1914: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5014 - accuracy: 0.9041 - val_loss: 0.4868 - val_accuracy: 0.9041\n",
            "Epoch 1915/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.9044\n",
            "Epoch 1915: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4221 - accuracy: 0.9044 - val_loss: 0.4138 - val_accuracy: 0.9027\n",
            "Epoch 1916/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.6172 - accuracy: 0.9016\n",
            "Epoch 1916: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6172 - accuracy: 0.9016 - val_loss: 0.4952 - val_accuracy: 0.8999\n",
            "Epoch 1917/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5299 - accuracy: 0.8918\n",
            "Epoch 1917: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.5299 - accuracy: 0.8918 - val_loss: 0.4324 - val_accuracy: 0.8999\n",
            "Epoch 1918/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.9125\n",
            "Epoch 1918: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4402 - accuracy: 0.9125 - val_loss: 0.4438 - val_accuracy: 0.9070\n",
            "Epoch 1919/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4530 - accuracy: 0.9088\n",
            "Epoch 1919: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4511 - accuracy: 0.9092 - val_loss: 0.4542 - val_accuracy: 0.8927\n",
            "Epoch 1920/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4391 - accuracy: 0.8999\n",
            "Epoch 1920: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4695 - accuracy: 0.9001 - val_loss: 0.4377 - val_accuracy: 0.9084\n",
            "Epoch 1921/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4301 - accuracy: 0.9126\n",
            "Epoch 1921: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4258 - accuracy: 0.9125 - val_loss: 0.3894 - val_accuracy: 0.9227\n",
            "Epoch 1922/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3712 - accuracy: 0.9169\n",
            "Epoch 1922: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3654 - accuracy: 0.9181 - val_loss: 0.4303 - val_accuracy: 0.9185\n",
            "Epoch 1923/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3531 - accuracy: 0.9213\n",
            "Epoch 1923: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3531 - accuracy: 0.9213 - val_loss: 0.4031 - val_accuracy: 0.9127\n",
            "Epoch 1924/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4682 - accuracy: 0.9072\n",
            "Epoch 1924: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4673 - accuracy: 0.9072 - val_loss: 0.3902 - val_accuracy: 0.9127\n",
            "Epoch 1925/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3604 - accuracy: 0.9146\n",
            "Epoch 1925: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3615 - accuracy: 0.9140 - val_loss: 0.3686 - val_accuracy: 0.9156\n",
            "Epoch 1926/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4615 - accuracy: 0.9156\n",
            "Epoch 1926: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4589 - accuracy: 0.9155 - val_loss: 0.4443 - val_accuracy: 0.9070\n",
            "Epoch 1927/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3595 - accuracy: 0.9130\n",
            "Epoch 1927: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3553 - accuracy: 0.9132 - val_loss: 0.3801 - val_accuracy: 0.9156\n",
            "Epoch 1928/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3923 - accuracy: 0.9139\n",
            "Epoch 1928: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3880 - accuracy: 0.9141 - val_loss: 0.4179 - val_accuracy: 0.9099\n",
            "Epoch 1929/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.9180\n",
            "Epoch 1929: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3673 - accuracy: 0.9180 - val_loss: 0.3508 - val_accuracy: 0.9185\n",
            "Epoch 1930/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5899 - accuracy: 0.9132\n",
            "Epoch 1930: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.6052 - accuracy: 0.9130 - val_loss: 0.3980 - val_accuracy: 0.9142\n",
            "Epoch 1931/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3987 - accuracy: 0.9110\n",
            "Epoch 1931: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3993 - accuracy: 0.9101 - val_loss: 0.3723 - val_accuracy: 0.9099\n",
            "Epoch 1932/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4008 - accuracy: 0.9191\n",
            "Epoch 1932: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4008 - accuracy: 0.9191 - val_loss: 0.3950 - val_accuracy: 0.9127\n",
            "Epoch 1933/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3998 - accuracy: 0.9187\n",
            "Epoch 1933: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3949 - accuracy: 0.9187 - val_loss: 0.3547 - val_accuracy: 0.9185\n",
            "Epoch 1934/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4558 - accuracy: 0.9115\n",
            "Epoch 1934: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4451 - accuracy: 0.9132 - val_loss: 0.3831 - val_accuracy: 0.9227\n",
            "Epoch 1935/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.9135\n",
            "Epoch 1935: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3891 - accuracy: 0.9135 - val_loss: 0.3740 - val_accuracy: 0.9185\n",
            "Epoch 1936/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.9191\n",
            "Epoch 1936: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3753 - accuracy: 0.9191 - val_loss: 0.3575 - val_accuracy: 0.9270\n",
            "Epoch 1937/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4040 - accuracy: 0.9140\n",
            "Epoch 1937: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4052 - accuracy: 0.9142 - val_loss: 0.4397 - val_accuracy: 0.9127\n",
            "Epoch 1938/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3175 - accuracy: 0.9175\n",
            "Epoch 1938: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3156 - accuracy: 0.9180 - val_loss: 0.3989 - val_accuracy: 0.9170\n",
            "Epoch 1939/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3049 - accuracy: 0.9304\n",
            "Epoch 1939: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3058 - accuracy: 0.9301 - val_loss: 0.4072 - val_accuracy: 0.9242\n",
            "Epoch 1940/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2845 - accuracy: 0.9342\n",
            "Epoch 1940: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2792 - accuracy: 0.9349 - val_loss: 0.4933 - val_accuracy: 0.9199\n",
            "Epoch 1941/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3500 - accuracy: 0.9301\n",
            "Epoch 1941: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3500 - accuracy: 0.9294 - val_loss: 0.4014 - val_accuracy: 0.9242\n",
            "Epoch 1942/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3080 - accuracy: 0.9295\n",
            "Epoch 1942: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3177 - accuracy: 0.9290 - val_loss: 0.3932 - val_accuracy: 0.9256\n",
            "Epoch 1943/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4053 - accuracy: 0.9167\n",
            "Epoch 1943: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4011 - accuracy: 0.9162 - val_loss: 0.3813 - val_accuracy: 0.9170\n",
            "Epoch 1944/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.9104\n",
            "Epoch 1944: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4690 - accuracy: 0.9104 - val_loss: 0.4343 - val_accuracy: 0.9070\n",
            "Epoch 1945/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4037 - accuracy: 0.9104\n",
            "Epoch 1945: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4007 - accuracy: 0.9108 - val_loss: 0.4198 - val_accuracy: 0.9199\n",
            "Epoch 1946/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3672 - accuracy: 0.9150\n",
            "Epoch 1946: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3659 - accuracy: 0.9152 - val_loss: 0.4205 - val_accuracy: 0.9185\n",
            "Epoch 1947/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.9241\n",
            "Epoch 1947: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3762 - accuracy: 0.9241 - val_loss: 0.3970 - val_accuracy: 0.9170\n",
            "Epoch 1948/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3215 - accuracy: 0.9264\n",
            "Epoch 1948: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3186 - accuracy: 0.9266 - val_loss: 0.3826 - val_accuracy: 0.9185\n",
            "Epoch 1949/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4035 - accuracy: 0.9153\n",
            "Epoch 1949: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4000 - accuracy: 0.9148 - val_loss: 0.4197 - val_accuracy: 0.9170\n",
            "Epoch 1950/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.9190\n",
            "Epoch 1950: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3594 - accuracy: 0.9190 - val_loss: 0.4296 - val_accuracy: 0.9127\n",
            "Epoch 1951/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4018 - accuracy: 0.9155\n",
            "Epoch 1951: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4018 - accuracy: 0.9155 - val_loss: 0.4093 - val_accuracy: 0.9170\n",
            "Epoch 1952/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3512 - accuracy: 0.9243\n",
            "Epoch 1952: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3496 - accuracy: 0.9244 - val_loss: 0.4338 - val_accuracy: 0.9199\n",
            "Epoch 1953/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4397 - accuracy: 0.9201\n",
            "Epoch 1953: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4373 - accuracy: 0.9201 - val_loss: 0.4591 - val_accuracy: 0.9227\n",
            "Epoch 1954/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8987\n",
            "Epoch 1954: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4480 - accuracy: 0.8991 - val_loss: 0.4443 - val_accuracy: 0.9113\n",
            "Epoch 1955/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4544 - accuracy: 0.9102\n",
            "Epoch 1955: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4540 - accuracy: 0.9105 - val_loss: 0.4374 - val_accuracy: 0.9185\n",
            "Epoch 1956/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4571 - accuracy: 0.9040\n",
            "Epoch 1956: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4558 - accuracy: 0.9041 - val_loss: 0.3980 - val_accuracy: 0.9142\n",
            "Epoch 1957/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3905 - accuracy: 0.9102\n",
            "Epoch 1957: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4073 - accuracy: 0.9095 - val_loss: 0.3788 - val_accuracy: 0.9170\n",
            "Epoch 1958/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.9158\n",
            "Epoch 1958: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3782 - accuracy: 0.9158 - val_loss: 0.3949 - val_accuracy: 0.9127\n",
            "Epoch 1959/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3536 - accuracy: 0.9244\n",
            "Epoch 1959: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3529 - accuracy: 0.9240 - val_loss: 0.3618 - val_accuracy: 0.9299\n",
            "Epoch 1960/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3056 - accuracy: 0.9230\n",
            "Epoch 1960: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3072 - accuracy: 0.9234 - val_loss: 0.3679 - val_accuracy: 0.9242\n",
            "Epoch 1961/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3508 - accuracy: 0.9258\n",
            "Epoch 1961: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3463 - accuracy: 0.9261 - val_loss: 0.3991 - val_accuracy: 0.9199\n",
            "Epoch 1962/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4008 - accuracy: 0.9157\n",
            "Epoch 1962: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3984 - accuracy: 0.9150 - val_loss: 0.3590 - val_accuracy: 0.9170\n",
            "Epoch 1963/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4896 - accuracy: 0.8966\n",
            "Epoch 1963: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4871 - accuracy: 0.8959 - val_loss: 0.4310 - val_accuracy: 0.9027\n",
            "Epoch 1964/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4447 - accuracy: 0.9024\n",
            "Epoch 1964: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4444 - accuracy: 0.9025 - val_loss: 0.3955 - val_accuracy: 0.9127\n",
            "Epoch 1965/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4123 - accuracy: 0.8986\n",
            "Epoch 1965: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4123 - accuracy: 0.8986 - val_loss: 0.4310 - val_accuracy: 0.9185\n",
            "Epoch 1966/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3651 - accuracy: 0.9140\n",
            "Epoch 1966: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3652 - accuracy: 0.9138 - val_loss: 0.4461 - val_accuracy: 0.9213\n",
            "Epoch 1967/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3905 - accuracy: 0.9186\n",
            "Epoch 1967: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3879 - accuracy: 0.9187 - val_loss: 0.4603 - val_accuracy: 0.9013\n",
            "Epoch 1968/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4108 - accuracy: 0.9099\n",
            "Epoch 1968: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4091 - accuracy: 0.9094 - val_loss: 0.4470 - val_accuracy: 0.9056\n",
            "Epoch 1969/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.9118\n",
            "Epoch 1969: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4547 - accuracy: 0.9118 - val_loss: 0.4686 - val_accuracy: 0.9084\n",
            "Epoch 1970/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3167 - accuracy: 0.9255\n",
            "Epoch 1970: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3135 - accuracy: 0.9256 - val_loss: 0.4390 - val_accuracy: 0.9199\n",
            "Epoch 1971/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3068 - accuracy: 0.9316\n",
            "Epoch 1971: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3056 - accuracy: 0.9313 - val_loss: 0.4588 - val_accuracy: 0.9099\n",
            "Epoch 1972/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.9181\n",
            "Epoch 1972: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3699 - accuracy: 0.9181 - val_loss: 0.5120 - val_accuracy: 0.9041\n",
            "Epoch 1973/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3491 - accuracy: 0.9193\n",
            "Epoch 1973: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3474 - accuracy: 0.9191 - val_loss: 0.4460 - val_accuracy: 0.8927\n",
            "Epoch 1974/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3998 - accuracy: 0.9074\n",
            "Epoch 1974: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3995 - accuracy: 0.9068 - val_loss: 0.4543 - val_accuracy: 0.8956\n",
            "Epoch 1975/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4196 - accuracy: 0.9084\n",
            "Epoch 1975: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4172 - accuracy: 0.9087 - val_loss: 0.3920 - val_accuracy: 0.9099\n",
            "Epoch 1976/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4022 - accuracy: 0.9163\n",
            "Epoch 1976: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3986 - accuracy: 0.9158 - val_loss: 0.3931 - val_accuracy: 0.9156\n",
            "Epoch 1977/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3640 - accuracy: 0.9203\n",
            "Epoch 1977: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3637 - accuracy: 0.9207 - val_loss: 0.3754 - val_accuracy: 0.9199\n",
            "Epoch 1978/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.2715 - accuracy: 0.9307\n",
            "Epoch 1978: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2690 - accuracy: 0.9304 - val_loss: 0.4022 - val_accuracy: 0.9213\n",
            "Epoch 1979/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3421 - accuracy: 0.9233\n",
            "Epoch 1979: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3414 - accuracy: 0.9234 - val_loss: 0.3993 - val_accuracy: 0.9227\n",
            "Epoch 1980/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4147 - accuracy: 0.9138\n",
            "Epoch 1980: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4080 - accuracy: 0.9151 - val_loss: 0.3424 - val_accuracy: 0.9242\n",
            "Epoch 1981/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3498 - accuracy: 0.9205\n",
            "Epoch 1981: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3498 - accuracy: 0.9205 - val_loss: 0.3590 - val_accuracy: 0.9242\n",
            "Epoch 1982/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.9209\n",
            "Epoch 1982: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3822 - accuracy: 0.9218 - val_loss: 0.3409 - val_accuracy: 0.9199\n",
            "Epoch 1983/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3634 - accuracy: 0.9235\n",
            "Epoch 1983: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4094 - accuracy: 0.9236 - val_loss: 0.4354 - val_accuracy: 0.9242\n",
            "Epoch 1984/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.9227\n",
            "Epoch 1984: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3699 - accuracy: 0.9227 - val_loss: 0.3933 - val_accuracy: 0.9270\n",
            "Epoch 1985/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3111 - accuracy: 0.9291\n",
            "Epoch 1985: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3092 - accuracy: 0.9291 - val_loss: 0.4111 - val_accuracy: 0.9313\n",
            "Epoch 1986/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.2569 - accuracy: 0.9337\n",
            "Epoch 1986: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2531 - accuracy: 0.9344 - val_loss: 0.4600 - val_accuracy: 0.9213\n",
            "Epoch 1987/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2933 - accuracy: 0.9330\n",
            "Epoch 1987: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.2933 - accuracy: 0.9330 - val_loss: 0.4296 - val_accuracy: 0.9242\n",
            "Epoch 1988/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3176 - accuracy: 0.9286\n",
            "Epoch 1988: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3191 - accuracy: 0.9283 - val_loss: 0.4375 - val_accuracy: 0.9242\n",
            "Epoch 1989/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3288 - accuracy: 0.9181\n",
            "Epoch 1989: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3257 - accuracy: 0.9185 - val_loss: 0.4087 - val_accuracy: 0.9299\n",
            "Epoch 1990/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3424 - accuracy: 0.9281\n",
            "Epoch 1990: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3514 - accuracy: 0.9287 - val_loss: 0.4173 - val_accuracy: 0.9256\n",
            "Epoch 1991/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3235 - accuracy: 0.9232\n",
            "Epoch 1991: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3200 - accuracy: 0.9240 - val_loss: 0.4001 - val_accuracy: 0.9313\n",
            "Epoch 1992/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.3121 - accuracy: 0.9317\n",
            "Epoch 1992: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3154 - accuracy: 0.9313 - val_loss: 0.3936 - val_accuracy: 0.9213\n",
            "Epoch 1993/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.3233 - accuracy: 0.9259\n",
            "Epoch 1993: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3264 - accuracy: 0.9264 - val_loss: 0.3966 - val_accuracy: 0.9299\n",
            "Epoch 1994/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3303 - accuracy: 0.9220\n",
            "Epoch 1994: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3303 - accuracy: 0.9220 - val_loss: 0.4267 - val_accuracy: 0.9413\n",
            "Epoch 1995/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.3105 - accuracy: 0.9333\n",
            "Epoch 1995: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3083 - accuracy: 0.9337 - val_loss: 0.4679 - val_accuracy: 0.9299\n",
            "Epoch 1996/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3340 - accuracy: 0.9321\n",
            "Epoch 1996: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3330 - accuracy: 0.9323 - val_loss: 0.5221 - val_accuracy: 0.9213\n",
            "Epoch 1997/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.3551 - accuracy: 0.9246\n",
            "Epoch 1997: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3505 - accuracy: 0.9246 - val_loss: 0.4744 - val_accuracy: 0.9070\n",
            "Epoch 1998/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.3729 - accuracy: 0.9225\n",
            "Epoch 1998: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.3736 - accuracy: 0.9221 - val_loss: 0.4154 - val_accuracy: 0.9227\n",
            "Epoch 1999/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3712 - accuracy: 0.9171\n",
            "Epoch 1999: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.3772 - accuracy: 0.9165 - val_loss: 0.4841 - val_accuracy: 0.9056\n",
            "Epoch 2000/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4087 - accuracy: 0.9083\n",
            "Epoch 2000: val_loss did not improve from 0.28055\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.4063 - accuracy: 0.9091 - val_loss: 0.3803 - val_accuracy: 0.9170\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1bc440a98d0>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "num_epochs = 2000\n",
        "num_batch_size = 50\n",
        "checkpointer = ModelCheckpoint(filepath='Models/audio_classification2.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_val, y_val), callbacks=[checkpointer], verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.lineplot(x = np.arange(num_epochs) , y = model.history.history['loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAx5L8gKanef",
        "outputId": "2471d69e-239f-471e-b5db-95d7bc31777f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9227099418640137\n"
          ]
        }
      ],
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHo6lsFIuXh8"
      },
      "outputs": [],
      "source": [
        "# Done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgHYX0r7nI4h"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "62KuqEjySSUU"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "7a1a0460069fc11b3fb92be4d9fd1cc415d13eb6d6391afc101a1435d589d745"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
